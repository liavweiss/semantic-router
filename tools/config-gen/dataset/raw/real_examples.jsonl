{"id": "real_envoy_9997", "source_file": "config/envoy.yaml", "category": "main", "deployment_context": "unknown", "intent": "Basic configuration", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": [], "full_config": "static_resources:\n  listeners:\n  - name: listener_0\n    address:\n      socket_address:\n        address: 0.0.0.0\n        port_value: 8801\n    filter_chains:\n    - filters:\n      - name: envoy.filters.network.http_connection_manager\n        typed_config:\n          \"@type\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\n          stat_prefix: ingress_http\n          access_log:\n          - name: envoy.access_loggers.stdout\n            typed_config:\n              \"@type\": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog\n              log_format:\n                json_format:\n                  time: \"%START_TIME%\"\n                  protocol: \"%PROTOCOL%\"\n                  request_method: \"%REQ(:METHOD)%\"\n                  request_path: \"%REQ(X-ENVOY-ORIGINAL-PATH?:PATH)%\"\n                  response_code: \"%RESPONSE_CODE%\"\n                  response_flags: \"%RESPONSE_FLAGS%\"\n                  bytes_received: \"%BYTES_RECEIVED%\"\n                  bytes_sent: \"%BYTES_SENT%\"\n                  duration: \"%DURATION%\"\n                  upstream_host: \"%UPSTREAM_HOST%\"\n                  upstream_cluster: \"%UPSTREAM_CLUSTER%\"\n                  upstream_local_address: \"%UPSTREAM_LOCAL_ADDRESS%\"\n                  request_id: \"%REQ(X-REQUEST-ID)%\"\n                  selected_model: \"%REQ(X-SELECTED-MODEL)%\"\n          route_config:\n            name: local_route\n            virtual_hosts:\n            - name: local_service\n              domains: [\"*\"]\n              routes:\n              # Single route using original destination cluster\n              - match:\n                  prefix: \"/\"\n                route:\n                  cluster: vllm_dynamic_cluster\n                  timeout: 300s\n          http_filters:\n          - name: envoy.filters.http.ext_proc\n            typed_config:\n              \"@type\": type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor\n              grpc_service:\n                envoy_grpc:\n                  cluster_name: extproc_service\n              allow_mode_override: true\n              processing_mode:\n                request_header_mode: \"SEND\"\n                response_header_mode: \"SEND\"\n                request_body_mode: \"BUFFERED\"\n                response_body_mode: \"BUFFERED\"\n                request_trailer_mode: \"SKIP\"\n                response_trailer_mode: \"SKIP\"\n              failure_mode_allow: true\n              message_timeout: 300s\n          - name: envoy.filters.http.router\n            typed_config:\n              \"@type\": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router\n              suppress_envoy_headers: true\n          http2_protocol_options:\n            max_concurrent_streams: 100\n            initial_stream_window_size: 65536\n            initial_connection_window_size: 1048576\n          stream_idle_timeout: \"300s\"\n          request_timeout: \"300s\"\n          common_http_protocol_options:\n            idle_timeout: \"300s\"\n\n  clusters:\n  - name: extproc_service\n    connect_timeout: 300s\n    per_connection_buffer_limit_bytes: 52428800\n    type: STATIC\n    lb_policy: ROUND_ROBIN\n    typed_extension_protocol_options:\n      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:\n        \"@type\": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\n        explicit_http_config:\n          http2_protocol_options:\n            connection_keepalive:\n              interval: 300s\n              timeout: 300s\n    load_assignment:\n      cluster_name: extproc_service\n      endpoints:\n      - lb_endpoints:\n        - endpoint:\n            address:\n              socket_address:\n                address: 127.0.0.1\n                port_value: 50051\n\n  # Dynamic vLLM cluster using original destination\n  - name: vllm_dynamic_cluster\n    connect_timeout: 300s\n    per_connection_buffer_limit_bytes: 52428800\n    type: ORIGINAL_DST\n    lb_policy: CLUSTER_PROVIDED\n    original_dst_lb_config:\n      use_http_header: true\n      http_header_name: \"x-vsr-destination-endpoint\"\n    typed_extension_protocol_options:\n      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:\n        \"@type\": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\n        explicit_http_config:\n          http_protocol_options: {}\n\nadmin:\n  address:\n    socket_address:\n      address: \"127.0.0.1\"\n      port_value: 19000\n", "source": "real", "collected_at": "2026-01-06T10:23:38.038098"}
{"id": "real_config_697", "source_file": "config/config.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Configuration quickstart deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for quickstart deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "# You can override by specifying your own mappings below:\n# Uncomment and customize if you need different model mappings:\n# mom_registry:\n#   \"models/mom-domain-classifier\": \"LLM-Semantic-Router/lora_intent_classifier_bert-base-uncased_model\"\n#   \"models/mom-pii-classifier\": \"LLM-Semantic-Router/lora_pii_detector_bert-base-uncased_model\"\n#   \"models/mom-jailbreak-classifier\": \"LLM-Semantic-Router/lora_jailbreak_classifier_bert-base-uncased_model\"\n#   \"models/mom-halugate-detector\": \"KRLabsOrg/lettucedect-base-modernbert-en-v1\"\n#   \"models/mom-halugate-sentinel\": \"LLM-Semantic-Router/halugate-sentinel\"\n#   \"models/mom-halugate-explainer\": \"tasksource/ModernBERT-base-nli\"\n#   \"models/mom-embedding-pro\": \"Qwen/Qwen3-Embedding-0.6B\"\n#   \"models/mom-embedding-flash\": \"google/embeddinggemma-300m\"\n\n# Response API Configuration\n# Enables OpenAI Response API support with conversation chaining\nresponse_api:\n  enabled: true\n  store_backend: \"memory\"  # Options: \"memory\", \"milvus\", \"redis\"\n  ttl_seconds: 86400       # 24 hours\n  max_responses: 1000\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"qwen3\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\njailbreak_mapping_path: \"models/mom-jailbreak-classifier/label_mapping.json\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    use_modernbert: false\n    threshold: 0.9\n    use_cpu: true\n  pii_mapping_path: \"models/mom-pii-classifier/label_mapping.json\"\n\n# Hallucination mitigation configuration\n# Disabled by default - enable in decisions via hallucination plugin\nhallucination_mitigation:\n  enabled: false\n  # Fact-check classifier: determines if a prompt needs fact verification\n  fact_check_model:\n    model_id: \"models/mom-halugate-sentinel\"\n    threshold: 0.6\n    use_cpu: true\n  # Hallucination detector: verifies if LLM response is grounded in context\n  hallucination_model:\n    model_id: \"models/mom-halugate-detector\"\n    threshold: 0.8\n    use_cpu: true\n  # NLI model: provides explanations for hallucinated spans\n  nli_model:\n    model_id: \"models/mom-halugate-explainer\"\n    threshold: 0.9\n    use_cpu: true\n\n# vLLM Endpoints Configuration\n# The 'address' field can be an IP address (IPv4 or IPv6) or a domain name\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1, example.com, localhost\n# Note: Use the 'port' field for port numbers, not in the address field\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]  # Optional: omit to let upstream handle endpoint selection\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\n# Decisions define routing logic with domain-based conditions\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business and management queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n\ndefault_model: qwen3\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  metrics:\n    enabled: true  # Set to false to disable the Prometheus /metrics endpoint\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:38.106918"}
{"id": "real_config.tracing_3469", "source_file": "config/observability/config.tracing.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability"], "full_config": "# Local Tracing Configuration (Jaeger + Always-On Sampling)\n# This config is used by tools/tracing/docker-compose.tracing.yaml via CONFIG_FILE.\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint1\"]\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\ncategories:\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful assistant.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n\nobservability:\n  metrics:\n    enabled: true  # Set to false to disable the Prometheus /metrics endpoint\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"  # Jaeger gRPC OTLP endpoint inside compose network\n      insecure: true\n    sampling:\n      type: \"always_on\"  # Always sample in local/dev for easy debugging\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"dev\"\n      deployment_environment: \"local\"\n", "source": "real", "collected_at": "2026-01-06T10:23:38.130429"}
{"id": "real_jailbreak_domain_1506", "source_file": "config/prompt-guard/jailbreak_domain.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "medium", "key_features": ["pii_detection", "jailbreak_detection", "routing_decisions"], "full_config": "# Category-Level Jailbreak Detection Example\n# This example demonstrates how to configure jailbreak detection at the category level\n# Different categories can have different jailbreak detection settings and thresholds based on their risk profiles\n\n# Global jailbreak detection configuration (can be overridden per category)\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7  # Global default threshold - can be overridden per category\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: business\n    description: \"Business queries, strategy, and professional advice\"\n    mmlu_categories: [\"business\"]\n  - name: customer_support\n    description: \"Customer support and general inquiries\"\n    mmlu_categories: [\"customer_support\"]\n  - name: code_generation\n    description: \"Internal code generation and development tools\"\n    mmlu_categories: [\"code_generation\"]\n  - name: testing\n    description: \"Testing and quality assurance queries\"\n    mmlu_categories: [\"testing\"]\n  - name: general\n    description: \"General queries that don't fit into specific categories\"\n    mmlu_categories: [\"general\"]\n\n# Decisions define routing logic with domain-based conditions\nstrategy: \"priority\"\n\ndecisions:\n  # High-security category: Strict jailbreak detection with high threshold\n  - name: \"business_decision\"\n    description: \"Business queries, strategy, and professional advice\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a professional business consultant. Provide practical, actionable business advice.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n          threshold: 0.9\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Public-facing category: Enable with standard threshold\n  - name: \"customer_support_decision\"\n    description: \"Customer support and general inquiries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"customer_support\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a friendly customer support agent. Help users with their questions.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n          threshold: 0.8\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Internal tool category: Relaxed threshold (trusted environment)\n  - name: \"code_generation_decision\"\n    description: \"Internal code generation and development tools\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"code_generation\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a code generation assistant for internal developers.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n          threshold: 0.5\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Testing category: Disable jailbreak detection\n  - name: \"testing_decision\"\n    description: \"Testing and quality assurance queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"testing\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a QA assistant helping with test scenarios.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: false\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Default category: Uses global setting (inherits prompt_guard.enabled and threshold)\n  - name: \"general_decision\"\n    description: \"General queries that don't fit into specific categories\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"general\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful assistant.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n# Model configuration\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint1\"]\n\n# Reasoning family configurations\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n# Default model for fallback\ndefault_model: qwen3\n\n# vLLM endpoints configuration\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\n# Usage Notes:\n# =============\n# 1. Global Settings:\n#    - prompt_guard.enabled: Sets the default enabled/disabled for all categories\n#    - prompt_guard.threshold: Sets the default detection threshold (0.0-1.0) for all categories\n# 2. Category Overrides:\n#    - jailbreak_enabled: Override global enabled/disabled setting per category\n#    - jailbreak_threshold: Override global threshold per category\n# 3. Inheritance:\n#    - If jailbreak_enabled is not specified, inherits from prompt_guard.enabled\n#    - If jailbreak_threshold is not specified, inherits from prompt_guard.threshold\n# 4. Threshold Tuning:\n#    - Higher threshold (0.8-0.95): Stricter detection, fewer false positives, may miss subtle attacks\n#    - Lower threshold (0.5-0.7): More sensitive detection, catches more attacks, higher false positive rate\n#    - Recommended: Start with 0.7 globally, adjust per category based on risk profile\n# 5. Use Cases:\n#    - High-security categories (business, customer_support): Use higher thresholds (0.8-0.9)\n#    - Internal tools with code/technical content: Use lower thresholds (0.5-0.6) to reduce false positives\n#    - General categories: Use global default threshold\n# 6. Security Best Practices:\n#    - Enable jailbreak detection by default (prompt_guard.enabled: true)\n#    - Only disable or use very low thresholds for specific categories where the risk is managed differently\n#    - Consider the consequences of threshold settings on a per-category basis\n#    - Monitor false positive and false negative rates to tune thresholds appropriately\n", "source": "real", "collected_at": "2026-01-06T10:23:38.162962"}
{"id": "real_pii_domain_4421", "source_file": "config/prompt-guard/pii_domain.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with routing decisions", "use_case": "Configuration for unknown deployment", "complexity": "medium", "key_features": ["routing_decisions", "tools"], "full_config": "# Category-Level PII Detection Example\n# This example demonstrates how to configure PII detection at the category level\n# Different categories can have different PII detection settings and thresholds based on their sensitivity\n\n# Global PII detection configuration (can be overridden per category)\nclassifier:\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_model\"\n    threshold: 0.7  # Global default threshold - can be overridden per category\n    use_cpu: true\n    pii_mapping_path: \"models/pii_classifier_modernbert-base_model/pii_type_mapping.json\"\n\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: healthcare\n    description: \"Healthcare and medical queries\"\n    mmlu_categories: [\"healthcare\"]\n  - name: finance\n    description: \"Financial and banking queries\"\n    mmlu_categories: [\"finance\"]\n  - name: customer_support\n    description: \"Customer support and general inquiries\"\n    mmlu_categories: [\"customer_support\"]\n  - name: code_generation\n    description: \"Internal code generation and development tools\"\n    mmlu_categories: [\"code_generation\"]\n  - name: documentation\n    description: \"Public documentation and help articles\"\n    mmlu_categories: [\"documentation\"]\n  - name: testing\n    description: \"Testing and quality assurance queries\"\n    mmlu_categories: [\"testing\"]\n  - name: general\n    description: \"General queries that don't fit into specific categories\"\n    mmlu_categories: [\"general\"]\n\n# Decisions define routing logic with domain-based conditions\nstrategy: \"priority\"\n\ndecisions:\n  # High-security category: Strict PII detection with high threshold\n  - name: \"healthcare_decision\"\n    description: \"Healthcare and medical queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"healthcare\"\n    modelRefs:\n      - model: \"secure-llm\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a healthcare assistant. Handle all personal information with utmost care.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          threshold: 0.9\n          pii_types_allowed: [\"GPE\", \"ORGANIZATION\"]\n\n  # Financial category: Very strict PII detection\n  - name: \"finance_decision\"\n    description: \"Financial and banking queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"finance\"\n    modelRefs:\n      - model: \"secure-llm\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a financial advisor. Never store or log any PII information.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          threshold: 0.95\n          pii_types_allowed: [\"GPE\", \"ORGANIZATION\"]\n\n  # Customer support: Balanced threshold\n  - name: \"customer_support_decision\"\n    description: \"Customer support and general inquiries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"customer_support\"\n    modelRefs:\n      - model: \"general-llm\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a friendly customer support agent. Be cautious with customer information.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          threshold: 0.8\n          pii_types_allowed: []\n\n  # Internal tools: Relaxed threshold (trusted environment)\n  - name: \"code_generation_decision\"\n    description: \"Internal code generation and development tools\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"code_generation\"\n    modelRefs:\n      - model: \"general-llm\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a code generation assistant for internal developers.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          threshold: 0.5\n          pii_types_allowed: []\n\n  # Public documentation: Lower threshold for broader detection\n  - name: \"documentation_decision\"\n    description: \"Public documentation and help articles\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"documentation\"\n    modelRefs:\n      - model: \"general-llm\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a documentation assistant. Help create clear public documentation.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          threshold: 0.6\n          pii_types_allowed: []\n\n  # Testing category: Disable PII detection\n  - name: \"testing_decision\"\n    description: \"Testing and quality assurance queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"testing\"\n    modelRefs:\n      - model: \"general-llm\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a QA assistant helping with test scenarios.\"\n      - type: \"pii\"\n        configuration:\n          enabled: false\n          pii_types_allowed: []\n\n  # Default category: Uses global setting\n  - name: \"general_decision\"\n    description: \"General queries that don't fit into specific categories\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"general\"\n    modelRefs:\n      - model: \"general-llm\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful assistant.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n# Model configuration\nmodel_config:\n  \"secure-llm\":\n    preferred_endpoints: [\"secure-endpoint\"]\n\n  \"general-llm\":\n    preferred_endpoints: [\"general-endpoint\"]\n\n# Default model for fallback\ndefault_model: general-llm\n\n# vLLM endpoints configuration\nvllm_endpoints:\n  - name: \"secure-endpoint\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\n  - name: \"general-endpoint\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 1\n\n# Usage Notes:\n# =============\n# 1. Global Settings:\n#    - classifier.pii_model: Configures the PII detection model and default threshold\n#    - threshold: Sets the default detection threshold (0.0-1.0) for all categories\n# 2. Category Overrides:\n#    - pii_enabled: Override global enabled/disabled setting per category\n#    - pii_threshold: Override global threshold per category\n# 3. Inheritance:\n#    - If pii_enabled is not specified, inherits from global (enabled if pii_model is configured)\n#    - If pii_threshold is not specified, inherits from global classifier.pii_model.threshold\n# 4. Threshold Tuning Guidelines:\n#    - Higher threshold (0.85-0.95): Stricter detection, fewer false positives, may miss subtle PII\n#      * Use for: Healthcare, Finance, Legal categories where precision is critical\n#      * Risk: May miss some PII entities with lower confidence\n#    - Medium threshold (0.65-0.85): Balanced detection, good for most use cases\n#      * Use for: Customer support, HR, General business queries\n#      * Risk: Moderate false positive/negative rate\n#    - Lower threshold (0.4-0.65): More sensitive detection, catches more PII, higher false positive rate\n#      * Use for: Public content, Documentation, Code generation (to avoid false positives)\n#      * Risk: Higher false positive rate, especially with technical content\n# 5. PII Type Considerations:\n#    - Different PII types have different consequences:\n#      * Critical (SSN, Credit Card, Passwords): Use threshold 0.9+\n#      * Sensitive (Email, Phone, Address): Use threshold 0.75-0.9\n#      * General (Names, Organizations, Dates): Use threshold 0.6-0.75\n#    - Consider using different thresholds per category based on expected PII types\n# 6. Use Cases by Category:\n#    - Healthcare: High threshold (0.9+) to avoid false positives on medical terms\n#    - Finance: Very high threshold (0.95+) for critical financial PII\n#    - Customer Support: Medium-high threshold (0.8) for balanced protection\n#    - Code/Technical: Lower threshold (0.5-0.6) to reduce false positives on code artifacts\n#    - Public Content: Lower threshold (0.6) to catch more potential PII before publication\n#    - Testing: Disabled to avoid interference with test data\n# 7. Security Best Practices:\n#    - Enable PII detection by default (configure classifier.pii_model)\n#    - Only disable or use very low thresholds for specific categories where risk is managed\n#    - Consider the consequences of PII exposure on a per-category basis\n#    - Monitor false positive and false negative rates to tune thresholds appropriately\n#    - Combine with model-level PII policies (pii_policy) for defense in depth\n#    - Use different thresholds for different sensitivity levels:\n#      * Public-facing categories: Higher thresholds to reduce false positives\n#      * Internal categories: Lower thresholds for broader detection\n#      * Critical categories: Highest thresholds for precision\n# 8. Testing and Tuning:\n#    - Start with conservative (higher) thresholds and adjust based on false positive rate\n#    - Monitor PII detection metrics to understand category-specific patterns\n#    - Test with representative data for each category to validate threshold settings\n#    - Consider A/B testing different thresholds to find optimal values\n", "source": "real", "collected_at": "2026-01-06T10:23:38.209219"}
{"id": "real_prompt_guard_2104", "source_file": "config/prompt-guard/prompt_guard.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"127.0.0.1\"  # Static IPv4 of llm-katan within docker compose network\n    port: 1234\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]  # Optional: omit to let upstream handle endpoint selection\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\n# Decisions define routing logic with domain-based conditions\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business and management queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\ndefault_model: qwen3\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:38.333274"}
{"id": "real_prompt_guard_external_3382", "source_file": "config/prompt-guard/prompt_guard_external.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "observability"], "full_config": "# Example configuration showing how to use ExternalModels for PromptGuard\n# This demonstrates the new hybrid approach where vLLM configuration can be\n# specified in external_models with model_role=\"guardrail\"\n\n# Embedding models configuration\nembedding_models:\n  qwen3_model_path: \"models/Qwen3-Embedding-0.6B\"\n  gemma_model_path: \"models/EmbeddingGemma-300M\"\n  use_cpu: true\n\n# BERT model for semantic similarity\nbert_model:\n  model_id: \"models/all-MiniLM-L6-v2\"\n  threshold: 0.85\n  use_cpu: true\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Prompt Guard Configuration\n# When use_vllm=true, the system will look for an external model with model_role=\"guardrail\"\n# vLLM endpoint/model configuration is now in external_models section below\nprompt_guard:\n  enabled: true\n  use_vllm: true  # Enable vLLM mode - will use external_models configuration\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n  threshold: 0.7  # Default threshold (can be overridden by external_models)\n\n  # Note: When use_vllm=true, the following vLLM fields are NOT needed here:\n  # - classifier_vllm_endpoint (use external_models.llm_endpoint instead)\n  # - vllm_model_name (use external_models.llm_model_name instead)\n  # - vllm_timeout_seconds (use external_models.llm_timeout_seconds instead)\n  # - response_parser_type (use external_models.parser_type instead)\n\n  # The following Candle fields are only used when use_vllm=false:\n  # use_modernbert: false\n  # model_id: \"models/mom-jailbreak-classifier\"\n  # use_cpu: true\n\n# External Models Configuration\n# This is the new recommended way to configure vLLM-based guardrails\n# Note: jailbreak_mapping_path and threshold are still in prompt_guard because they are\n# used by the classification logic (not by the vLLM model itself)\nexternal_models:\n  - llm_provider: \"vllm\"\n    model_role: \"guardrail\"  # This identifies it as a guardrail/safety model\n    llm_endpoint:\n      address: \"127.0.0.1\"\n      port: 1235\n      name: \"qwen3guard-endpoint\"\n      use_chat_template: true  # Qwen3Guard requires chat template format\n      # prompt_template: \"Custom template with %s placeholder\"  # Optional\n    llm_model_name: \"qwen_guard\"  # Model name as served by vLLM\n    llm_timeout_seconds: 30\n    parser_type: \"qwen3guard\"  # Response parser type\n    threshold: 0.75  # Optional: Override the default threshold from prompt_guard\n\n# vLLM Endpoints Configuration (for backend inference)\n# These are separate from the guardrail endpoint above\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"127.0.0.1\"\n    port: 1234\n    weight: 1\n\n# Backend model configuration\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint1\"]\n\ndefault_model: \"qwen3\"\n\n# API configuration\napi:\n  batch_classification:\n    metrics:\n      enabled: true\n\n# Observability\nobservability:\n  tracing:\n    enabled: false\n  metrics:\n    enabled: true\n\n# Semantic cache\nsemantic_cache:\n  enabled: false\n\n# Response API\nresponse_api:\n  enabled: false\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.351397"}
{"id": "real_milvus_4299", "source_file": "config/semantic-cache/milvus.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": ["semantic_cache"], "full_config": "# Milvus Vector Database Configuration for Semantic Cache\n# This configuration file contains settings for using Milvus as the semantic cache backend.\n# To use this configuration:\n# 1. Set backend_type: \"milvus\" in your main config.yaml\n# 2. Set backend_config_path: \"config/semantic-cache/milvus.yaml\" in your main config.yaml\n# 3. Ensure Milvus server is running and accessible\n# 4. Build with Milvus support: go build -tags=milvus\n\n# Milvus connection settings\nconnection:\n  # Milvus server host (change for production deployment)\n  host: \"localhost\"  # For production: use your Milvus cluster endpoint\n\n  # Milvus server port\n  port: 19530  # Standard Milvus port\n\n  # Database name (optional, defaults to \"default\")\n  database: \"semantic_router_cache\"\n\n  # Connection timeout in seconds\n  timeout: 30\n\n  # Authentication (enable for production)\n  auth:\n    enabled: false  # Set to true for production\n    username: \"\"    # Your Milvus username\n    password: \"\"    # Your Milvus password\n\n  # TLS/SSL configuration (recommended for production)\n  tls:\n    enabled: false      # Set to true for secure connections\n    cert_file: \"\"       # Path to client certificate\n    key_file: \"\"        # Path to client private key\n    ca_file: \"\"         # Path to CA certificate\n\n# Collection settings\ncollection:\n  # Name of the collection to store cache entries\n  name: \"semantic_cache\"\n\n  # Description of the collection\n  description: \"Semantic cache for LLM request-response pairs\"\n\n  # Vector field configuration\n  vector_field:\n    # Name of the vector field\n    name: \"embedding\"\n\n    # Dimension of the embeddings (auto-detected from model at runtime)\n    dimension: 384  # This value is ignored - dimension is auto-detected from the embedding model\n\n    # Metric type for similarity calculation\n    metric_type: \"IP\"  # Inner Product (cosine similarity for normalized vectors)\n\n  # Index configuration for the vector field\n  index:\n    # Index type (HNSW is recommended for most use cases)\n    type: \"HNSW\"\n\n    # Index parameters\n    params:\n      M: 16              # Number of bi-directional links for each node\n      efConstruction: 64  # Search scope during index construction\n\n# Search configuration\nsearch:\n  # Search parameters\n  params:\n    ef: 64  # Search scope during search (should be >= topk)\n\n  # Number of top results to retrieve for similarity comparison\n  topk: 10\n\n  # Consistency level for search operations\n  consistency_level: \"Session\"  # Options: Strong, Session, Bounded, Eventually\n\n# Performance and resource settings\nperformance:\n  # Connection pool settings\n  connection_pool:\n    # Maximum number of connections in the pool\n    max_connections: 10\n\n    # Maximum idle connections\n    max_idle_connections: 5\n\n    # Connection timeout for acquiring from pool\n    acquire_timeout: 5\n\n  # Batch operation settings\n  batch:\n    # Maximum batch size for insert operations\n    insert_batch_size: 1000\n\n    # Batch timeout in seconds\n    timeout: 30\n\n# Data management\ndata_management:\n  # Automatic data expiration (TTL) settings\n  ttl:\n    # Enable automatic TTL-based cleanup (requires TTL to be set in main config)\n    enabled: true\n\n    # Field name to store timestamp for TTL calculation\n    timestamp_field: \"timestamp\"\n\n    # Cleanup interval in seconds (how often to run cleanup)\n    cleanup_interval: 3600  # 1 hour\n\n  # Compaction settings\n  compaction:\n    # Enable automatic compaction\n    enabled: true\n\n    # Compaction interval in seconds\n    interval: 86400  # 24 hours\n\n# Logging and monitoring\nlogging:\n  # Log level for Milvus client operations (debug, info, warn, error)\n  level: \"info\"\n\n  # Enable query/search logging for debugging\n  enable_query_log: false\n\n  # Enable performance metrics collection\n  enable_metrics: true\n\n# Development and debugging settings\ndevelopment:\n  # Drop collection on startup (WARNING: This will delete all cached data)\n  drop_collection_on_startup: true  # Enable for development to test dynamic dimensions\n\n  # Create collection if it doesn't exist\n  auto_create_collection: true\n\n  # Print detailed error messages\n  verbose_errors: true\n\n# Example configurations for different environments:\n#\n# Local Development (Docker):\n# connection:\n#   host: \"localhost\"\n#   port: 19530\n#   auth:\n#     enabled: false\n#   development:\n#     drop_collection_on_startup: true  # Clean start for development\n#\n# Production (Zilliz Cloud):\n# connection:\n#   host: \"your-cluster-endpoint.zillizcloud.com\"\n#   port: 443\n#   auth:\n#     enabled: true\n#     username: \"your-username\"\n#     password: \"your-password\"\n#   tls:\n#     enabled: true\n#   development:\n#     drop_collection_on_startup: false\n#     auto_create_collection: false  # Pre-create collections in production\n#\n# Kubernetes Deployment:\n# connection:\n#   host: \"milvus-service.milvus-system.svc.cluster.local\"\n#   port: 19530\n#   timeout: 60  # Longer timeout for cluster environments\n", "source": "real", "collected_at": "2026-01-06T10:23:38.372686"}
{"id": "real_redis_1330", "source_file": "config/semantic-cache/redis.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": ["semantic_cache"], "full_config": "# Redis Vector Database Configuration for Semantic Cache\n# This configuration file contains settings for using Redis with vector search as the semantic cache backend.\n# To use this configuration:\n# 1. Set backend_type: \"redis\" in your main config.yaml\n# 2. Set backend_config_path: \"config/semantic-cache/redis.yaml\" in your main config.yaml\n# 3. Ensure Redis server with RediSearch module is running and accessible\n# 4. Redis Stack or Redis Enterprise with vector search capability is required\n\n# Redis connection settings\nconnection:\n  # Redis server host (change for production deployment)\n  host: \"localhost\"  # For production: use your Redis cluster endpoint\n\n  # Redis server port\n  port: 6379  # Standard Redis port\n\n  # Database number (0-15 for standard Redis)\n  database: 0\n\n  # Password for authentication (leave empty if no auth required)\n  password: \"\"\n\n  # Connection timeout in seconds\n  timeout: 30\n\n  # TLS/SSL configuration (recommended for production)\n  tls:\n    enabled: false      # Set to true for secure connections\n    cert_file: \"\"       # Path to client certificate\n    key_file: \"\"        # Path to client private key\n    ca_file: \"\"         # Path to CA certificate\n\n# Index settings for vector search\nindex:\n  # Name of the search index\n  name: \"semantic_cache_idx\"\n\n  # Key prefix for documents in this index\n  prefix: \"doc:\"\n\n  # Vector field configuration\n  vector_field:\n    # Name of the vector field\n    name: \"embedding\"\n\n    # Dimension of the embeddings (auto-detected from model at runtime)\n    dimension: 384  # This value is ignored - dimension is auto-detected from the embedding model\n\n    # Distance metric for similarity calculation\n    # Options: COSINE (cosine similarity), L2 (Euclidean distance), IP (inner product)\n    metric_type: \"COSINE\"  # COSINE is recommended for semantic similarity\n\n  # Index type and parameters\n  # Options: HNSW (Hierarchical Navigable Small World) or FLAT (brute force)\n  index_type: \"HNSW\"  # HNSW is recommended for performance\n\n  # Index parameters (only used when index_type is HNSW)\n  params:\n    M: 16              # Number of bi-directional links per node (default: 16)\n    efConstruction: 64  # Size of dynamic candidate list during construction (default: 64)\n\n# Search configuration\nsearch:\n  # Number of top results to retrieve for similarity comparison\n  topk: 1  # We only need the most similar entry for cache lookup\n\n# Logging and monitoring\nlogging:\n  # Log level for Redis client operations (debug, info, warn, error)\n  level: \"info\"\n\n  # Enable query/search logging for debugging\n  enable_query_log: false\n\n  # Enable performance metrics collection\n  enable_metrics: true\n\n# Development and debugging settings\ndevelopment:\n  # Drop index on startup (WARNING: This will delete all cached data)\n  drop_index_on_startup: true  # Enable for development to test dynamic dimensions\n\n  # Create index if it doesn't exist\n  auto_create_index: true\n\n  # Print detailed error messages\n  verbose_errors: true\n\n# Example configurations for different environments:\n#\n# Local Development (Docker - Redis Stack):\n# connection:\n#   host: \"localhost\"\n#   port: 6379\n#   password: \"\"\n#   database: 0\n# development:\n#   drop_index_on_startup: true  # Clean start for development\n#   auto_create_index: true\n#\n# Production (Redis Enterprise Cloud):\n# connection:\n#   host: \"redis-12345.c123.us-east-1-1.ec2.cloud.redislabs.com\"\n#   port: 12345\n#   password: \"your-secure-password\"\n#   database: 0\n#   tls:\n#     enabled: true\n# development:\n#   drop_index_on_startup: false\n#   auto_create_index: false  # Pre-create indexes in production\n#\n# Kubernetes Deployment:\n# connection:\n#   host: \"redis-service.redis-system.svc.cluster.local\"\n#   port: 6379\n#   timeout: 60  # Longer timeout for cluster environments\n#   password: \"${REDIS_PASSWORD}\"  # Use environment variable\n#\n# Performance Tuning Notes:\n# - For HNSW index:\n#   * M (16-64): Higher M = better recall, more memory, slower indexing\n#   * efConstruction (64-512): Higher ef = better index quality, slower indexing\n# - For metric_type:\n#   * COSINE: Best for semantic similarity (normalized vectors)\n#   * IP: Fast but requires normalized vectors\n#   * L2: Euclidean distance, good for non-normalized vectors\n# - For index_type:\n#   * HNSW: Fast approximate search, recommended for >10k entries\n#   * FLAT: Exact search, better for <10k entries or when recall must be 100%\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.387718"}
{"id": "real_config.hybrid_552", "source_file": "config/semantic-cache/config.hybrid.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "tools"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"  # Hybrid HNSW + Milvus backend\n  similarity_threshold: 0.85\n  ttl_seconds: 3600\n\n  # Hybrid cache specific settings\n  max_memory_entries: 100000  # Max entries in HNSW index (100K)\n\n  # HNSW parameters\n  hnsw_m: 16  # Number of bi-directional links\n  hnsw_ef_construction: 200  # Construction quality parameter\n\n  # Milvus configuration file path\n  backend_config_path: \"config/semantic-cache/milvus.yaml\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint1\"]\n\n# Classifier configuration\nclassifier:\n  enabled: true\n  model_path: \"models/qwen3-router_model/router_qwen_generative_model.safetensors\"\n  tokenizer_path: \"models/qwen3-router_model\"\n  use_cpu: true\n  threshold: 0.7\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.398625"}
{"id": "real_config.redis_5707", "source_file": "config/semantic-cache/config.redis.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true  # Global cache enabled (applies to all requests)\n  backend_type: \"redis\"  # Using Redis vector database for semantic cache\n  similarity_threshold: 0.80  # Global threshold (lowered for better matching)\n  ttl_seconds: 3600\n  backend_config_path: \"config/semantic-cache/redis.yaml\"\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"local_vllm\"\n    address: \"127.0.0.1\"  # Local vLLM instance\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"  # GPT-OSS uses reasoning_effort parameter\n    preferred_endpoints: [\"local_vllm\"]\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\n# Decisions define routing logic with domain-based conditions\n# Redis semantic cache is enabled for selected high-value categories\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics - with Redis semantic cache\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries - with Redis semantic cache\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics - with Redis semantic cache\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Other categories without semantic-cache for comparison\n  - name: \"business_decision\"\n    description: \"Business and management queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  high_confidence_threshold: 0.99\n  low_latency_threshold_ms: 2000\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  success_confidence_threshold: 0.8\n  large_batch_threshold: 4\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  multi_task_lora_weight: 0.30\n  single_task_traditional_weight: 0.30\n  large_batch_lora_weight: 0.25\n  small_batch_traditional_weight: 0.25\n  medium_batch_weight: 0.10\n  high_confidence_lora_weight: 0.25\n  low_confidence_traditional_weight: 0.25\n  low_latency_lora_weight: 0.30\n  high_latency_traditional_weight: 0.10\n  performance_history_weight: 0.20\n  traditional_bert_confidence_threshold: 0.95\n  traditional_modernbert_confidence_threshold: 0.8\n  traditional_pii_detection_threshold: 0.5\n  traditional_token_classification_threshold: 0.9\n  traditional_dropout_prob: 0.1\n  traditional_attention_dropout_prob: 0.1\n  tie_break_confidence: 0.5\n\ndefault_model: openai/gpt-oss-20b\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.494264"}
{"id": "real_config.e2e_6379", "source_file": "config/testing/config.e2e.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "lora_routing"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\" or \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n\n  # For production environments, use Milvus for scalable caching:\n  # backend_type: \"milvus\"\n  # backend_config_path: \"config/semantic-cache/milvus.yaml\"\n\n  # Development/Testing: Use in-memory cache (current configuration)\n  # - Fast startup and no external dependencies\n  # - Limited to single instance scaling\n  # - Data lost on restart\n\n  # Production: Use Milvus vector database\n  # - Horizontally scalable and persistent\n  # - Supports distributed deployments\n  # - Requires Milvus cluster setup\n  # - To enable: uncomment the lines above and install Milvus dependencies\ntools:\n  enabled: true  # Set to true to enable automatic tool selection\n  top_k: 3        # Number of most relevant tools to select\n  similarity_threshold: 0.2  # Threshold for tool similarity\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true  # If true, return no tools on failure; if false, return error\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration - supports multiple endpoints, each can serve multiple models\nvllm_endpoints:\n  - name: \"qwen-endpoint\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n    health_check_path: \"/health\"\n  - name: \"tinyllama-endpoint\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 1\n    health_check_path: \"/health\"\n\nmodel_config:\n  \"Model-A\":\n    use_reasoning: false\n    reasoning_family: \"qwen3\"  # This model uses Qwen reasoning syntax\n    preferred_endpoints: [\"qwen-endpoint\"]\n  \"Model-B\":\n    use_reasoning: false\n    preferred_endpoints: [\"tinyllama-endpoint\"]\n\n# Classifier configuration for text classification\n# Using LoRA intent classifier (preferred modern approach with lora_config.json)\nclassifier:\n  category_model:\n    model_id: \"models/lora_intent_classifier_bert-base-uncased_model\"\n    use_modernbert: false  # BERT-based LoRA model\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/lora_intent_classifier_bert-base-uncased_model/category_mapping.json\"\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    use_modernbert: false  # BERT-based LoRA model (this field is ignored - always auto-detects)\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\ncategories:\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business and management related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"Model-A\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\"]\n\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"Model-A\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\"]\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"Model-A\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\"]\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"Model-A\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\"]\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"Model-A\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\"]\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"Model-A\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\"]\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: [\"EMAIL_ADDRESS\", \"PERSON\", \"GPE\", \"PHONE_NUMBER\", \"US_SSN\", \"CREDIT_CARD\"]\n\n  # Default catch-all decision for unmatched requests (E2E PII test fix)\n  # This ensures PII detection is always enabled, even when no specific decision matches\n  - name: \"default_decision\"\n    description: \"Default catch-all decision - blocks all PII for safety\"\n    priority: 1  # Lowest priority - only matches if nothing else does\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"always\"  # Always matches as fallback\n    modelRefs:\n      - model: \"Model-B\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []  # Block ALL PII - empty list means nothing allowed\n\ndefault_model: \"Model-A\"\n\n# API Configuration\napi:\n  batch_classification:\n    # Metrics configuration for monitoring batch classification performance\n    metrics:\n      enabled: true              # Enable comprehensive metrics collection\n      detailed_goroutine_tracking: true  # Track individual goroutine lifecycle\n      high_resolution_timing: false      # Use nanosecond precision timing\n      sample_rate: 1.0                   # Collect metrics for all requests (1.0 = 100%, 0.5 = 50%)\n      # Histogram buckets for metrics (directly configure what you need)\n      duration_buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Reasoning family configurations - define how different model families handle reasoning syntax\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: medium  # Default reasoning effort level (low, medium, high)\n", "source": "real", "collected_at": "2026-01-06T10:23:38.603880"}
{"id": "real_config.hallucination_3225", "source_file": "config/testing/config.hallucination.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions"], "full_config": "# Configuration for testing hallucination detection pipeline\n# Tests: fact-check classifier, hallucination detector, and NLI explainer\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: false  # Disable cache for testing\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Fact-check rules for signal classification\n# Similar to keyword_rules and embedding_rules, but based on ML model classification\n# The classifier outputs one of these signals that can be referenced in decision conditions\n# Threshold is read from hallucination_mitigation.fact_check_model.threshold\nfact_check_rules:\n  - name: needs_fact_check\n    description: \"Query contains factual claims that should be verified against context\"\n  - name: no_fact_check_needed\n    description: \"Query is creative, code-related, or opinion-based - no fact verification needed\"\n\n# Hallucination mitigation model configuration\n# Contains model paths for fact-check classifier, hallucination detector, and NLI explainer\nhallucination_mitigation:\n  # Fact-check classifier: determines if a prompt needs fact verification\n  fact_check_model:\n    model_id: \"models/mom-halugate-sentinel\"\n    threshold: 0.6\n    use_cpu: true\n\n  # Hallucination detector: verifies if LLM response is grounded in context\n  hallucination_model:\n    model_id: \"models/mom-halugate-detector\"\n    threshold: 0.8\n    use_cpu: true\n\n  # NLI model: provides explanations for hallucinated spans\n  nli_model:\n    model_id: \"models/mom-halugate-explainer\"\n    threshold: 0.9\n    use_cpu: true\n\n# Prompt guard\nprompt_guard:\n  enabled: true\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM endpoints - mock server for testing\nvllm_endpoints:\n  - name: \"mock-vllm\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n    health_check_path: \"/health\"\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"mock-vllm\"]\n\n# Minimal categories for testing\ncategories:\n  - name: general\n    description: \"General questions\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"general_decision\"\n    description: \"General questions\"\n    priority: 100\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"general\"\n        - type: \"fact_check\"\n          name: \"needs_fact_check\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true  # Enable NLI for detailed explanations\n          # Action when hallucination detected: \"header\", \"body\", \"block\", or \"none\"\n          hallucination_action: \"header\"\n          # Action when fact-check needed but no tool context: \"header\", \"body\", or \"none\"\n          unverified_factual_action: \"header\"\n          # Include detailed info (confidence, spans) in body warning\n          include_hallucination_details: true\n\ndefault_model: qwen3\n\n# API Configuration\napi:\n  batch_classification:\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.629346"}
{"id": "real_config.response-api_7325", "source_file": "config/testing/config.response-api.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions", "use_case": "Configuration for unknown deployment", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions", "lora_routing"], "full_config": "# Response API testing configuration\n# Based on config.e2e.yaml with Response API enabled\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\n# Response API Configuration - NEW\nresponse_api:\n  enabled: true\n  store_backend: \"memory\"  # Use in-memory store for testing\n  ttl_seconds: 86400       # 24 hours\n  max_responses: 1000\n\n# vLLM Endpoints Configuration\nvllm_endpoints:\n  - name: \"test-endpoint\"\n    address: \"0.0.0.0\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-120b\":\n    use_reasoning: false\n    preferred_endpoints: [\"test-endpoint\"]\n\n# Minimal classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/lora_intent_classifier_bert-base-uncased_model\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/lora_intent_classifier_bert-base-uncased_model/category_mapping.json\"\n\ncategories:\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"default_decision\"\n    description: \"Default catch-all decision\"\n    priority: 1\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-120b\"\n        use_reasoning: false\n\ndefault_model: \"openai/gpt-oss-120b\"\n\n# Reasoning family configurations\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.643543"}
{"id": "real_config.testing_20", "source_file": "config/testing/config.testing.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\nvllm_endpoints:\n  - name: \"mock\"\n    address: \"172.28.0.10\"\n    port: 8000\n    weight: 1\n    health_check_path: \"/health\"\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"mock\"]\n\ncategories:\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n", "source": "real", "collected_at": "2026-01-06T10:23:38.666807"}
{"id": "real_bert_classification_7027", "source_file": "config/intelligent-routing/in-tree/bert_classification.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business and management related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\ndefault_model: qwen3\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:38.768377"}
{"id": "real_embedding_8723", "source_file": "config/intelligent-routing/in-tree/embedding.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Embedding-based classification rules\n# These rules use semantic similarity between query text and keywords\nembedding_rules:\n  - category: \"technical_support\"\n    threshold: 0.75\n    keywords:\n      - \"how to configure the system\"\n      - \"installation guide\"\n      - \"troubleshooting steps\"\n      - \"error message explanation\"\n      - \"setup instructions\"\n    aggregation_method: \"max\"  # Options: \"max\", \"avg\", \"any\"\n    model: \"auto\"  # Options: \"auto\", \"qwen3\", \"gemma\"\n    dimension: 768  # Options: 128, 256, 512, 768, 1024\n    quality_priority: 0.7  # 0.0-1.0, only for \"auto\" model\n    latency_priority: 0.3  # 0.0-1.0, only for \"auto\" model\n\n  - category: \"product_inquiry\"\n    threshold: 0.70\n    keywords:\n      - \"product features and specifications\"\n      - \"pricing information\"\n      - \"availability and stock\"\n      - \"product comparison\"\n      - \"warranty details\"\n    aggregation_method: \"avg\"\n    model: \"gemma\"\n    dimension: 768\n\n  - category: \"account_management\"\n    threshold: 0.72\n    keywords:\n      - \"password reset\"\n      - \"account settings\"\n      - \"profile update\"\n      - \"subscription management\"\n      - \"billing information\"\n    aggregation_method: \"max\"\n    model: \"qwen3\"\n    dimension: 1024\n\n  - category: \"general_inquiry\"\n    threshold: 0.65\n    keywords:\n      - \"general question\"\n      - \"information request\"\n      - \"help needed\"\n      - \"customer service\"\n    aggregation_method: \"any\"\n    model: \"auto\"\n    dimension: 512\n    quality_priority: 0.5\n    latency_priority: 0.5\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: technical_support\n    description: \"Technical support and troubleshooting queries\"\n    mmlu_categories: [\"technical_support\"]\n  - name: product_inquiry\n    description: \"Product information and specifications\"\n    mmlu_categories: [\"product_inquiry\"]\n  - name: account_management\n    description: \"Account and subscription management\"\n    mmlu_categories: [\"account_management\"]\n  - name: general_inquiry\n    description: \"General questions and information requests\"\n    mmlu_categories: [\"general_inquiry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"technical_support_decision\"\n    description: \"Technical support and troubleshooting queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"technical_support\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a technical support specialist. Provide detailed, step-by-step guidance for technical issues. Use clear explanations and include relevant troubleshooting steps.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"product_inquiry_decision\"\n    description: \"Product information and specifications\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"product_inquiry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a product specialist. Provide accurate information about products, features, pricing, and availability. Be helpful and informative.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n      - type: \"pii\"\n        configuration:\n          enabled: false\n          pii_types_allowed: []\n\n  - name: \"account_management_decision\"\n    description: \"Account and subscription management\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"account_management\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an account management assistant. Help users with account-related tasks such as password resets, profile updates, and subscription management. Prioritize security and privacy.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_inquiry_decision\"\n    description: \"General questions and information requests\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"general_inquiry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful general assistant. Answer questions clearly and concisely. If you need more information, ask clarifying questions.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n      - type: \"pii\"\n        configuration:\n          enabled: false\n          pii_types_allowed: []\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality, 1024-dim embeddings\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Default model for fallback\ndefault_model: \"qwen3\"\n\n# Entropy-based reasoning configuration\nentropy_threshold: 0.5  # Threshold for entropy-based reasoning decision\nhigh_entropy_threshold: 0.8  # High entropy threshold for complex queries\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.826037"}
{"id": "real_generic_categories_5372", "source_file": "config/intelligent-routing/in-tree/generic_categories.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with routing decisions", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "# Example: Using generic categories with MMLU-Pro mapping\n# This file demonstrates how to declare free-style categories and map them to\n# MMLU-Pro categories expected by the classifier model.\n\nbert_model:\n  model_id: sentence-transformers/all-MiniLM-L12-v2\n  threshold: 0.6\n  use_cpu: true\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n\n# Define your generic categories and map them to MMLU-Pro categories.\n# The classifier will translate predicted MMLU categories into these generic names.\n# Categories now only contain metadata - routing logic is defined in decisions below.\ncategories:\n  - name: tech\n    mmlu_categories: [\"computer science\", \"engineering\"]\n  - name: finance\n    mmlu_categories: [\"economics\"]\n  - name: politics  # If omitted, identity mapping applies when this name matches MMLU\n\n# Decisions define routing logic by combining rules and model selection\ndecisions:\n  - name: tech\n    description: \"Route technology-related queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"tech\"\n    modelRefs:\n      - model: phi4\n  - name: finance\n    description: \"Route finance and economics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"finance\"\n    modelRefs:\n      - model: gemma3:27b\n  - name: politics\n    description: \"Route politics-related queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"politics\"\n    modelRefs:\n      - model: gemma3:27b\n\n# A default model is recommended for fallback\ndefault_model: mistral-small3.1\n", "source": "real", "collected_at": "2026-01-06T10:23:38.840981"}
{"id": "real_keyword_4890", "source_file": "config/intelligent-routing/in-tree/keyword.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\nkeyword_rules:\n  - category: \"urgent_request\"\n    operator: \"OR\"\n    keywords: [\"urgent\", \"immediate\", \"asap\"]\n    case_sensitive: false\n  - category: \"sensitive_data\"\n    operator: \"AND\"\n    keywords: [\"SSN\", \"social security number\", \"credit card\"]\n    case_sensitive: false\n  - category: \"exclude_spam\"\n    operator: \"NOR\"\n    keywords: [\"buy now\", \"free money\"]\n    case_sensitive: false\n  - category: \"regex_pattern_match\"\n    operator: \"OR\"\n    keywords: [\"user\\\\.name@domain\\\\.com\", \"C:\\\\Program Files\\\\\\\\\"]  # Keywords are treated as regex\n    case_sensitive: false\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: urgent_request\n    description: \"Urgent and time-sensitive requests\"\n    mmlu_categories: [\"urgent_request\"]\n  - name: sensitive_data\n    description: \"Requests involving sensitive personal data\"\n    mmlu_categories: [\"sensitive_data\"]\n  - name: exclude_spam\n    description: \"Potential spam or suspicious requests\"\n    mmlu_categories: [\"exclude_spam\"]\n  - name: regex_pattern_match\n    description: \"Structured data and pattern-based requests\"\n    mmlu_categories: [\"regex_pattern_match\"]\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"urgent_request_decision\"\n    description: \"Urgent and time-sensitive requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"urgent_request\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a highly responsive assistant specialized in handling urgent requests. Prioritize speed and efficiency while maintaining accuracy. Provide concise, actionable responses and focus on immediate solutions.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"sensitive_data_decision\"\n    description: \"Requests involving sensitive personal data\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"sensitive_data\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a security-conscious assistant specialized in handling sensitive data. Exercise extreme caution with personal information, follow data protection best practices, and remind users about privacy considerations.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n          threshold: 0.6\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"exclude_spam_decision\"\n    description: \"Potential spam or suspicious requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"exclude_spam\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a content moderation assistant. This request has been flagged as potential spam. Please verify the legitimacy of the request before proceeding.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"regex_pattern_match_decision\"\n    description: \"Structured data and pattern-based requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"regex_pattern_match\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a technical assistant specialized in handling structured data and pattern-based requests. Provide precise, format-aware responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Standard category decisions (similar to config.yaml)\n  - name: \"business_decision\"\n    description: \"Business and management related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Add remaining standard decisions (law through engineering)\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\ndefault_model: qwen3\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:38.976970"}
{"id": "real_lora_routing_3300", "source_file": "config/intelligent-routing/in-tree/lora_routing.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with routing decisions", "use_case": "Configuration for unknown deployment", "complexity": "medium", "key_features": ["routing_decisions", "lora_routing"], "full_config": "# Example configuration for Intent-Aware LoRA Routing\n# This demonstrates how to use the lora_name field to route requests to different\n# LoRA adapters based on the classified intent/category.\n#\n# Prerequisites:\n# 1. vLLM server must be started with --enable-lora flag\n# 2. LoRA adapters must be registered at server startup using --lora-modules\n#    Example: vllm serve meta-llama/Llama-2-7b-hf \\\n#               --enable-lora \\\n#               --lora-modules technical-lora=/path/to/technical-adapter \\\n#                              medical-lora=/path/to/medical-adapter \\\n#                              legal-lora=/path/to/legal-adapter\n#\n# How it works:\n# - When a request is classified into a category (e.g., \"technical\")\n# - The router selects the best ModelScore for that category\n# - If the ModelScore has a lora_name specified, that name is used as the final model name\n# - The request is sent to vLLM with model=\"technical-lora\" instead of model=\"llama2-7b\"\n# - vLLM automatically routes to the appropriate LoRA adapter\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\n# vLLM Endpoints Configuration\nvllm_endpoints:\n  - name: \"vllm-primary\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\n# Base model configuration\n# IMPORTANT: LoRA adapters must be defined here before they can be referenced in model_scores\nmodel_config:\n  \"llama2-7b\":\n    reasoning_family: \"llama2\"\n    preferred_endpoints: [\"vllm-primary\"]\n    # Define available LoRA adapters for this model\n    # These names must match the LoRA modules registered with vLLM at startup\n    loras:\n      - name: \"technical-lora\"\n        description: \"Optimized for programming and technical questions\"\n      - name: \"medical-lora\"\n        description: \"Specialized for medical and healthcare domain\"\n      - name: \"legal-lora\"\n        description: \"Fine-tuned for legal questions and law-related topics\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n\n# Categories with LoRA routing\ncategories:\n  - name: technical\n    description: \"Programming, software engineering, and technical questions\"\n    mmlu_categories: [\"technical\"]\n  - name: medical\n    description: \"Medical and healthcare questions\"\n    mmlu_categories: [\"medical\"]\n  - name: legal\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"legal\"]\n  - name: general\n    description: \"General questions that don't fit specific domains\"\n    mmlu_categories: [\"general\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"technical_decision\"\n    description: \"Programming, software engineering, and technical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"technical\"\n    modelRefs:\n      - model: \"llama2-7b\"\n        lora_name: \"technical-lora\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an expert software engineer with deep knowledge of programming languages, algorithms, system design, and best practices. Provide clear, accurate technical guidance with code examples when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"medical_decision\"\n    description: \"Medical and healthcare questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"medical\"\n    modelRefs:\n      - model: \"llama2-7b\"\n        lora_name: \"medical-lora\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a medical expert with comprehensive knowledge of anatomy, physiology, diseases, treatments, and healthcare practices. Provide accurate medical information while emphasizing that responses are for educational purposes only and not a substitute for professional medical advice.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"legal_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"legal\"\n    modelRefs:\n      - model: \"llama2-7b\"\n        lora_name: \"legal-lora\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a legal expert with knowledge of legal principles, case law, and statutory interpretation. Provide accurate legal information while clearly stating that responses are for informational purposes only and do not constitute legal advice.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General questions that don't fit specific domains\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"general\"\n    modelRefs:\n      - model: \"llama2-7b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful AI assistant with broad knowledge across many topics. Provide clear, accurate, and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n# Default model for fallback\ndefault_model: llama2-7b\n\n# Benefits of LoRA Routing:\n# 1. Domain-Specific Expertise: Each LoRA adapter is fine-tuned for specific domains\n# 2. Cost Efficiency: Share base model weights across adapters, reducing memory footprint\n# 3. Easy A/B Testing: Gradually roll out new adapters by adjusting scores\n# 4. Flexible Deployment: Add/remove adapters without restarting the router\n# 5. Performance: vLLM efficiently serves multiple LoRA adapters with minimal overhead\n#\n# Use Cases:\n# - Multi-domain chatbots (technical support, medical advice, legal information)\n# - Task-specific optimization (code generation, summarization, translation)\n# - Language-specific adapters for multilingual systems\n# - Customer-specific adapters for personalized experiences\n# - Version testing (compare different adapter versions)\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.998325"}
{"id": "real_config-mcp-classifier_8962", "source_file": "config/intelligent-routing/out-tree/config-mcp-classifier.yaml", "category": "main", "deployment_context": "unknown", "intent": "Basic configuration", "use_case": "Configuration for unknown deployment", "complexity": "medium", "key_features": ["tools", "observability"], "full_config": "# Example Configuration for MCP-Based Category Classifier (HTTP Transport)\n#\n# This configuration demonstrates how to use an external MCP (Model Context Protocol)\n# service via HTTP for category classification instead of the built-in Candle/ModernBERT models.\n#\n# Use cases:\n# - Offload classification to a remote HTTP service\n# - Use custom classification models not supported in-tree\n# - Scale classification independently from the router\n# - Integrate with existing ML infrastructure via REST API\n#\n# Note: This example uses HTTP transport. The MCP server should expose an HTTP endpoint\n# that implements the MCP protocol (e.g., http://localhost:8080/mcp)\n\n# BERT model for semantic caching and tool selection\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.85\n  use_cpu: true\n\n# Classifier configuration\nclassifier:\n  # Disable in-tree category classifier (leave model_id empty)\n  category_model:\n    model_id: \"\"  # Empty = disabled\n\n  # Enable MCP-based category classifier (HTTP transport only)\n  mcp_category_model:\n    enabled: true  # Enable MCP classifier\n    transport_type: \"http\"  # HTTP transport\n    url: \"http://localhost:8090/mcp\"  # MCP server endpoint\n\n    # tool_name: Optional - auto-discovers classification tool if not specified\n    # Will search for tools like: classify_text, classify, categorize, etc.\n    # Uncomment to explicitly specify:\n    # tool_name: \"classify_text\"\n\n    threshold: 0.6  # Confidence threshold\n    timeout_seconds: 30  # Request timeout\n\n# Categories for routing queries\n#\n# Categories are automatically loaded from MCP server via 'list_categories' tool.\n# The MCP server controls BOTH classification AND routing decisions.\n#\n# How it works:\n#   1. Router connects to MCP server at startup\n#   2. Calls 'list_categories' tool and MCP returns:\n#      {\n#        \"categories\": [\"math\", \"science\", \"technology\", \"history\", \"general\"],\n#        \"category_system_prompts\": {\n#          \"math\": \"You are a mathematics expert. When answering math questions...\",\n#          \"science\": \"You are a science expert. When answering science questions...\",\n#          \"technology\": \"You are a technology expert...\"\n#        },\n#        \"category_descriptions\": {\n#          \"math\": \"Mathematical and computational queries\",\n#          \"science\": \"Scientific concepts and queries\"\n#        }\n#      }\n#   3. For each request, calls 'classify_text' tool which returns:\n#      {\n#        \"class\": 3,\n#        \"confidence\": 0.85,\n#        \"model\": \"openai/gpt-oss-20b\",        # MCP decides which model to use\n#        \"use_reasoning\": true                  # MCP decides whether to use reasoning\n#      }\n#   4. Router uses the model and reasoning settings from MCP response\n#\n# PER-CATEGORY SYSTEM PROMPT INJECTION:\n#   - The MCP server provides SEPARATE system prompts for EACH category\n#   - Each category gets its own specialized instructions and context\n#   - The router stores these prompts and injects the appropriate one per query\n#   - Use classifier.GetCategorySystemPrompt(categoryName) to retrieve for a specific category\n#   - Examples:\n#       * Math category: \"You are a mathematics expert. Show step-by-step solutions...\"\n#       * Science category: \"You are a science expert. Provide evidence-based answers...\"\n#       * Technology category: \"You are a tech expert. Include practical code examples...\"\n#   - This allows domain-specific expertise per category\n#\n# BENEFITS:\n#   - MCP server makes intelligent routing decisions per query\n#   - No hardcoded routing rules needed in config\n#   - MCP can adapt routing based on query complexity, content, etc.\n#   - Centralized routing logic and per-category system prompts in MCP server\n#   - Category descriptions available for logging and debugging\n#   - Domain-specific LLM behavior for each category\n#\n# FALLBACK:\n#   - If MCP doesn't return model/use_reasoning, uses default_model below\n#   - If MCP doesn't return category_system_prompts, router can use default prompts\n#   - Can also add category-specific overrides here if needed\n#\ncategories: []\n\n# Default model to use when category can't be determined\ndefault_model: openai/gpt-oss-20b\n\n# vLLM endpoints configuration\nvllm_endpoints:\n  - name: endpoint1\n    address: 127.0.0.1\n    port: 8000\n    weight: 1\n    health_check_path: /health\n\n# Model-specific configuration\nmodel_config:\n  openai/gpt-oss-20b:\n    reasoning_family: gpt-oss\n    preferred_endpoints:\n      - endpoint1\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: chat_template_kwargs\n    parameter: thinking\n  qwen3:\n    type: chat_template_kwargs\n    parameter: enable_thinking\n  gpt-oss:\n    type: reasoning_effort\n    parameter: reasoning_effort\n  gpt:\n    type: reasoning_effort\n    parameter: reasoning_effort\n\n# Default reasoning effort level\ndefault_reasoning_effort: high\n\n# Tools configuration (optional)\ntools:\n  enabled: false\n  top_k: 5\n  similarity_threshold: 0.7\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\n# API configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        - 0.001\n        - 0.005\n        - 0.01\n        - 0.025\n        - 0.05\n        - 0.1\n        - 0.25\n        - 0.5\n        - 1\n        - 2.5\n        - 5\n        - 10\n        - 30\n      size_buckets:\n        - 1\n        - 2\n        - 5\n        - 10\n        - 20\n        - 50\n        - 100\n        - 200\n\n# Observability configuration\nobservability:\n  tracing:\n    enabled: false\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"localhost:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n    resource:\n      service_name: \"semantic-router\"\n      service_version: \"1.0.0\"\n      deployment_environment: \"production\"\n\n", "source": "real", "collected_at": "2026-01-06T10:23:39.013232"}
{"id": "real_config-with-embedding_5827", "source_file": "e2e/profiles/routing-strategies/config-with-embedding.yaml", "category": "e2e", "deployment_context": "routing-strategies", "intent": "Configuration routing-strategies deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for routing-strategies deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "# Extended configuration for routing-strategies profile with embedding rules\n# This config enables all routing methods: Keyword \u2192 Embedding \u2192 BERT \u2192 MCP\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true\n  use_modernbert: false  # MoM uses LoRA-based model\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint1\"]\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Keyword rules - Priority 1 (highest)\nkeyword_rules:\n  - name: \"urgent_request\"\n    operator: \"OR\"\n    keywords: [\"urgent\", \"immediate\", \"asap\", \"emergency\"]\n    case_sensitive: false\n  - name: \"sensitive_data\"\n    operator: \"AND\"\n    keywords: [\"SSN\", \"social security number\", \"credit card\"]\n    case_sensitive: false\n  - name: \"exclude_spam\"\n    operator: \"NOR\"\n    keywords: [\"buy now\", \"free money\"]\n    case_sensitive: false\n  - name: \"regex_pattern_match\"\n    operator: \"OR\"\n    keywords: [\"user\\\\.name@domain\\\\.com\", \"C:\\\\Program Files\\\\\\\\\"]\n    case_sensitive: false\n\n# Embedding rules - Priority 2 (after keyword)\n# These use semantic similarity to match queries to predefined candidates\nembedding_rules:\n  - name: \"ai\"\n    threshold: 0.75\n    candidates:\n      - \"artificial intelligence\"\n      - \"machine learning\"\n      - \"deep learning\"\n      - \"neural networks\"\n      - \"AI algorithms\"\n    aggregation_method: \"max\"  # Use maximum similarity score\n    model: \"auto\"  # Auto-select best embedding model\n  - name: \"data_science\"\n    threshold: 0.70\n    candidates:\n      - \"data analysis\"\n      - \"statistical modeling\"\n      - \"predictive analytics\"\n      - \"data visualization\"\n    aggregation_method: \"mean\"\n    model: \"auto\"\n  - name: \"programming\"\n    threshold: 0.72\n    candidates:\n      - \"write code\"\n      - \"implement function\"\n      - \"create class\"\n      - \"code snippet\"\n      - \"programming task\"\n    aggregation_method: \"max\"\n    model: \"auto\"\n\n# Categories - Used by BERT classifier (Priority 3)\ncategories:\n  # Keyword-based categories (for decision matching)\n  - name: urgent_request\n    description: \"Urgent and time-sensitive requests\"\n    mmlu_categories: [\"urgent_request\"]\n  - name: sensitive_data\n    description: \"Requests involving sensitive personal data\"\n    mmlu_categories: [\"sensitive_data\"]\n  - name: exclude_spam\n    description: \"Potential spam or suspicious requests\"\n    mmlu_categories: [\"exclude_spam\"]\n  - name: regex_pattern_match\n    description: \"Structured data and pattern-based requests\"\n    mmlu_categories: [\"regex_pattern_match\"]\n\n  # Embedding-based categories (for decision matching)\n  - name: ai\n    description: \"Artificial intelligence and machine learning topics\"\n    mmlu_categories: [\"ai\", \"machine_learning\"]\n  - name: data_science\n    description: \"Data science and analytics\"\n    mmlu_categories: [\"data_science\"]\n  - name: programming\n    description: \"Programming and software development\"\n    mmlu_categories: [\"programming\"]\n\n  # BERT/Domain categories (for BERT classification)\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\n# Decisions define routing logic\n# Priority order: Keyword (150) > Embedding (140) > Domain/BERT (100) > Default (50)\ndecisions:\n  # === KEYWORD-BASED DECISIONS (Priority 150) ===\n  - name: \"urgent_request_decision\"\n    description: \"Urgent and time-sensitive requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"urgent_request\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a highly responsive assistant specialized in handling urgent requests. Prioritize speed and efficiency while maintaining accuracy.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"sensitive_data_decision\"\n    description: \"Requests involving sensitive personal data\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"sensitive_data\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a security-conscious assistant specialized in handling sensitive data. Exercise extreme caution with personal information.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n          threshold: 0.6\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"exclude_spam_decision\"\n    description: \"Potential spam or suspicious requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"exclude_spam\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a content moderation assistant. This request has been flagged as potential spam.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"regex_pattern_match_decision\"\n    description: \"Structured data and pattern-based requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"regex_pattern_match\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a technical assistant specialized in handling structured data and pattern-based requests.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # === EMBEDDING-BASED DECISIONS (Priority 140) ===\n  - name: \"ai_decision\"\n    description: \"Artificial intelligence and machine learning topics\"\n    priority: 140\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"embedding\"\n          name: \"ai\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an AI and machine learning expert. Provide detailed, technical explanations about artificial intelligence, neural networks, and related topics.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"data_science_decision\"\n    description: \"Data science and analytics\"\n    priority: 140\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"embedding\"\n          name: \"data_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a data science expert. Provide insights on data analysis, statistical methods, and predictive modeling.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"programming_decision\"\n    description: \"Programming and software development\"\n    priority: 140\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"embedding\"\n          name: \"programming\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a programming expert. Help with code implementation, debugging, and software development best practices.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # === DOMAIN/BERT DECISIONS (Priority 100) ===\n  - name: \"business_decision\"\n    description: \"Business and management related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # ... Continue with all other domain decisions (law, psychology, biology, etc.)\n  # Each with priority: 100 and type: \"domain\"\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # === DEFAULT FALLBACK (Priority 50) ===\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\ndefault_model: qwen3\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\n# Embedding Models Configuration\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  # gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.074327"}
{"id": "real_config_1419", "source_file": "e2e/profiles/routing-strategies/config.yaml", "category": "e2e", "deployment_context": "routing-strategies", "intent": "Configuration routing-strategies deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for routing-strategies deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false  # MoM uses LoRA-based model\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false  # MoM uses LoRA-based model\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    use_modernbert: false  # MoM uses LoRA-based model\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\nkeyword_rules:\n  - name: \"urgent_request\"\n    operator: \"OR\"\n    keywords: [\"urgent\", \"immediate\", \"asap\", \"emergency\"]\n    case_sensitive: false\n  - name: \"sensitive_data\"\n    operator: \"AND\"\n    keywords: [\"SSN\", \"social security number\", \"credit card\"]\n    case_sensitive: false\n  - name: \"exclude_spam\"\n    operator: \"NOR\"\n    keywords: [\"buy now\", \"free money\"]\n    case_sensitive: false\n  - name: \"regex_pattern_match\"\n    operator: \"OR\"\n    keywords: [\"user\\\\.name@domain\\\\.com\", \"C:\\\\Program Files\\\\\\\\\"]  # Keywords are treated as regex\n    case_sensitive: false\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: urgent_request\n    description: \"Urgent and time-sensitive requests\"\n    mmlu_categories: [\"urgent_request\"]\n  - name: sensitive_data\n    description: \"Requests involving sensitive personal data\"\n    mmlu_categories: [\"sensitive_data\"]\n  - name: exclude_spam\n    description: \"Potential spam or suspicious requests\"\n    mmlu_categories: [\"exclude_spam\"]\n  - name: regex_pattern_match\n    description: \"Structured data and pattern-based requests\"\n    mmlu_categories: [\"regex_pattern_match\"]\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"urgent_request_decision\"\n    description: \"Urgent and time-sensitive requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"urgent_request\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a highly responsive assistant specialized in handling urgent requests. Prioritize speed and efficiency while maintaining accuracy. Provide concise, actionable responses and focus on immediate solutions.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"sensitive_data_decision\"\n    description: \"Requests involving sensitive personal data\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"sensitive_data\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a security-conscious assistant specialized in handling sensitive data. Exercise extreme caution with personal information, follow data protection best practices, and remind users about privacy considerations.\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n          threshold: 0.6\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"exclude_spam_decision\"\n    description: \"Potential spam or suspicious requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"exclude_spam\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a content moderation assistant. This request has been flagged as potential spam. Please verify the legitimacy of the request before proceeding.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"regex_pattern_match_decision\"\n    description: \"Structured data and pattern-based requests\"\n    priority: 150\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"keyword\"\n          name: \"regex_pattern_match\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a technical assistant specialized in handling structured data and pattern-based requests. Provide precise, format-aware responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Standard category decisions (similar to config.yaml)\n  - name: \"business_decision\"\n    description: \"Business and management related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  # Add remaining standard decisions (law through engineering)\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\ndefault_model: qwen3\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - mom-embedding-pro: Up to 32K context, high quality (Qwen3-Embedding-0.6B)\n# - mom-embedding-flash: Up to 8K context, fast inference, Matryoshka support (EmbeddingGemma-300M)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  # gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.159333"}
{"id": "real_prometheus-config_7779", "source_file": "e2e/profiles/production-stack/prometheus-config.yaml", "category": "e2e", "deployment_context": "production-stack", "intent": "Configuration production-stack deployment", "use_case": "Configuration for production-stack deployment", "complexity": "low", "key_features": [], "full_config": "global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: prometheus\n    static_configs:\n      - targets:\n          - localhost:9090\n\n  - job_name: semantic-router\n    kubernetes_sd_configs:\n      - role: endpoints\n        namespaces:\n          names:\n            - vllm-semantic-router-system\n            - default\n    relabel_configs:\n      - source_labels: [__meta_kubernetes_service_name]\n        regex: semantic-router-metrics\n        action: keep\n      - source_labels: [__meta_kubernetes_endpoint_port_name]\n        regex: metrics\n        action: keep\n      - source_labels: [__meta_kubernetes_namespace]\n        target_label: namespace\n      - source_labels: [__address__]\n        target_label: instance\n\n  - job_name: kubernetes-pods\n    kubernetes_sd_configs:\n      - role: pod\n        namespaces:\n          names:\n            - default\n            - vllm-semantic-router-system\n\n  - job_name: kubernetes-nodes\n    kubernetes_sd_configs:\n      - role: node\n    scheme: https\n    tls_config:\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n      insecure_skip_verify: true\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n    relabel_configs:\n      - action: labelmap\n        regex: __meta_kubernetes_node_label_(.+)\n      - target_label: __address__\n        replacement: kubernetes.default.svc:443\n      - source_labels: [__meta_kubernetes_node_name]\n        regex: (.+)\n        target_label: __metrics_path__\n        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor\n\n", "source": "real", "collected_at": "2026-01-06T10:23:39.166383"}
{"id": "real_intelligentroute_5958", "source_file": "e2e/profiles/dynamic-config/crds/intelligentroute.yaml", "category": "e2e", "deployment_context": "dynamic-config", "intent": "Configuration dynamic-config deployment, with routing decisions", "use_case": "Configuration for dynamic-config deployment", "complexity": "medium", "key_features": ["routing_decisions", "lora_routing"], "full_config": "apiVersion: vllm.ai/v1alpha1\nkind: IntelligentRoute\nmetadata:\n  name: ai-gateway-route\n  namespace: default\nspec:\n  signals:\n    # EmbeddingSignal configurations for semantic similarity routing\n    embeddings:\n      # PII Detection Signal\n      # Candidate patterns based on CRD test examples (testdata/input/10-embedding-plugin.yaml)\n      - name: \"pii_detected\"\n        threshold: 0.75\n        aggregationMethod: \"max\"\n        candidates:\n          - \"I need to share my personal information\"\n          - \"Here is my credit card number\"\n          - \"My social security number is\"\n          - \"Contact me at my email\"\n          - \"You can reach me at\"\n          - \"My phone number is\"\n          - \"Let me provide my details\"\n\n      # Security Threat Detection Signal\n      # Patterns for detecting malicious intent or security threats\n      - name: \"security_threat\"\n        threshold: 0.75\n        aggregationMethod: \"any\"\n        candidates:\n          # Attack intent patterns\n          - \"I want to bypass authentication\"\n          - \"How can I gain unauthorized access\"\n          - \"Help me with SQL injection\"\n          - \"I need to escalate privileges\"\n          - \"Show me how to hack\"\n          - \"Can you help me break in\"\n\n      # Kubernetes Technical Topic Signal\n      - name: \"kubernetes_topic\"\n        threshold: 0.70\n        aggregationMethod: \"max\"\n        candidates:\n          - \"kubernetes deployment\"\n          - \"container orchestration\"\n          - \"k8s cluster management\"\n          - \"pod configuration\"\n          - \"helm charts\"\n          - \"kubernetes troubleshooting\"\n          - \"kubectl commands\"\n\n    domains:\n      - name: \"business\"\n        description: \"Business and management related queries\"\n      - name: \"law\"\n        description: \"Legal questions and law-related topics\"\n      - name: \"psychology\"\n        description: \"Psychology and mental health topics\"\n      - name: \"biology\"\n        description: \"Biology and life sciences questions\"\n      - name: \"chemistry\"\n        description: \"Chemistry and chemical sciences questions\"\n      - name: \"history\"\n        description: \"Historical questions and cultural topics\"\n      - name: \"health\"\n        description: \"Health and medical information queries\"\n      - name: \"economics\"\n        description: \"Economics and financial topics\"\n      - name: \"math\"\n        description: \"Mathematics and quantitative reasoning\"\n      - name: \"physics\"\n        description: \"Physics and physical sciences\"\n      - name: \"computer science\"\n        description: \"Computer science and programming\"\n      - name: \"philosophy\"\n        description: \"Philosophy and ethical questions\"\n      - name: \"engineering\"\n        description: \"Engineering and technical problem-solving\"\n      - name: \"other\"\n        description: \"General knowledge and miscellaneous topics\"\n\n    keywords:\n      - name: \"thinking\"\n        operator: \"OR\"\n        keywords: [\"urgent\", \"immediate\", \"asap\", \"think\", \"careful\"]\n        caseSensitive: false\n\n  decisions:\n    # === HIGH PRIORITY EMBEDDING-BASED DECISIONS ===\n    # Block PII (highest priority)\n    - name: \"block_pii\"\n      priority: 100\n      description: \"Block requests containing PII\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"embedding\"\n            name: \"pii_detected\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"general-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"header_mutation\"\n          configuration:\n            add:\n              - name: \"x-vsr-pii-violation\"\n                value: \"true\"\n              - name: \"x-vsr-signal-pii_detected\"\n                value: \"true\"\n\n    # Block Security Threats\n    - name: \"block_security\"\n      priority: 95\n      description: \"Block security threats and malicious requests\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"embedding\"\n            name: \"security_threat\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"general-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"header_mutation\"\n          configuration:\n            add:\n              - name: \"x-vsr-security-violation\"\n                value: \"true\"\n              - name: \"x-vsr-signal-security_threat\"\n                value: \"true\"\n\n    # Route to Kubernetes Expert\n    - name: \"kubernetes_expert\"\n      priority: 90\n      description: \"Route Kubernetes questions to specialist\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"embedding\"\n            name: \"kubernetes_topic\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"general-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"header_mutation\"\n          configuration:\n            add:\n              - name: \"x-vsr-signal-kubernetes_topic\"\n                value: \"true\"\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a Kubernetes expert. Provide detailed technical guidance for K8s operations.\"\n            mode: \"replace\"\n\n\n    # === KEYWORD-BASED DECISIONS ===\n    - name: \"thinking_decision\"\n      priority: 15\n      description: \"Queries requiring careful thought or urgent attention\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"keyword\"\n            name: \"thinking\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"math-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a thoughtful assistant trained to approach problems systematically. When handling urgent matters or complex questions, break down the problem into clear steps, consider multiple angles, and provide thorough, well-reasoned responses. Take your time to think through implications and edge cases.\"\n            mode: \"replace\"\n\n    - name: \"business_decision\"\n      priority: 10\n      description: \"Business and management related queries\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"business\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"social-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n            mode: \"replace\"\n\n    - name: \"law_decision\"\n      priority: 10\n      description: \"Legal questions and law-related topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"law\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"law-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n            mode: \"replace\"\n\n    - name: \"psychology_decision\"\n      priority: 10\n      description: \"Psychology and mental health topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"psychology\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"humanities-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"semantic-cache\"\n          configuration:\n            enabled: true\n            similarity_threshold: 0.92\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n            mode: \"replace\"\n\n    - name: \"biology_decision\"\n      priority: 10\n      description: \"Biology and life sciences questions\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"biology\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed:\n              - \"ORGANIZATION\"  # Allow - scientific terms like \"photosynthesis\" falsely detected as ORG\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n            mode: \"replace\"\n\n    - name: \"chemistry_decision\"\n      priority: 10\n      description: \"Chemistry and chemical sciences questions\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"chemistry\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n            mode: \"replace\"\n\n    - name: \"history_decision\"\n      priority: 10\n      description: \"Historical questions and cultural topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"history\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"humanities-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n            mode: \"replace\"\n\n    - name: \"health_decision\"\n      priority: 10\n      description: \"Health and medical information queries\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"health\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"semantic-cache\"\n          configuration:\n            enabled: true\n            similarity_threshold: 0.95\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n            mode: \"replace\"\n\n    - name: \"economics_decision\"\n      priority: 10\n      description: \"Economics and financial topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"economics\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"social-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n            mode: \"replace\"\n\n    - name: \"math_decision\"\n      priority: 10\n      description: \"Mathematics and quantitative reasoning\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"math\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"math-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n            mode: \"replace\"\n\n    - name: \"physics_decision\"\n      priority: 10\n      description: \"Physics and physical sciences\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"physics\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n            mode: \"replace\"\n\n    - name: \"computer_science_decision\"\n      priority: 10\n      description: \"Computer science and programming\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"computer science\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n            mode: \"replace\"\n\n    - name: \"philosophy_decision\"\n      priority: 10\n      description: \"Philosophy and ethical questions\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"philosophy\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"humanities-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n            mode: \"replace\"\n\n    - name: \"engineering_decision\"\n      priority: 10\n      description: \"Engineering and technical problem-solving\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"engineering\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n            mode: \"replace\"\n\n    - name: \"other_decision\"\n      priority: 1\n      description: \"General knowledge and miscellaneous topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"other\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed:\n              - \"GPE\"  # Allow - country/city names like \"France\" in general knowledge questions\n        - type: \"semantic-cache\"\n          configuration:\n            enabled: true\n            similarity_threshold: 0.75\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a knowledgeable AI assistant with broad expertise across many domains. Provide accurate, helpful, and well-structured responses to general questions. When uncertain, acknowledge limitations and suggest where to find authoritative information.\"\n            mode: \"replace\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.235584"}
{"id": "real_vllm.ai_intelligentroutes_8714", "source_file": "deploy/kubernetes/crds/vllm.ai_intelligentroutes.yaml", "category": "deploy", "deployment_context": "unknown", "intent": "Configuration with routing decisions", "use_case": "Configuration for unknown deployment", "complexity": "medium", "key_features": ["jailbreak_detection", "routing_decisions", "lora_routing"], "full_config": "---\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  annotations:\n    controller-gen.kubebuilder.io/version: v0.19.0\n  name: intelligentroutes.vllm.ai\nspec:\n  group: vllm.ai\n  names:\n    kind: IntelligentRoute\n    listKind: IntelligentRouteList\n    plural: intelligentroutes\n    shortNames:\n    - iroute\n    singular: intelligentroute\n  scope: Namespaced\n  versions:\n  - additionalPrinterColumns:\n    - description: Number of decisions\n      jsonPath: .status.statistics.decisions\n      name: Decisions\n      type: integer\n    - description: Number of keyword signals\n      jsonPath: .status.statistics.keywords\n      name: Keywords\n      type: integer\n    - description: Number of embedding signals\n      jsonPath: .status.statistics.embeddings\n      name: Embeddings\n      type: integer\n    - description: Number of domain signals\n      jsonPath: .status.statistics.domains\n      name: Domains\n      type: integer\n    - description: Ready status\n      jsonPath: .status.conditions[?(@.type=='Ready')].status\n      name: Status\n      type: string\n    - jsonPath: .metadata.creationTimestamp\n      name: Age\n      type: date\n    name: v1alpha1\n    schema:\n      openAPIV3Schema:\n        description: IntelligentRoute defines intelligent routing rules and decisions\n        properties:\n          apiVersion:\n            description: |-\n              APIVersion defines the versioned schema of this representation of an object.\n              Servers should convert recognized schemas to the latest internal value, and\n              may reject unrecognized values.\n              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n            type: string\n          kind:\n            description: |-\n              Kind is a string value representing the REST resource this object represents.\n              Servers may infer this from the endpoint the client submits requests to.\n              Cannot be updated.\n              In CamelCase.\n              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n            type: string\n          metadata:\n            type: object\n          spec:\n            description: IntelligentRouteSpec defines the desired state of IntelligentRoute\n            properties:\n              decisions:\n                description: Decisions defines the routing decisions based on signal\n                  combinations\n                items:\n                  description: Decision defines a routing decision based on rule combinations\n                  properties:\n                    description:\n                      description: Description provides a human-readable description\n                        of this decision\n                      maxLength: 500\n                      type: string\n                    modelRefs:\n                      description: ModelRefs defines the model references for this\n                        decision (currently only one model is supported)\n                      items:\n                        description: ModelRef defines a model reference without score\n                        properties:\n                          loraName:\n                            description: LoRAName is the name of the LoRA adapter\n                              to use (must exist in the model's LoRAs)\n                            maxLength: 100\n                            type: string\n                          model:\n                            description: Model is the name of the model (must exist\n                              in IntelligentPool)\n                            maxLength: 100\n                            minLength: 1\n                            type: string\n                          reasoningDescription:\n                            description: ReasoningDescription provides context for\n                              when to use reasoning\n                            maxLength: 500\n                            type: string\n                          reasoningEffort:\n                            description: ReasoningEffort defines the reasoning effort\n                              level (low/medium/high)\n                            enum:\n                            - low\n                            - medium\n                            - high\n                            type: string\n                          useReasoning:\n                            default: false\n                            description: UseReasoning specifies whether to enable\n                              reasoning mode for this model\n                            type: boolean\n                        required:\n                        - model\n                        type: object\n                      maxItems: 1\n                      minItems: 1\n                      type: array\n                    name:\n                      description: Name is the unique identifier for this decision\n                      maxLength: 100\n                      minLength: 1\n                      type: string\n                    plugins:\n                      description: Plugins defines the plugins to apply for this decision\n                      items:\n                        description: DecisionPlugin defines a plugin configuration\n                          for a decision\n                        properties:\n                          configuration:\n                            description: Configuration is the plugin-specific configuration\n                              as a raw JSON object\n                            x-kubernetes-preserve-unknown-fields: true\n                          type:\n                            description: Type is the plugin type (semantic-cache,\n                              jailbreak, pii, system_prompt, header_mutation)\n                            enum:\n                            - semantic-cache\n                            - jailbreak\n                            - pii\n                            - system_prompt\n                            - header_mutation\n                            type: string\n                        required:\n                        - type\n                        type: object\n                      maxItems: 10\n                      type: array\n                    priority:\n                      default: 0\n                      description: |-\n                        Priority defines the priority of this decision (higher values = higher priority)\n                        Used when strategy is \"priority\"\n                      format: int32\n                      maximum: 1000\n                      minimum: 0\n                      type: integer\n                    signals:\n                      description: Signals defines the signal combination logic\n                      properties:\n                        conditions:\n                          description: Conditions defines the list of signal conditions\n                          items:\n                            description: SignalCondition defines a single signal condition\n                            properties:\n                              name:\n                                description: Name is the name of the signal to reference\n                                maxLength: 100\n                                minLength: 1\n                                type: string\n                              type:\n                                description: Type defines the type of signal (keyword/embedding/domain)\n                                enum:\n                                - keyword\n                                - embedding\n                                - domain\n                                type: string\n                            required:\n                            - name\n                            - type\n                            type: object\n                          maxItems: 50\n                          minItems: 1\n                          type: array\n                        operator:\n                          description: Operator defines the logical operator for combining\n                            conditions (AND/OR)\n                          enum:\n                          - AND\n                          - OR\n                          type: string\n                      required:\n                      - conditions\n                      - operator\n                      type: object\n                  required:\n                  - modelRefs\n                  - name\n                  - signals\n                  type: object\n                maxItems: 100\n                minItems: 1\n                type: array\n              signals:\n                description: Signals defines signal extraction rules for routing decisions\n                properties:\n                  domains:\n                    description: Domains defines MMLU domain categories for classification\n                    items:\n                      description: DomainSignal defines a domain category for classification\n                      properties:\n                        description:\n                          description: Description provides a human-readable description\n                            of this domain\n                          maxLength: 500\n                          type: string\n                        name:\n                          description: Name is the unique identifier for this domain\n                          maxLength: 100\n                          minLength: 1\n                          type: string\n                      required:\n                      - name\n                      type: object\n                    maxItems: 14\n                    type: array\n                  embeddings:\n                    description: Embeddings defines embedding-based signal extraction\n                      rules\n                    items:\n                      description: EmbeddingSignal defines an embedding-based signal\n                        extraction rule\n                      properties:\n                        aggregationMethod:\n                          default: max\n                          description: AggregationMethod defines how to aggregate\n                            multiple candidate similarities\n                          enum:\n                          - mean\n                          - max\n                          - any\n                          type: string\n                        candidates:\n                          description: Candidates is the list of candidate phrases\n                            for semantic matching\n                          items:\n                            type: string\n                          maxItems: 100\n                          minItems: 1\n                          type: array\n                        name:\n                          description: Name is the unique identifier for this signal\n                          maxLength: 100\n                          minLength: 1\n                          type: string\n                        threshold:\n                          description: Threshold is the similarity threshold for matching\n                            (0.0-1.0)\n                          maximum: 1\n                          minimum: 0\n                          type: number\n                      required:\n                      - candidates\n                      - name\n                      - threshold\n                      type: object\n                    maxItems: 100\n                    type: array\n                  keywords:\n                    description: Keywords defines keyword-based signal extraction\n                      rules\n                    items:\n                      description: KeywordSignal defines a keyword-based signal extraction\n                        rule\n                      properties:\n                        caseSensitive:\n                          default: false\n                          description: CaseSensitive specifies whether keyword matching\n                            is case-sensitive\n                          type: boolean\n                        keywords:\n                          description: Keywords is the list of keywords to match\n                          items:\n                            type: string\n                          maxItems: 100\n                          minItems: 1\n                          type: array\n                        name:\n                          description: Name is the unique identifier for this rule\n                            (also used as category name)\n                          maxLength: 100\n                          minLength: 1\n                          type: string\n                        operator:\n                          description: Operator defines the logical operator for keywords\n                            (AND/OR)\n                          enum:\n                          - AND\n                          - OR\n                          type: string\n                      required:\n                      - keywords\n                      - name\n                      - operator\n                      type: object\n                    maxItems: 100\n                    type: array\n                type: object\n            required:\n            - decisions\n            type: object\n          status:\n            description: IntelligentRouteStatus defines the observed state of IntelligentRoute\n            properties:\n              conditions:\n                description: Conditions represent the latest available observations\n                  of the IntelligentRoute's state\n                items:\n                  description: Condition contains details for one aspect of the current\n                    state of this API Resource.\n                  properties:\n                    lastTransitionTime:\n                      description: |-\n                        lastTransitionTime is the last time the condition transitioned from one status to another.\n                        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.\n                      format: date-time\n                      type: string\n                    message:\n                      description: |-\n                        message is a human readable message indicating details about the transition.\n                        This may be an empty string.\n                      maxLength: 32768\n                      type: string\n                    observedGeneration:\n                      description: |-\n                        observedGeneration represents the .metadata.generation that the condition was set based upon.\n                        For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date\n                        with respect to the current state of the instance.\n                      format: int64\n                      minimum: 0\n                      type: integer\n                    reason:\n                      description: |-\n                        reason contains a programmatic identifier indicating the reason for the condition's last transition.\n                        Producers of specific condition types may define expected values and meanings for this field,\n                        and whether the values are considered a guaranteed API.\n                        The value should be a CamelCase string.\n                        This field may not be empty.\n                      maxLength: 1024\n                      minLength: 1\n                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$\n                      type: string\n                    status:\n                      description: status of the condition, one of True, False, Unknown.\n                      enum:\n                      - \"True\"\n                      - \"False\"\n                      - Unknown\n                      type: string\n                    type:\n                      description: type of condition in CamelCase or in foo.example.com/CamelCase.\n                      maxLength: 316\n                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$\n                      type: string\n                  required:\n                  - lastTransitionTime\n                  - message\n                  - reason\n                  - status\n                  - type\n                  type: object\n                type: array\n              observedGeneration:\n                description: ObservedGeneration reflects the generation of the most\n                  recently observed IntelligentRoute\n                format: int64\n                type: integer\n              statistics:\n                description: Statistics provides statistics about configured decisions\n                  and signals\n                properties:\n                  decisions:\n                    description: Decisions indicates the number of decisions\n                    format: int32\n                    type: integer\n                  domains:\n                    description: Domains indicates the number of domain signals\n                    format: int32\n                    type: integer\n                  embeddings:\n                    description: Embeddings indicates the number of embedding signals\n                    format: int32\n                    type: integer\n                  keywords:\n                    description: Keywords indicates the number of keyword signals\n                    format: int32\n                    type: integer\n                required:\n                - decisions\n                - domains\n                - embeddings\n                - keywords\n                type: object\n            type: object\n        type: object\n    served: true\n    storage: true\n    subresources:\n      status: {}\n", "source": "real", "collected_at": "2026-01-06T10:23:39.286329"}
{"id": "real_destinationrule_5435", "source_file": "deploy/kubernetes/istio/destinationrule.yaml", "category": "deploy", "deployment_context": "istio", "intent": "Configuration istio deployment", "use_case": "Configuration for istio deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: networking.istio.io/v1\nkind: DestinationRule\nmetadata:\n  name: semantic-router\n  namespace: default\nspec:\n  host: semantic-router.vllm-semantic-router-system.svc.cluster.local\n  trafficPolicy:\n    tls:\n      mode: DISABLE\n      insecureSkipVerify: true\n", "source": "real", "collected_at": "2026-01-06T10:23:39.287859"}
{"id": "real_envoyfilter_3156", "source_file": "deploy/kubernetes/istio/envoyfilter.yaml", "category": "deploy", "deployment_context": "istio", "intent": "Configuration istio deployment", "use_case": "Configuration for istio deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: networking.istio.io/v1alpha3\nkind: EnvoyFilter\nmetadata:\n  name: semantic-router\n  namespace: default\nspec:\n  configPatches:\n  - applyTo: HTTP_FILTER\n    match:\n      listener:\n        filterChain:\n          filter:\n            name: envoy.filters.network.http_connection_manager\n    patch:\n      operation: INSERT_FIRST\n      value:\n        name: envoy.filters.http.ext_proc\n        typed_config:\n          '@type': type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor\n          failure_mode_allow: true\n          allow_mode_override: true\n          message_timeout: 300s\n          processing_mode:\n            request_header_mode: SEND\n            response_header_mode: SEND\n            request_body_mode: BUFFERED\n            response_body_mode: NONE\n            request_trailer_mode: SKIP\n            response_trailer_mode: SKIP\n          grpc_service:\n            envoy_grpc:\n              cluster_name: outbound|50051||semantic-router.vllm-semantic-router-system.svc.cluster.local\n", "source": "real", "collected_at": "2026-01-06T10:23:39.291483"}
{"id": "real_namespace_3470", "source_file": "deploy/kubernetes/istio/namespace.yaml", "category": "deploy", "deployment_context": "istio", "intent": "Configuration istio deployment", "use_case": "Configuration for istio deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: v1\nkind: Namespace\nmetadata:\n  name: vllm-semantic-router-system\n", "source": "real", "collected_at": "2026-01-06T10:23:39.292072"}
{"id": "real_config_9056", "source_file": "deploy/kubernetes/istio/config.yaml", "category": "deploy", "deployment_context": "istio", "intent": "Configuration istio deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for istio deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "model_config:\n  \"llama3-8b\":\n    allow_by_default: true\n  \"phi4-mini\":\n    allow_by_default: true\n\ndefault_model: \"llama3-8b\"\n\n# Categories - now only contain metadata for domain classification\ncategories:\n  - name: business\n  - name: law\n  - name: psychology\n  - name: biology\n  - name: chemistry\n  - name: history\n  - name: other\n  - name: health\n  - name: economics\n  - name: math\n  - name: physics\n  - name: computer science\n  - name: philosophy\n  - name: engineering\n\n# Decisions - define routing logic with rules, model selection, and plugins\ndecisions:\n  - name: business\n    description: \"Route business and management queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n          mode: \"replace\"\n  - name: law\n    description: \"Route legal queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n          mode: \"replace\"\n  - name: psychology\n    description: \"Route psychology queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: false\n          similarity_threshold: 0.92\n  - name: biology\n    description: \"Route biology queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n          mode: \"replace\"\n  - name: chemistry\n    description: \"Route chemistry queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n          mode: \"replace\"\n  - name: history\n    description: \"Route history queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n          mode: \"replace\"\n  - name: other\n    description: \"Route general queries\"\n    priority: 5\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: false\n          similarity_threshold: 0.75\n  - name: health\n    description: \"Route health and medical queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: false\n          similarity_threshold: 0.95\n  - name: economics\n    description: \"Route economics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n          mode: \"replace\"\n  - name: math\n    description: \"Route mathematics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: phi4-mini\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n          mode: \"replace\"\n  - name: physics\n    description: \"Route physics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n          mode: \"replace\"\n  - name: computer_science\n    description: \"Route computer science queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer science\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n\n          mode: \"replace\"\n  - name: philosophy\n    description: \"Route philosophy queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n          mode: \"replace\"\n  - name: engineering\n    description: \"Route engineering queries\"\n\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: llama3-8b\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: false\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n          mode: \"replace\"\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: false\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: false\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: false  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Gateway route cache clearing\nclear_route_cache: true  # Enable for some gateways such as Istio\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  # gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: false  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n\n", "source": "real", "collected_at": "2026-01-06T10:23:39.347362"}
{"id": "real_config_5946", "source_file": "deploy/kubernetes/observability/dashboard/config.yaml", "category": "deploy", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "tools", "observability"], "full_config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\" or \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM Endpoints Configuration\n# IMPORTANT: 'address' field must be a valid IP address (IPv4 or IPv6)\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1\n# NOT supported: domain names (example.com), protocol prefixes (http://), paths (/api), ports in address (use 'port' field)\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]\n    allow_by_default: true\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Categories with new use_reasoning field structure\ncategories:\n  - name: business\n    system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n    # jailbreak_enabled: true  # Optional: Override global jailbreak detection per category\n    # jailbreak_threshold: 0.8  # Optional: Override global jailbreak threshold per category\n    model_scores:\n      - model: qwen3\n        score: 0.7\n        use_reasoning: false  # Business performs better without reasoning\n  - name: law\n    system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n    model_scores:\n      - model: qwen3\n        score: 0.4\n        use_reasoning: false\n  - name: psychology\n    system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n    semantic_cache_enabled: true\n    semantic_cache_similarity_threshold: 0.92  # High threshold for psychology - sensitive to nuances\n    model_scores:\n      - model: qwen3\n        score: 0.6\n        use_reasoning: false\n  - name: biology\n    system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n    model_scores:\n      - model: qwen3\n        score: 0.9\n        use_reasoning: false\n  - name: chemistry\n    system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n    model_scores:\n      - model: qwen3\n        score: 0.6\n        use_reasoning: true  # Enable reasoning for complex chemistry\n  - name: history\n    system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n    model_scores:\n      - model: qwen3\n        score: 0.7\n        use_reasoning: false\n  - name: other\n    system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n    semantic_cache_enabled: true\n    semantic_cache_similarity_threshold: 0.75  # Lower threshold for general chat - less sensitive\n    model_scores:\n      - model: qwen3\n        score: 0.7\n        use_reasoning: false\n  - name: health\n    system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n    semantic_cache_enabled: true\n    semantic_cache_similarity_threshold: 0.95  # High threshold for health - very sensitive to word changes\n    model_scores:\n      - model: qwen3\n        score: 0.5\n        use_reasoning: false\n  - name: economics\n    system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n    model_scores:\n      - model: qwen3\n        score: 1.0\n        use_reasoning: false\n  - name: math\n    system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n    model_scores:\n      - model: qwen3\n        score: 1.0\n        use_reasoning: true  # Enable reasoning for complex math\n  - name: physics\n    system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n    model_scores:\n      - model: qwen3\n        score: 0.7\n        use_reasoning: true  # Enable reasoning for physics\n  - name: computer science\n    system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n    model_scores:\n      - model: qwen3\n        score: 0.6\n        use_reasoning: false\n  - name: philosophy\n    system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n    model_scores:\n      - model: qwen3\n        score: 0.5\n        use_reasoning: false\n  - name: engineering\n    system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n    model_scores:\n      - model: qwen3\n        score: 0.7\n        use_reasoning: false\n\ndefault_model: \"qwen3\"\n\n# Auto model name for automatic model selection (optional)\n# This is the model name that clients should use to trigger automatic model selection\n# If not specified, defaults to \"MoM\" (Mixture of Models)\n# For backward compatibility, \"auto\" is always accepted as an alias\n# Example: auto_model_name: \"MoM\"  # or any other name you prefer\n# auto_model_name: \"MoM\"\n\n# Include configured models in /v1/models list endpoint (optional, default: false)\n# When false (default): only the auto model name is returned in the /v1/models endpoint\n# When true: all models configured in model_config are also included in the /v1/models endpoint\n# This is useful for clients that need to discover all available models\n# Example: include_config_models_in_list: true\n# include_config_models_in_list: false\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.382651"}
{"id": "real_configmap_9319", "source_file": "deploy/kubernetes/observability/dashboard/configmap.yaml", "category": "deploy", "deployment_context": "unknown", "intent": "Basic configuration", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": ["observability"], "full_config": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: semantic-router-dashboard-config\n  labels:\n    app: semantic-router-dashboard\n    app.kubernetes.io/part-of: semantic-router\n    app.kubernetes.io/component: observability\ndata:\n  TARGET_GRAFANA_URL: http://grafana.vllm-semantic-router-system.svc.cluster.local:3000\n  TARGET_PROMETHEUS_URL: http://prometheus.vllm-semantic-router-system.svc.cluster.local:9090\n  TARGET_ROUTER_API_URL: http://semantic-router.vllm-semantic-router-system.svc.cluster.local:8080\n  TARGET_ROUTER_METRICS_URL: http://semantic-router-metrics.vllm-semantic-router-system.svc.cluster.local:9190/metrics\n", "source": "real", "collected_at": "2026-01-06T10:23:39.384598"}
{"id": "real_configmap-dashboard_5347", "source_file": "deploy/kubernetes/observability/grafana/configmap-dashboard.yaml", "category": "deploy", "deployment_context": "unknown", "intent": "Basic configuration", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": ["jailbreak_detection"], "full_config": "apiVersion: v1\ndata:\n  llm-router-dashboard.json: |-\n    {\n      \"annotations\": {\n        \"list\": [\n          {\n            \"builtIn\": 1,\n            \"datasource\": {\n              \"type\": \"grafana\",\n              \"uid\": \"-- Grafana --\"\n            },\n            \"enable\": true,\n            \"hide\": true,\n            \"iconColor\": \"rgba(0, 211, 255, 1)\",\n            \"name\": \"Annotations & Alerts\",\n            \"target\": {\n              \"limit\": 100,\n              \"matchAny\": false,\n              \"tags\": [],\n              \"type\": \"dashboard\"\n            },\n            \"type\": \"dashboard\"\n          }\n        ]\n      },\n      \"editable\": true,\n      \"fiscalYearStartMonth\": 0,\n      \"graphTooltip\": 0,\n      \"id\": 18,\n      \"links\": [],\n      \"panels\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 80\n                  }\n                ]\n              }\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 0\n          },\n          \"id\": 4,\n          \"options\": {\n            \"displayMode\": \"gradient\",\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": false\n            },\n            \"maxVizHeight\": 300,\n            \"minVizHeight\": 16,\n            \"minVizWidth\": 8,\n            \"namePlacement\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"showUnfilled\": true,\n            \"sizing\": \"auto\",\n            \"valueMode\": \"color\"\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"disableTextWrap\": false,\n              \"editorMode\": \"builder\",\n              \"expr\": \"sum by(category) (llm_category_classifications_count)\",\n              \"fullMetaSearch\": false,\n              \"includeNullMetadata\": true,\n              \"instant\": false,\n              \"legendFormat\": \"__auto\",\n              \"range\": true,\n              \"refId\": \"A\",\n              \"useBackend\": false\n            }\n          ],\n          \"title\": \"Prompt Category\",\n          \"type\": \"bargauge\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Tokens/sec\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"tps\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 0\n          },\n          \"id\": 2,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_model_completion_tokens_total[5m])) by (model)\",\n              \"legendFormat\": \"Completion Tokens {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Token Usage Rate by Model\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Routes/sec\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"ops\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 8\n          },\n          \"id\": 3,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_model_routing_modifications_total[5m])) by (source_model, target_model)\",\n              \"format\": \"time_series\",\n              \"legendFormat\": \"{{source_model}} -> {{target_model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Model Routing Rate\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Seconds\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 80\n                  }\n                ]\n              },\n              \"unit\": \"s\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 8\n          },\n          \"id\": 1,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"histogram_quantile(0.95, sum(rate(llm_model_completion_latency_seconds_bucket[5m])) by (le, model))\",\n              \"legendFormat\": \"p95 {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Model Completion Latency (p95)\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Seconds\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 80\n                  }\n                ]\n              },\n              \"unit\": \"s\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 16\n          },\n          \"id\": 5,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"histogram_quantile(0.95, sum(rate(llm_model_ttft_seconds_bucket[5m])) by (le, model))\",\n              \"legendFormat\": \"TTFT p95 {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"TTFT (p95) by Model\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Seconds per token\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"s\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 16\n          },\n          \"id\": 6,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"histogram_quantile(0.95, sum(rate(llm_model_tpot_seconds_bucket[5m])) by (le, model))\",\n              \"legendFormat\": \"TPOT p95 {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"TPOT (p95) by Model (sec/token)\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Requests/sec\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"reqps\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 24\n          },\n          \"id\": 7,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_reasoning_decisions_total{enabled=\\\"true\\\"}[5m])) by (model, effort)\",\n              \"legendFormat\": \"Reasoning Enabled: {{model}} ({{effort}})\",\n              \"range\": true,\n              \"refId\": \"A\"\n            },\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_reasoning_decisions_total{enabled=\\\"false\\\"}[5m])) by (model)\",\n              \"legendFormat\": \"Reasoning Disabled: {{model}}\",\n              \"range\": true,\n              \"refId\": \"B\"\n            }\n          ],\n          \"title\": \"Reasoning Rate by Model\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Cost\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 24\n          },\n          \"id\": 8,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_model_cost_total{currency=\\\"USD\\\"}[5m])) by (model)\",\n              \"legendFormat\": \"Cost/sec: {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Model Cost Rate (USD/sec)\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Errors/sec\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"normal\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 1\n                  }\n                ]\n              },\n              \"unit\": \"reqps\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 32\n          },\n          \"id\": 9,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_request_errors_total{reason=\\\"pii_policy_denied\\\"}[5m])) by (model)\",\n              \"legendFormat\": \"PII Policy Denied: {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            },\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_request_errors_total{reason=\\\"jailbreak_block\\\"}[5m])) by (model)\",\n              \"legendFormat\": \"Jailbreak Block: {{model}}\",\n              \"range\": true,\n              \"refId\": \"B\"\n            }\n          ],\n          \"title\": \"Refusal Rates by Model\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"yellow\",\n                    \"value\": 0.01\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 0.05\n                  }\n                ]\n              },\n              \"unit\": \"percentunit\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 32\n          },\n          \"id\": 10,\n          \"options\": {\n            \"displayMode\": \"gradient\",\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"maxVizHeight\": 300,\n            \"minVizHeight\": 16,\n            \"minVizWidth\": 8,\n            \"namePlacement\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"mean\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"showUnfilled\": true,\n            \"sizing\": \"auto\",\n            \"valueMode\": \"color\"\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(rate(llm_request_errors_total{reason=~\\\"pii_policy_denied|jailbreak_block\\\"}[5m])) by (model) / sum(rate(llm_model_requests_total[5m])) by (model)\",\n              \"legendFormat\": \"{{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Refusal Rate Percentage by Model\",\n          \"type\": \"bargauge\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 40\n          },\n          \"id\": 11,\n          \"options\": {\n            \"displayMode\": \"gradient\",\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"maxVizHeight\": 300,\n            \"minVizHeight\": 16,\n            \"minVizWidth\": 8,\n            \"namePlacement\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"showUnfilled\": true,\n            \"sizing\": \"auto\",\n            \"valueMode\": \"color\"\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(llm_model_cost_total{currency=\\\"USD\\\"}) by (model)\",\n              \"legendFormat\": \"{{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Total Cost by Model (USD)\",\n          \"type\": \"bargauge\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${DS_PROMETHEUS}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisBorderShow\": false,\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"Seconds\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"barWidthFactor\": 0.6,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"legend\": false,\n                  \"tooltip\": false,\n                  \"viz\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"smooth\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"auto\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"s\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 40\n          },\n          \"id\": 12,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\n                \"mean\",\n                \"max\",\n                \"lastNotNull\"\n              ],\n              \"displayMode\": \"table\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"hideZeros\": false,\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"pluginVersion\": \"11.5.1\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"histogram_quantile(0.50, sum(rate(llm_model_completion_latency_seconds_bucket[5m])) by (le, model))\",\n              \"legendFormat\": \"p50 {{model}}\",\n              \"range\": true,\n              \"refId\": \"A\"\n            },\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"histogram_quantile(0.90, sum(rate(llm_model_completion_latency_seconds_bucket[5m])) by (le, model))\",\n              \"legendFormat\": \"p90 {{model}}\",\n              \"range\": true,\n              \"refId\": \"B\"\n            },\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${DS_PROMETHEUS}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"histogram_quantile(0.99, sum(rate(llm_model_completion_latency_seconds_bucket[5m])) by (le, model))\",\n              \"legendFormat\": \"p99 {{model}}\",\n              \"range\": true,\n              \"refId\": \"C\"\n            }\n          ],\n          \"title\": \"Model Completion Latency (p50/p90/p99)\",\n          \"type\": \"timeseries\"\n        }\n      ],\n      \"preload\": false,\n      \"refresh\": \"10s\",\n      \"schemaVersion\": 40,\n      \"tags\": [\n        \"llm-router\"\n      ],\n      \"templating\": {\n        \"list\": [\n          {\n            \"current\": {\n              \"text\": \"prometheus\",\n              \"value\": \"prometheus\"\n            },\n            \"includeAll\": false,\n            \"name\": \"DS_PROMETHEUS\",\n            \"options\": [],\n            \"query\": \"prometheus\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"type\": \"datasource\"\n          }\n        ]\n      },\n      \"time\": {\n        \"from\": \"now-5m\",\n        \"to\": \"now\"\n      },\n      \"timepicker\": {},\n      \"timezone\": \"\",\n      \"title\": \"LLM Router Metrics\",\n      \"uid\": \"llm-router-metrics\",\n      \"version\": 14,\n      \"weekStart\": \"\"\n    }\nkind: ConfigMap\nmetadata:\n  name: grafana-dashboards\n", "source": "real", "collected_at": "2026-01-06T10:23:39.412893"}
{"id": "real_configmap-provisioning_7134", "source_file": "deploy/kubernetes/observability/grafana/configmap-provisioning.yaml", "category": "deploy", "deployment_context": "unknown", "intent": "Basic configuration", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-provisioning\n  labels:\n    app: grafana\ndata:\n  datasources.yaml: |\n    apiVersion: 1\n    datasources:\n      - name: Prometheus\n        uid: prometheus\n        type: prometheus\n        access: proxy\n        url: http://prometheus:9090\n        isDefault: true\n        editable: false\n        jsonData:\n          timeInterval: 15s\n  dashboards.yaml: |\n    apiVersion: 1\n    providers:\n      - name: semantic-router-dashboards\n        orgId: 1\n        folder: Semantic Router\n        type: file\n        disableDeletion: false\n        editable: true\n        options:\n          path: /var/lib/grafana-dashboards\n", "source": "real", "collected_at": "2026-01-06T10:23:39.414569"}
{"id": "real_configmap_1506", "source_file": "deploy/kubernetes/observability/prometheus/configmap.yaml", "category": "deploy", "deployment_context": "unknown", "intent": "Basic configuration", "use_case": "Configuration for unknown deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  labels:\n    app: prometheus\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n\n    scrape_configs:\n      - job_name: prometheus\n        static_configs:\n          - targets:\n              - localhost:9090\n\n      - job_name: semantic-router\n        kubernetes_sd_configs:\n          - role: endpoints\n            namespaces:\n              names:\n                - vllm-semantic-router-system\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_name]\n            regex: semantic-router-metrics\n            action: keep\n          - source_labels: [__meta_kubernetes_endpoint_port_name]\n            regex: metrics\n            action: keep\n          - source_labels: [__meta_kubernetes_namespace]\n            target_label: namespace\n          - source_labels: [__address__]\n            target_label: instance\n", "source": "real", "collected_at": "2026-01-06T10:23:39.416174"}
{"id": "real_namespace_6316", "source_file": "deploy/kubernetes/aibrix/semantic-router/namespace.yaml", "category": "deploy", "deployment_context": "aibrix", "intent": "Configuration aibrix deployment", "use_case": "Configuration for aibrix deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: v1\nkind: Namespace\nmetadata:\n  name: vllm-semantic-router-system\n", "source": "real", "collected_at": "2026-01-06T10:23:39.423641"}
{"id": "real_config_4819", "source_file": "deploy/kubernetes/aibrix/semantic-router/config.yaml", "category": "deploy", "deployment_context": "aibrix", "intent": "Configuration aibrix deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for aibrix deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "model_config:\n  \"vllm-llama3-8b-instruct\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    # Define available LoRA adapters for this base model\n    # These names must match the LoRA modules registered with vLLM at startup\n    loras:\n      - name: \"science-expert\"\n        description: \"Specialized for science domains: biology, chemistry, physics, health, engineering\"\n      - name: \"social-expert\"\n        description: \"Optimized for social sciences: business, economics\"\n      - name: \"math-expert\"\n        description: \"Fine-tuned for mathematics and quantitative reasoning\"\n      - name: \"law-expert\"\n        description: \"Specialized for legal questions and law-related topics\"\n      - name: \"humanities-expert\"\n        description: \"Optimized for humanities: psychology, history, philosophy\"\n      - name: \"general-expert\"\n        description: \"General-purpose adapter for diverse topics\"\n\n# Categories - now only contain metadata for domain classification\ncategories:\n  - name: business\n  - name: law\n  - name: psychology\n  - name: biology\n  - name: chemistry\n  - name: history\n  - name: other\n  - name: health\n  - name: economics\n  - name: math\n  - name: physics\n  - name: computer science\n  - name: philosophy\n  - name: engineering\n  - name: thinking\n\n# Decisions - define routing logic with rules, model selection, and plugins\ndecisions:\n  - name: business\n    description: \"Route business and management queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n          mode: \"replace\"\n  - name: law\n    description: \"Route legal queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n          mode: \"replace\"\n  - name: psychology\n    description: \"Route psychology queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n  - name: biology\n    description: \"Route biology queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n          mode: \"replace\"\n  - name: chemistry\n    description: \"Route chemistry queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n          mode: \"replace\"\n  - name: history\n    description: \"Route history queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n          mode: \"replace\"\n  - name: other\n    description: \"Route general queries\"\n    priority: 5\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n  - name: health\n    description: \"Route health and medical queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n  - name: economics\n    description: \"Route economics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n          mode: \"replace\"\n  - name: math\n    description: \"Route mathematics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n          mode: \"replace\"\n  - name: physics\n    description: \"Route physics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n          mode: \"replace\"\n  - name: computer_science\n    description: \"Route computer science queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer science\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n          mode: \"replace\"\n  - name: philosophy\n    description: \"Route philosophy queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n          mode: \"replace\"\n  - name: engineering\n    description: \"Route engineering queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n          mode: \"replace\"\n  - name: thinking\n    description: \"Route thinking and reasoning queries\"\n    priority: 15\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"thinking\"\n    modelRefs:\n      - model: vllm-llama3-8b-instruct\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a thinking expert, should think multiple steps before answering. Please answer the question step by step.\"\n          mode: \"replace\"\n\ndefault_model: vllm-llama3-8b-instruct\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\nkeyword_rules:\n  - name: \"thinking\"\n    operator: \"OR\"\n    keywords: [\"urgent\", \"immediate\", \"asap\", \"think\", \"careful\"]\n    case_sensitive: false\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: false  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.484618"}
{"id": "real_namespace_4893", "source_file": "deploy/kubernetes/ai-gateway/semantic-router/namespace.yaml", "category": "deploy", "deployment_context": "ai-gateway", "intent": "Configuration ai-gateway deployment", "use_case": "Configuration for ai-gateway deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: v1\nkind: Namespace\nmetadata:\n  name: vllm-semantic-router-system\n", "source": "real", "collected_at": "2026-01-06T10:23:39.486285"}
{"id": "real_config_5535", "source_file": "deploy/kubernetes/ai-gateway/semantic-router/config.yaml", "category": "deploy", "deployment_context": "ai-gateway", "intent": "Configuration ai-gateway deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for ai-gateway deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "model_config:\n  \"base-model\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    # Define available LoRA adapters for this base model\n    # These names must match the LoRA modules registered with vLLM at startup\n    loras:\n      - name: \"science-expert\"\n        description: \"Specialized for science domains: biology, chemistry, physics, health, engineering\"\n      - name: \"social-expert\"\n        description: \"Optimized for social sciences: business, economics\"\n      - name: \"math-expert\"\n        description: \"Fine-tuned for mathematics and quantitative reasoning\"\n      - name: \"law-expert\"\n        description: \"Specialized for legal questions and law-related topics\"\n      - name: \"humanities-expert\"\n        description: \"Optimized for humanities: psychology, history, philosophy\"\n      - name: \"general-expert\"\n        description: \"General-purpose adapter for diverse topics\"\n\ndefault_model: general-expert\n\n# Categories - now only contain metadata for domain classification\ncategories:\n  - name: business\n  - name: law\n  - name: psychology\n  - name: biology\n  - name: chemistry\n  - name: history\n  - name: other\n  - name: health\n  - name: economics\n  - name: math\n  - name: physics\n  - name: computer science\n  - name: philosophy\n  - name: engineering\n  - name: urgent request\n  - name: technical_support\n  - name: product_info\n\n# Decisions - define routing logic with rules, model selection, and plugins\ndecisions:\n  - name: business\n    description: \"Route business and management queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: base-model\n        lora_name: social-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n          mode: \"replace\"\n  - name: law\n    description: \"Route legal queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: base-model\n        lora_name: law-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n          mode: \"replace\"\n  - name: psychology\n    description: \"Route psychology queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: base-model\n        lora_name: humanities-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n  - name: biology\n    description: \"Route biology queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: base-model\n        lora_name: science-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n          mode: \"replace\"\n  - name: chemistry\n    description: \"Route chemistry queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: base-model\n        lora_name: science-expert\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n          mode: \"replace\"\n  - name: history\n    description: \"Route history queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: base-model\n        lora_name: humanities-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n          mode: \"replace\"\n  - name: other\n    description: \"Route general queries\"\n    priority: 5\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: base-model\n        lora_name: general-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n  - name: health\n    description: \"Route health and medical queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: base-model\n        lora_name: science-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n          mode: \"replace\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n  - name: economics\n    description: \"Route economics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: base-model\n        lora_name: social-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n          mode: \"replace\"\n  - name: math\n    description: \"Route mathematics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: base-model\n        lora_name: math-expert\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n          mode: \"replace\"\n  - name: physics\n    description: \"Route physics queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: base-model\n        lora_name: science-expert\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n          mode: \"replace\"\n  - name: computer_science\n    description: \"Route computer science queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer science\"\n    modelRefs:\n      - model: base-model\n        lora_name: science-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n          mode: \"replace\"\n  - name: philosophy\n    description: \"Route philosophy queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: base-model\n        lora_name: humanities-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n          mode: \"replace\"\n  - name: engineering\n    description: \"Route engineering queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: base-model\n        lora_name: science-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n          mode: \"replace\"\n  - name: urgent_request\n    description: \"Route urgent and emergency requests\"\n    priority: 20\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"urgent request\"\n    modelRefs:\n      - model: general-expert\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a thinking expert, should think multiple steps before answering. Please answer the question step by step.\"\n          mode: \"replace\"\n  - name: technical_support\n    description: \"Route technical support queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"technical_support\"\n    modelRefs:\n      - model: general-expert\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a technical support specialist. Provide detailed, step-by-step guidance for technical issues. Use clear explanations and include relevant troubleshooting steps.\"\n          mode: \"replace\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n      - type: \"pii\"\n        configuration:\n          enabled: true\n  - name: product_info\n    description: \"Route product information queries\"\n    priority: 10\n    rules:\n      operator: \"OR\"\n      conditions:\n        - type: \"domain\"\n          name: \"product_info\"\n    modelRefs:\n      - model: general-expert\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          enabled: true\n          system_prompt: \"You are a product specialist. Provide accurate information about products, features, pricing, and availability. Be helpful and informative.\"\n          mode: \"replace\"\n      - type: \"jailbreak\"\n        configuration:\n          enabled: true\n      - type: \"pii\"\n        configuration:\n          enabled: true\n\nkeyword_rules:\n  # Keyword Rule 1: Emergency/Urgent Requests\n  # Use case: Fast routing for time-sensitive queries that need immediate attention\n  # Examples: \"URGENT: server down\", \"EMERGENCY: data loss\", \"CRITICAL: security breach\"\n  - name: \"urgent request\"\n    operator: \"OR\"\n    keywords: [\"urgent\", \"emergency\", \"critical\", \"asap\", \"immediately\", \"help!\", \"sos\"]\n    case_sensitive: false\n\n  # Keyword Rule 2: Programming Language Detection\n  # Use case: Route code-related queries to appropriate handlers based on language\n  # Examples: \"python error\", \"java exception\", \"golang panic\", \"rust compiler error\"\n  - name: \"computer science\"\n    operator: \"OR\"\n    keywords: [\"python\", \"java\", \"golang\", \"rust\", \"javascript\", \"typescript\", \"c++\", \"ruby\", \"php\"]\n    case_sensitive: false\n\n# Embedding-based classification rules\n# These rules use semantic similarity between query text and candidates\nembedding_rules:\n  # Embedding Rule 1: Customer Complaint/Feedback Detection\n  # Use case: Identify negative sentiment and complaints regardless of exact wording\n  # Examples: \"I'm disappointed with the service\", \"This product doesn't work as expected\",\n  #           \"Not satisfied with my purchase\", \"The quality is poor\"\n  - name: \"technical_support\"\n    threshold: 0.72\n    candidates:\n      - \"I'm not satisfied with the product quality\"\n      - \"The service didn't meet my expectations\"\n      - \"I'm experiencing issues and need help\"\n      - \"Something is broken and not working properly\"\n      - \"I'm disappointed with the performance\"\n      - \"This is not what I expected when I ordered\"\n    aggregation_method: \"max\"  # Use max to catch any strong complaint signal\n    model: \"auto\"\n    dimension: 768\n    quality_priority: 0.8  # High quality needed for sentiment detection\n    latency_priority: 0.2\n\n  # Embedding Rule 2: Account/Billing Related Queries\n  # Use case: Route financial and account queries even with varied phrasing\n  # Examples: \"How much do I owe?\", \"Check my balance\", \"Update payment method\",\n  #           \"Why was I charged twice?\", \"Cancel my subscription\"\n  - name: \"product_info\"\n    threshold: 0.68\n    candidates:\n      - \"I need to check my account balance and payment history\"\n      - \"How can I update my billing information and payment method\"\n      - \"I was charged incorrectly and need a refund\"\n      - \"I want to cancel my subscription and stop recurring payments\"\n      - \"What are the fees and charges on my account\"\n      - \"I need to review my invoice and transaction details\"\n    aggregation_method: \"avg\"  # Use avg for balanced matching across billing topics\n    model: \"qwen3\"  # Use high-quality model for financial queries\n    dimension: 1024\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"bert\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n\n# Router Configuration for Dual-Path Selection\nrouter:\n  # High confidence threshold for automatic LoRA selection\n  high_confidence_threshold: 0.99\n  # Low latency threshold in milliseconds for LoRA path selection\n  low_latency_threshold_ms: 2000\n  # Baseline scores for path evaluation\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  # Success rate calculation threshold\n  success_confidence_threshold: 0.8\n  # Large batch size threshold for parallel processing\n  large_batch_threshold: 4\n  # Default performance metrics (milliseconds)\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  # Default processing requirements\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  # Default confidence and success rates\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  # Scoring weights for intelligent path selection (balanced approach)\n  multi_task_lora_weight: 0.30  # LoRA advantage for multi-task processing\n  single_task_traditional_weight: 0.30  # Traditional advantage for single tasks\n  large_batch_lora_weight: 0.25  # LoRA advantage for large batches (\u22654)\n  small_batch_traditional_weight: 0.25  # Traditional advantage for single items\n  medium_batch_weight: 0.10  # Neutral weight for medium batches (2-3)\n  high_confidence_lora_weight: 0.25  # LoRA advantage for high confidence (\u22650.99)\n  low_confidence_traditional_weight: 0.25  # Traditional for lower confidence (\u22640.9)\n  low_latency_lora_weight: 0.30  # LoRA advantage for low latency (\u22642000ms)\n  high_latency_traditional_weight: 0.10  # Traditional acceptable for relaxed timing\n  performance_history_weight: 0.20  # Historical performance comparison factor\n  # Traditional model specific configurations\n  traditional_bert_confidence_threshold: 0.95  # Traditional BERT confidence threshold\n  traditional_modernbert_confidence_threshold: 0.8  # Traditional ModernBERT confidence threshold\n  traditional_pii_detection_threshold: 0.5  # Traditional PII detection confidence threshold\n  traditional_token_classification_threshold: 0.9  # Traditional token classification threshold\n  traditional_dropout_prob: 0.1  # Traditional model dropout probability\n  traditional_attention_dropout_prob: 0.1  # Traditional model attention dropout probability\n  tie_break_confidence: 0.5  # Confidence value for tie-breaking situations\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  gemma_model_path: \"models/mom-embedding-flash\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  tracing:\n    enabled: false  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.559198"}
{"id": "real_config-7b_1306", "source_file": "bench/hallucination/config-7b.yaml", "category": "bench", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions"], "full_config": "# Configuration for hallucination detection benchmark\n# Connects to real vLLM server at port 8083\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: false  # Disable cache for benchmarking\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Hallucination mitigation configuration\nhallucination_mitigation:\n  enabled: true\n\n  # Fact-check classifier: determines if a prompt needs fact verification\n  fact_check_model:\n    model_id: \"models/mom-halugate-sentinel\"\n    threshold: 0.6\n    use_cpu: true\n\n  # Hallucination detector: verifies if LLM response is grounded in context\n  # Using base model (149M params) for balanced accuracy and speed\n  hallucination_model:\n    model_id: \"models/mom-halugate-detector\"\n    threshold: 0.5\n    use_cpu: true\n\n  # NLI model: provides explanations for hallucinated spans\n  nli_model:\n    model_id: \"models/mom-halugate-explainer\"\n    threshold: 0.7\n    use_cpu: true\n\n  # Action when hallucination detected: \"warn\" adds headers, \"block\" returns error\n  on_hallucination_detected: \"warn\"\n\n# Fact-check rules for signal classification\n# The classifier outputs one of these signals that can be referenced in decision conditions\nfact_check_rules:\n  - name: needs_fact_check\n    description: \"Query contains factual claims that should be verified against context\"\n  - name: no_fact_check_needed\n    description: \"Query is creative, code-related, or opinion-based - no fact verification needed\"\n\n# Prompt guard\nprompt_guard:\n  enabled: true\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM endpoint - real vLLM server\nvllm_endpoints:\n  - name: \"vllm-general\"\n    address: \"127.0.0.1\"\n    port: 8083\n    weight: 1\n    health_check_path: \"/health\"\n\n# Model configuration - use the actual model from vLLM\nmodel_config:\n  \"Qwen/Qwen2.5-14B-Instruct-AWQ\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"vllm-general\"]\n\n# Categories for routing\ncategories:\n  - name: general\n    description: \"General questions\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: science\n    description: \"Science questions\"\n    mmlu_categories: [\"physics\", \"chemistry\", \"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true\n          hallucination_action: \"header\"\n          unverified_factual_action: \"header\"\n          include_hallucination_details: false\n\n  - name: \"science_decision\"\n    description: \"Science questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"science\"\n    modelRefs:\n      - model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true\n          hallucination_action: \"header\"\n          unverified_factual_action: \"header\"\n          include_hallucination_details: false\n\n  - name: \"general_decision\"\n    description: \"General questions\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"general\"\n    modelRefs:\n      - model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true\n          hallucination_action: \"header\"\n          unverified_factual_action: \"header\"\n          include_hallucination_details: false\n\ndefault_model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n\n# API Configuration\napi:\n  batch_classification:\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n\n", "source": "real", "collected_at": "2026-01-06T10:23:39.577203"}
{"id": "real_config_9571", "source_file": "bench/hallucination/config.yaml", "category": "bench", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions"], "full_config": "# Configuration for hallucination detection benchmark\n# Connects to real vLLM server at port 8083\n\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\n\nsemantic_cache:\n  enabled: false  # Disable cache for benchmarking\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/pii_classifier_modernbert-base_presidio_token_model\"\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Hallucination mitigation configuration\nhallucination_mitigation:\n  enabled: true\n\n  # Fact-check classifier: determines if a prompt needs fact verification\n  fact_check_model:\n    model_id: \"models/mom-halugate-sentinel\"\n    threshold: 0.6\n    use_cpu: true\n\n  # Hallucination detector: verifies if LLM response is grounded in context\n  # Using base model (149M params) for balanced accuracy and speed\n  hallucination_model:\n    model_id: \"models/mom-halugate-detector\"\n    threshold: 0.5\n    use_cpu: true\n\n  # NLI model: provides explanations for hallucinated spans\n  nli_model:\n    model_id: \"models/mom-halugate-explainer\"\n    threshold: 0.7\n    use_cpu: true\n\n  # Action when hallucination detected: \"warn\" adds headers, \"block\" returns error\n  on_hallucination_detected: \"warn\"\n\n# Fact-check rules for signal classification\n# The classifier outputs one of these signals that can be referenced in decision conditions\nfact_check_rules:\n  - name: needs_fact_check\n    description: \"Query contains factual claims that should be verified against context\"\n  - name: no_fact_check_needed\n    description: \"Query is creative, code-related, or opinion-based - no fact verification needed\"\n\n# Prompt guard\nprompt_guard:\n  enabled: true\n  use_modernbert: true\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n\n# vLLM endpoint - real vLLM server\nvllm_endpoints:\n  - name: \"vllm-qwen\"\n    address: \"127.0.0.1\"\n    port: 8083\n    weight: 1\n    health_check_path: \"/health\"\n\n# Model configuration - use the actual model from vLLM\nmodel_config:\n  \"Qwen/Qwen2.5-14B-Instruct-AWQ\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"vllm-qwen\"]\n\n# Categories for routing\ncategories:\n  - name: general\n    description: \"General questions\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: science\n    description: \"Science questions\"\n    mmlu_categories: [\"physics\", \"chemistry\", \"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true\n          hallucination_action: \"header\"\n          unverified_factual_action: \"header\"\n          include_hallucination_details: false\n\n  - name: \"science_decision\"\n    description: \"Science questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"science\"\n    modelRefs:\n      - model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n        use_reasoning: true\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true\n          hallucination_action: \"header\"\n          unverified_factual_action: \"header\"\n          include_hallucination_details: false\n\n  - name: \"general_decision\"\n    description: \"General questions\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"general\"\n    modelRefs:\n      - model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n        use_reasoning: false\n    plugins:\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n      - type: \"hallucination\"\n        configuration:\n          enabled: true\n          use_nli: true\n          hallucination_action: \"header\"\n          unverified_factual_action: \"header\"\n          include_hallucination_details: false\n\ndefault_model: \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n\n# API Configuration\napi:\n  batch_classification:\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n\n", "source": "real", "collected_at": "2026-01-06T10:23:39.595379"}
