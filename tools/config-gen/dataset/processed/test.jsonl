{"id": "ai_generated_00446", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.432133"}
{"id": "ai_generated_00103", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.763002"}
{"id": "ai_generated_00560", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.435363"}
{"id": "ai_generated_00284", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407246"}
{"id": "ai_generated_00387", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.430404"}
{"id": "ai_generated_00137", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with PII detection, with 9 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.765620"}
{"id": "ai_generated_00123", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.764540"}
{"id": "ai_generated_00910", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.444896"}
{"id": "ai_generated_00687", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.438899"}
{"id": "template_10133", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"general_decision\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"technical\"\n          - \"customer_service\"\n\nmodel_config:\n  llama3:\n    reasoning_family: \"llama3\"\n    preferred_endpoints:\n      - \"endpoint_llama3\"\n\nvllm_endpoints:\n  - name: \"endpoint_llama3\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 3\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"redis\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to llama3, using embedding-based routing, with redis semantic cache, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "general_decision", "model_name": "llama3", "signal_type": "embedding", "category1": "technical", "category2": "customer_service", "endpoint_address": "192.168.1.100", "endpoint_port": 11434, "endpoint_weight": 3, "cache_enabled": true, "cache_backend": "redis", "cache_threshold": 0.8, "guard_enabled": false, "guard_threshold": 0.6, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "ai_generated_00080", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.761238"}
{"id": "template_21741", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"technical\"\n          - \"customer_service\"\n\nmodel_config:\n  phi4:\n    reasoning_family: \"phi4\"\n    preferred_endpoints:\n      - \"endpoint_phi4\"\n\nvllm_endpoints:\n  - name: \"endpoint_phi4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"milvus\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to phi4, using embedding-based routing, with PII detection, with tools auto-selection, for quickstart deployment", "deployment_context": "quickstart", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "phi4", "signal_type": "embedding", "category1": "technical", "category2": "customer_service", "endpoint_address": "192.168.1.100", "endpoint_port": 8080, "endpoint_weight": 1, "cache_enabled": false, "cache_backend": "milvus", "cache_threshold": 0.7, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": true, "deployment_context": "quickstart"}}
{"id": "augmented_real_prompt_guard_external_3382_2686", "config": "embedding_models:\n  qwen3_model_path: models/Qwen3-Embedding-0.6B\n  gemma_model_path: models/EmbeddingGemma-300M\n  use_cpu: true\nbert_model:\n  model_id: models/all-MiniLM-L6-v2\n  threshold: 0.85\n  use_cpu: true\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/mom-pii-classifier\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\nprompt_guard:\n  enabled: true\n  use_vllm: true\n  jailbreak_mapping_path: models/mom-jailbreak-classifier/jailbreak_type_mapping.json\n  threshold: 0.7\nexternal_models:\n- llm_provider: vllm\n  model_role: guardrail\n  llm_endpoint:\n    address: 127.0.0.1\n    port: 1235\n    name: qwen3guard-endpoint\n    use_chat_template: true\n  llm_model_name: qwen_guard\n  llm_timeout_seconds: 30\n  parser_type: qwen3guard\n  threshold: 0.75\nvllm_endpoints:\n- name: endpoint1\n  address: 127.0.0.1\n  port: 1234\n  weight: 1\nmodel_config:\n  qwen3:\n    reasoning_family: qwen3\n    preferred_endpoints:\n    - endpoint1\ndefault_model: qwen3\napi:\n  batch_classification:\n    metrics:\n      enabled: true\nobservability:\n  tracing:\n    enabled: false\n  metrics:\n    enabled: true\nsemantic_cache:\n  enabled: false\nresponse_api:\n  enabled: false\ndecisions:\n- name: decision_1\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  signals:\n  - type: keyword\n    categories:\n    - business\n    - general\n", "intent": "Configuration with semantic caching, with PII detection with additional routing decision", "deployment_context": "unknown", "source": "augmented", "base_id": "real_prompt_guard_external_3382", "augmentation_type": "add_decision"}
{"id": "ai_generated_00541", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.434917"}
{"id": "ai_generated_00592", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 8 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.436177"}
{"id": "ai_generated_00688", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.438911"}
{"id": "ai_generated_00032", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with observability, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399884"}
{"id": "ai_generated_00791", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.441531"}
{"id": "ai_generated_00191", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.770383"}
{"id": "ai_generated_00001", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.754365"}
{"id": "ai_generated_00289", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407399"}
{"id": "section_vllm_endpoints_real_config.e2e_6379_8", "config": "vllm_endpoints:\n- name: qwen-endpoint\n  address: 127.0.0.1\n  port: 8000\n  weight: 1\n  health_check_path: /health\n- name: tinyllama-endpoint\n  address: 127.0.0.1\n  port: 8001\n  weight: 1\n  health_check_path: /health\n", "intent": "Generate vLLM endpoints configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "vllm_endpoints", "deployment_context": "unknown", "source": "section", "base_id": "real_config.e2e_6379", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00115", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.422169"}
{"id": "real_config_697", "source_file": "config/config.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Configuration quickstart deployment, with semantic caching, with routing decisions, with PII detection", "use_case": "Configuration for quickstart deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "routing_decisions", "tools", "observability", "lora_routing"], "full_config": "# You can override by specifying your own mappings below:\n# Uncomment and customize if you need different model mappings:\n# mom_registry:\n#   \"models/mom-domain-classifier\": \"LLM-Semantic-Router/lora_intent_classifier_bert-base-uncased_model\"\n#   \"models/mom-pii-classifier\": \"LLM-Semantic-Router/lora_pii_detector_bert-base-uncased_model\"\n#   \"models/mom-jailbreak-classifier\": \"LLM-Semantic-Router/lora_jailbreak_classifier_bert-base-uncased_model\"\n#   \"models/mom-halugate-detector\": \"KRLabsOrg/lettucedect-base-modernbert-en-v1\"\n#   \"models/mom-halugate-sentinel\": \"LLM-Semantic-Router/halugate-sentinel\"\n#   \"models/mom-halugate-explainer\": \"tasksource/ModernBERT-base-nli\"\n#   \"models/mom-embedding-pro\": \"Qwen/Qwen3-Embedding-0.6B\"\n#   \"models/mom-embedding-flash\": \"google/embeddinggemma-300m\"\n\n# Response API Configuration\n# Enables OpenAI Response API support with conversation chaining\nresponse_api:\n  enabled: true\n  store_backend: \"memory\"  # Options: \"memory\", \"milvus\", \"redis\"\n  ttl_seconds: 86400       # 24 hours\n  max_responses: 1000\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"  # Options: \"memory\", \"milvus\", or \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000  # Only applies to memory backend\n  ttl_seconds: 3600\n  eviction_policy: \"fifo\"\n  # HNSW index configuration (for memory backend only)\n  use_hnsw: true  # Enable HNSW index for faster similarity search\n  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)\n  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)\n\n  # Hybrid cache configuration (when backend_type: \"hybrid\")\n  # Combines in-memory HNSW for fast search with Milvus for scalable storage\n  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)\n  # backend_config_path: \"config/milvus.yaml\" # Path to Milvus config\n\n  # Embedding model for semantic similarity matching\n  # Options: \"bert\" (fast, 384-dim), \"qwen3\" (high quality, 1024-dim, 32K context), \"gemma\" (balanced, 768-dim, 8K context)\n  # Default: \"bert\" (fastest, lowest memory)\n  embedding_model: \"qwen3\"\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nprompt_guard:\n  enabled: true  # Global default - can be overridden per category with jailbreak_enabled\n  use_modernbert: false\n  model_id: \"models/mom-jailbreak-classifier\"\n  threshold: 0.7\n  use_cpu: true\njailbreak_mapping_path: \"models/mom-jailbreak-classifier/label_mapping.json\"\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    use_modernbert: false\n    threshold: 0.9\n    use_cpu: true\n  pii_mapping_path: \"models/mom-pii-classifier/label_mapping.json\"\n\n# Hallucination mitigation configuration\n# Disabled by default - enable in decisions via hallucination plugin\nhallucination_mitigation:\n  enabled: false\n  # Fact-check classifier: determines if a prompt needs fact verification\n  fact_check_model:\n    model_id: \"models/mom-halugate-sentinel\"\n    threshold: 0.6\n    use_cpu: true\n  # Hallucination detector: verifies if LLM response is grounded in context\n  hallucination_model:\n    model_id: \"models/mom-halugate-detector\"\n    threshold: 0.8\n    use_cpu: true\n  # NLI model: provides explanations for hallucinated spans\n  nli_model:\n    model_id: \"models/mom-halugate-explainer\"\n    threshold: 0.9\n    use_cpu: true\n\n# vLLM Endpoints Configuration\n# The 'address' field can be an IP address (IPv4 or IPv6) or a domain name\n# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1, example.com, localhost\n# Note: Use the 'port' field for port numbers, not in the address field\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"172.28.0.20\"  # Static IPv4 of llm-katan within docker compose network\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"  # This model uses Qwen-3 reasoning syntax\n    preferred_endpoints: [\"endpoint1\"]  # Optional: omit to let upstream handle endpoint selection\n\n# Categories define domain metadata only (no routing logic)\ncategories:\n  - name: business\n    description: \"Business and management related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Legal questions and law-related topics\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology and mental health topics\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology and life sciences questions\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry and chemical sciences questions\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"Historical questions and cultural topics\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"General knowledge and miscellaneous topics\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health and medical information queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics and financial topics\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Mathematics and quantitative reasoning\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics and physical sciences\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer science and programming\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy and ethical questions\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering and technical problem-solving\"\n    mmlu_categories: [\"engineering\"]\n\n# Decisions define routing logic with domain-based conditions\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business and management queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"law_decision\"\n    description: \"Legal questions and law-related topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"psychology_decision\"\n    description: \"Psychology and mental health topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"biology_decision\"\n    description: \"Biology and life sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry and chemical sciences questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"history_decision\"\n    description: \"Historical questions and cultural topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"health_decision\"\n    description: \"Health and medical information queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"economics_decision\"\n    description: \"Economics and financial topics\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"math_decision\"\n    description: \"Mathematics and quantitative reasoning\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"physics_decision\"\n    description: \"Physics and physical sciences\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"computer_science_decision\"\n    description: \"Computer science and programming\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy and ethical questions\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"engineering_decision\"\n    description: \"Engineering and technical problem-solving\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n  - name: \"general_decision\"\n    description: \"General knowledge and miscellaneous topics\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: []\n\n\ndefault_model: qwen3\n\n# Reasoning family configurations\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n  gpt:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\n# Global default reasoning effort level\ndefault_reasoning_effort: high\n\n# API Configuration\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]\n      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]\n\n# Embedding Models Configuration\n# These models provide intelligent embedding generation with automatic routing:\n# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,\n# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)\nembedding_models:\n  qwen3_model_path: \"models/mom-embedding-pro\"\n  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)\n\n# Observability Configuration\nobservability:\n  metrics:\n    enabled: true  # Set to false to disable the Prometheus /metrics endpoint\n  tracing:\n    enabled: true  # Enable distributed tracing for docker-compose stack\n    provider: \"opentelemetry\"  # Provider: opentelemetry, openinference, openllmetry\n    exporter:\n      type: \"otlp\"  # Export spans to Jaeger (via OTLP gRPC)\n      endpoint: \"jaeger:4317\"  # Jaeger collector inside compose network\n      insecure: true  # Use insecure connection (no TLS)\n    sampling:\n      type: \"always_on\"  # Sampling: always_on, always_off, probabilistic\n      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"development\"\n", "source": "real", "collected_at": "2026-01-06T10:23:38.106918"}
{"id": "ai_generated_00963", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446411"}
{"id": "ai_generated_00375", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409893"}
{"id": "ai_generated_00778", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using qwen3 model, in istio deployment, with PII detection, with tool selection, with 8 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.441203"}
{"id": "ai_generated_00483", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.433239"}
{"id": "ai_generated_00393", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410394"}
{"id": "ai_generated_00292", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with semantic caching, with observability, with 6 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.779541"}
{"id": "ai_generated_00450", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with 10 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.432275"}
{"id": "ai_generated_00054", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 12 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400514"}
{"id": "ai_generated_00874", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.443919"}
{"id": "template_86135", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"general_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"domain\"\n        categories:\n          - \"technical\"\n          - \"finance\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 3\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"redis\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: False\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using domain-based routing, with redis semantic cache, with PII detection, for quickstart deployment", "deployment_context": "quickstart", "source": "template", "values": {"decision_name": "general_decision", "model_name": "mistral", "signal_type": "domain", "category1": "technical", "category2": "finance", "endpoint_address": "192.168.1.100", "endpoint_port": 11434, "endpoint_weight": 3, "cache_enabled": true, "cache_backend": "redis", "cache_threshold": 0.9, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": false, "deployment_context": "quickstart"}}
{"id": "ai_generated_00136", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using llama3 model, in istio deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.422755"}
{"id": "ai_generated_00832", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.442815"}
{"id": "ai_generated_00197", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.424417"}
{"id": "ai_generated_00612", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using gpt-oss-20b model, in kubernetes deployment, with semantic caching, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.436735"}
{"id": "augmented_real_vllm.ai_intelligentroutes_8714_9443", "config": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  annotations:\n    controller-gen.kubebuilder.io/version: v0.19.0\n  name: intelligentroutes.vllm.ai\nspec:\n  group: vllm.ai\n  names:\n    kind: IntelligentRoute\n    listKind: IntelligentRouteList\n    plural: intelligentroutes\n    shortNames:\n    - iroute\n    singular: intelligentroute\n  scope: Namespaced\n  versions:\n  - additionalPrinterColumns:\n    - description: Number of decisions\n      jsonPath: .status.statistics.decisions\n      name: Decisions\n      type: integer\n    - description: Number of keyword signals\n      jsonPath: .status.statistics.keywords\n      name: Keywords\n      type: integer\n    - description: Number of embedding signals\n      jsonPath: .status.statistics.embeddings\n      name: Embeddings\n      type: integer\n    - description: Number of domain signals\n      jsonPath: .status.statistics.domains\n      name: Domains\n      type: integer\n    - description: Ready status\n      jsonPath: .status.conditions[?(@.type=='Ready')].status\n      name: Status\n      type: string\n    - jsonPath: .metadata.creationTimestamp\n      name: Age\n      type: date\n    name: v1alpha1\n    schema:\n      openAPIV3Schema:\n        description: IntelligentRoute defines intelligent routing rules and decisions\n        properties:\n          apiVersion:\n            description: 'APIVersion defines the versioned schema of this representation\n              of an object.\n\n              Servers should convert recognized schemas to the latest internal value,\n              and\n\n              may reject unrecognized values.\n\n              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n            type: string\n          kind:\n            description: 'Kind is a string value representing the REST resource this\n              object represents.\n\n              Servers may infer this from the endpoint the client submits requests\n              to.\n\n              Cannot be updated.\n\n              In CamelCase.\n\n              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n            type: string\n          metadata:\n            type: object\n          spec:\n            description: IntelligentRouteSpec defines the desired state of IntelligentRoute\n            properties:\n              decisions:\n                description: Decisions defines the routing decisions based on signal\n                  combinations\n                items:\n                  description: Decision defines a routing decision based on rule combinations\n                  properties:\n                    description:\n                      description: Description provides a human-readable description\n                        of this decision\n                      maxLength: 500\n                      type: string\n                    modelRefs:\n                      description: ModelRefs defines the model references for this\n                        decision (currently only one model is supported)\n                      items:\n                        description: ModelRef defines a model reference without score\n                        properties:\n                          loraName:\n                            description: LoRAName is the name of the LoRA adapter\n                              to use (must exist in the model's LoRAs)\n                            maxLength: 100\n                            type: string\n                          model:\n                            description: Model is the name of the model (must exist\n                              in IntelligentPool)\n                            maxLength: 100\n                            minLength: 1\n                            type: string\n                          reasoningDescription:\n                            description: ReasoningDescription provides context for\n                              when to use reasoning\n                            maxLength: 500\n                            type: string\n                          reasoningEffort:\n                            description: ReasoningEffort defines the reasoning effort\n                              level (low/medium/high)\n                            enum:\n                            - low\n                            - medium\n                            - high\n                            type: string\n                          useReasoning:\n                            default: false\n                            description: UseReasoning specifies whether to enable\n                              reasoning mode for this model\n                            type: boolean\n                        required:\n                        - model\n                        type: object\n                      maxItems: 1\n                      minItems: 1\n                      type: array\n                    name:\n                      description: Name is the unique identifier for this decision\n                      maxLength: 100\n                      minLength: 1\n                      type: string\n                    plugins:\n                      description: Plugins defines the plugins to apply for this decision\n                      items:\n                        description: DecisionPlugin defines a plugin configuration\n                          for a decision\n                        properties:\n                          configuration:\n                            description: Configuration is the plugin-specific configuration\n                              as a raw JSON object\n                            x-kubernetes-preserve-unknown-fields: true\n                          type:\n                            description: Type is the plugin type (semantic-cache,\n                              jailbreak, pii, system_prompt, header_mutation)\n                            enum:\n                            - semantic-cache\n                            - jailbreak\n                            - pii\n                            - system_prompt\n                            - header_mutation\n                            type: string\n                        required:\n                        - type\n                        type: object\n                      maxItems: 10\n                      type: array\n                    priority:\n                      default: 0\n                      description: 'Priority defines the priority of this decision\n                        (higher values = higher priority)\n\n                        Used when strategy is \"priority\"'\n                      format: int32\n                      maximum: 1000\n                      minimum: 0\n                      type: integer\n                    signals:\n                      description: Signals defines the signal combination logic\n                      properties:\n                        conditions:\n                          description: Conditions defines the list of signal conditions\n                          items:\n                            description: SignalCondition defines a single signal condition\n                            properties:\n                              name:\n                                description: Name is the name of the signal to reference\n                                maxLength: 100\n                                minLength: 1\n                                type: string\n                              type:\n                                description: Type defines the type of signal (keyword/embedding/domain)\n                                enum:\n                                - keyword\n                                - embedding\n                                - domain\n                                type: string\n                            required:\n                            - name\n                            - type\n                            type: object\n                          maxItems: 50\n                          minItems: 1\n                          type: array\n                        operator:\n                          description: Operator defines the logical operator for combining\n                            conditions (AND/OR)\n                          enum:\n                          - AND\n                          - OR\n                          type: string\n                      required:\n                      - conditions\n                      - operator\n                      type: object\n                  required:\n                  - modelRefs\n                  - name\n                  - signals\n                  type: object\n                maxItems: 100\n                minItems: 1\n                type: array\n              signals:\n                description: Signals defines signal extraction rules for routing decisions\n                properties:\n                  domains:\n                    description: Domains defines MMLU domain categories for classification\n                    items:\n                      description: DomainSignal defines a domain category for classification\n                      properties:\n                        description:\n                          description: Description provides a human-readable description\n                            of this domain\n                          maxLength: 500\n                          type: string\n                        name:\n                          description: Name is the unique identifier for this domain\n                          maxLength: 100\n                          minLength: 1\n                          type: string\n                      required:\n                      - name\n                      type: object\n                    maxItems: 14\n                    type: array\n                  embeddings:\n                    description: Embeddings defines embedding-based signal extraction\n                      rules\n                    items:\n                      description: EmbeddingSignal defines an embedding-based signal\n                        extraction rule\n                      properties:\n                        aggregationMethod:\n                          default: max\n                          description: AggregationMethod defines how to aggregate\n                            multiple candidate similarities\n                          enum:\n                          - mean\n                          - max\n                          - any\n                          type: string\n                        candidates:\n                          description: Candidates is the list of candidate phrases\n                            for semantic matching\n                          items:\n                            type: string\n                          maxItems: 100\n                          minItems: 1\n                          type: array\n                        name:\n                          description: Name is the unique identifier for this signal\n                          maxLength: 100\n                          minLength: 1\n                          type: string\n                        threshold:\n                          description: Threshold is the similarity threshold for matching\n                            (0.0-1.0)\n                          maximum: 1\n                          minimum: 0\n                          type: number\n                      required:\n                      - candidates\n                      - name\n                      - threshold\n                      type: object\n                    maxItems: 100\n                    type: array\n                  keywords:\n                    description: Keywords defines keyword-based signal extraction\n                      rules\n                    items:\n                      description: KeywordSignal defines a keyword-based signal extraction\n                        rule\n                      properties:\n                        caseSensitive:\n                          default: false\n                          description: CaseSensitive specifies whether keyword matching\n                            is case-sensitive\n                          type: boolean\n                        keywords:\n                          description: Keywords is the list of keywords to match\n                          items:\n                            type: string\n                          maxItems: 100\n                          minItems: 1\n                          type: array\n                        name:\n                          description: Name is the unique identifier for this rule\n                            (also used as category name)\n                          maxLength: 100\n                          minLength: 1\n                          type: string\n                        operator:\n                          description: Operator defines the logical operator for keywords\n                            (AND/OR)\n                          enum:\n                          - AND\n                          - OR\n                          type: string\n                      required:\n                      - keywords\n                      - name\n                      - operator\n                      type: object\n                    maxItems: 100\n                    type: array\n                type: object\n            required:\n            - decisions\n            type: object\n          status:\n            description: IntelligentRouteStatus defines the observed state of IntelligentRoute\n            properties:\n              conditions:\n                description: Conditions represent the latest available observations\n                  of the IntelligentRoute's state\n                items:\n                  description: Condition contains details for one aspect of the current\n                    state of this API Resource.\n                  properties:\n                    lastTransitionTime:\n                      description: 'lastTransitionTime is the last time the condition\n                        transitioned from one status to another.\n\n                        This should be when the underlying condition changed.  If\n                        that is not known, then using the time when the API field\n                        changed is acceptable.'\n                      format: date-time\n                      type: string\n                    message:\n                      description: 'message is a human readable message indicating\n                        details about the transition.\n\n                        This may be an empty string.'\n                      maxLength: 32768\n                      type: string\n                    observedGeneration:\n                      description: 'observedGeneration represents the .metadata.generation\n                        that the condition was set based upon.\n\n                        For instance, if .metadata.generation is currently 12, but\n                        the .status.conditions[x].observedGeneration is 9, the condition\n                        is out of date\n\n                        with respect to the current state of the instance.'\n                      format: int64\n                      minimum: 0\n                      type: integer\n                    reason:\n                      description: 'reason contains a programmatic identifier indicating\n                        the reason for the condition''s last transition.\n\n                        Producers of specific condition types may define expected\n                        values and meanings for this field,\n\n                        and whether the values are considered a guaranteed API.\n\n                        The value should be a CamelCase string.\n\n                        This field may not be empty.'\n                      maxLength: 1024\n                      minLength: 1\n                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$\n                      type: string\n                    status:\n                      description: status of the condition, one of True, False, Unknown.\n                      enum:\n                      - 'True'\n                      - 'False'\n                      - Unknown\n                      type: string\n                    type:\n                      description: type of condition in CamelCase or in foo.example.com/CamelCase.\n                      maxLength: 316\n                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$\n                      type: string\n                  required:\n                  - lastTransitionTime\n                  - message\n                  - reason\n                  - status\n                  - type\n                  type: object\n                type: array\n              observedGeneration:\n                description: ObservedGeneration reflects the generation of the most\n                  recently observed IntelligentRoute\n                format: int64\n                type: integer\n              statistics:\n                description: Statistics provides statistics about configured decisions\n                  and signals\n                properties:\n                  decisions:\n                    description: Decisions indicates the number of decisions\n                    format: int32\n                    type: integer\n                  domains:\n                    description: Domains indicates the number of domain signals\n                    format: int32\n                    type: integer\n                  embeddings:\n                    description: Embeddings indicates the number of embedding signals\n                    format: int32\n                    type: integer\n                  keywords:\n                    description: Keywords indicates the number of keyword signals\n                    format: int32\n                    type: integer\n                required:\n                - decisions\n                - domains\n                - embeddings\n                - keywords\n                type: object\n            type: object\n        type: object\n    served: true\n    storage: true\n    subresources:\n      status: {}\nprompt_guard:\n  enabled: true\n  threshold: 0.73\n  use_modernbert: true\n", "intent": "Configuration with routing decisions with PII detection added", "deployment_context": "unknown", "source": "augmented", "base_id": "real_vllm.ai_intelligentroutes_8714", "augmentation_type": "add_pii_detection"}
{"id": "ai_generated_00169", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.423668"}
{"id": "ai_generated_00671", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.438384"}
{"id": "ai_generated_00179", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.769517"}
{"id": "ai_generated_00758", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.440681"}
{"id": "ai_generated_00328", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408500"}
{"id": "template_41346", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"domain\"\n        categories:\n          - \"technical\"\n          - \"customer_service\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"milvus\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using domain-based routing, with milvus semantic cache, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "mistral", "signal_type": "domain", "category1": "technical", "category2": "customer_service", "endpoint_address": "172.16.0.10", "endpoint_port": 8000, "endpoint_weight": 1, "cache_enabled": true, "cache_backend": "milvus", "cache_threshold": 0.7, "guard_enabled": false, "guard_threshold": 0.8, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "ai_generated_00449", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.432229"}
{"id": "ai_generated_00314", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408139"}
{"id": "augmented_real_redis_1330_904", "config": "connection:\n  host: localhost\n  port: 6379\n  database: 0\n  password: ''\n  timeout: 30\n  tls:\n    enabled: false\n    cert_file: ''\n    key_file: ''\n    ca_file: ''\nindex:\n  name: semantic_cache_idx\n  prefix: 'doc:'\n  vector_field:\n    name: embedding\n    dimension: 384\n    metric_type: COSINE\n  index_type: HNSW\n  params:\n    M: 16\n    efConstruction: 64\nsearch:\n  topk: 1\nlogging:\n  level: info\n  enable_query_log: false\n  enable_metrics: true\ndevelopment:\n  drop_index_on_startup: true\n  auto_create_index: true\n  verbose_errors: true\n", "intent": "Configuration with semantic caching with simplified routing", "deployment_context": "unknown", "source": "augmented", "base_id": "real_redis_1330", "augmentation_type": "remove_decision"}
{"id": "ai_generated_00362", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.429647"}
{"id": "ai_generated_00682", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.438716"}
{"id": "ai_generated_00367", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with observability, with 8 routing decisions", "use_case": "Configuration for production-stack deployment with observability, routing_decisions", "complexity": "high", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.429780"}
{"id": "real_prompt_guard_external_3382", "source_file": "config/prompt-guard/prompt_guard_external.yaml", "category": "main", "deployment_context": "unknown", "intent": "Configuration with semantic caching, with PII detection", "use_case": "Configuration for unknown deployment", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "jailbreak_detection", "observability"], "full_config": "# Example configuration showing how to use ExternalModels for PromptGuard\n# This demonstrates the new hybrid approach where vLLM configuration can be\n# specified in external_models with model_role=\"guardrail\"\n\n# Embedding models configuration\nembedding_models:\n  qwen3_model_path: \"models/Qwen3-Embedding-0.6B\"\n  gemma_model_path: \"models/EmbeddingGemma-300M\"\n  use_cpu: true\n\n# BERT model for semantic similarity\nbert_model:\n  model_id: \"models/all-MiniLM-L6-v2\"\n  threshold: 0.85\n  use_cpu: true\n\n# Classifier configuration\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: \"models/mom-domain-classifier/category_mapping.json\"\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: \"models/mom-pii-classifier/pii_type_mapping.json\"\n\n# Prompt Guard Configuration\n# When use_vllm=true, the system will look for an external model with model_role=\"guardrail\"\n# vLLM endpoint/model configuration is now in external_models section below\nprompt_guard:\n  enabled: true\n  use_vllm: true  # Enable vLLM mode - will use external_models configuration\n  jailbreak_mapping_path: \"models/mom-jailbreak-classifier/jailbreak_type_mapping.json\"\n  threshold: 0.7  # Default threshold (can be overridden by external_models)\n\n  # Note: When use_vllm=true, the following vLLM fields are NOT needed here:\n  # - classifier_vllm_endpoint (use external_models.llm_endpoint instead)\n  # - vllm_model_name (use external_models.llm_model_name instead)\n  # - vllm_timeout_seconds (use external_models.llm_timeout_seconds instead)\n  # - response_parser_type (use external_models.parser_type instead)\n\n  # The following Candle fields are only used when use_vllm=false:\n  # use_modernbert: false\n  # model_id: \"models/mom-jailbreak-classifier\"\n  # use_cpu: true\n\n# External Models Configuration\n# This is the new recommended way to configure vLLM-based guardrails\n# Note: jailbreak_mapping_path and threshold are still in prompt_guard because they are\n# used by the classification logic (not by the vLLM model itself)\nexternal_models:\n  - llm_provider: \"vllm\"\n    model_role: \"guardrail\"  # This identifies it as a guardrail/safety model\n    llm_endpoint:\n      address: \"127.0.0.1\"\n      port: 1235\n      name: \"qwen3guard-endpoint\"\n      use_chat_template: true  # Qwen3Guard requires chat template format\n      # prompt_template: \"Custom template with %s placeholder\"  # Optional\n    llm_model_name: \"qwen_guard\"  # Model name as served by vLLM\n    llm_timeout_seconds: 30\n    parser_type: \"qwen3guard\"  # Response parser type\n    threshold: 0.75  # Optional: Override the default threshold from prompt_guard\n\n# vLLM Endpoints Configuration (for backend inference)\n# These are separate from the guardrail endpoint above\nvllm_endpoints:\n  - name: \"endpoint1\"\n    address: \"127.0.0.1\"\n    port: 1234\n    weight: 1\n\n# Backend model configuration\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint1\"]\n\ndefault_model: \"qwen3\"\n\n# API configuration\napi:\n  batch_classification:\n    metrics:\n      enabled: true\n\n# Observability\nobservability:\n  tracing:\n    enabled: false\n  metrics:\n    enabled: true\n\n# Semantic cache\nsemantic_cache:\n  enabled: false\n\n# Response API\nresponse_api:\n  enabled: false\n\n", "source": "real", "collected_at": "2026-01-06T10:23:38.351397"}
{"id": "ai_generated_00218", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405352"}
{"id": "ai_generated_00285", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with semantic caching, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.778975"}
{"id": "ai_generated_00179", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404229"}
{"id": "augmented_real_embedding_8723_2678", "config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: false\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: models/mom-jailbreak-classifier\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: models/mom-jailbreak-classifier/jailbreak_type_mapping.json\nvllm_endpoints:\n- name: endpoint1\n  address: 172.28.0.20\n  port: 8002\n  weight: 1\nmodel_config:\n  qwen3:\n    reasoning_family: qwen3\n    preferred_endpoints:\n    - endpoint1\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/pii_classifier_modernbert-base_presidio_token_model\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\nembedding_rules:\n- category: technical_support\n  threshold: 0.75\n  keywords:\n  - how to configure the system\n  - installation guide\n  - troubleshooting steps\n  - error message explanation\n  - setup instructions\n  aggregation_method: max\n  model: auto\n  dimension: 768\n  quality_priority: 0.7\n  latency_priority: 0.3\n- category: product_inquiry\n  threshold: 0.7\n  keywords:\n  - product features and specifications\n  - pricing information\n  - availability and stock\n  - product comparison\n  - warranty details\n  aggregation_method: avg\n  model: gemma\n  dimension: 768\n- category: account_management\n  threshold: 0.72\n  keywords:\n  - password reset\n  - account settings\n  - profile update\n  - subscription management\n  - billing information\n  aggregation_method: max\n  model: qwen3\n  dimension: 1024\n- category: general_inquiry\n  threshold: 0.65\n  keywords:\n  - general question\n  - information request\n  - help needed\n  - customer service\n  aggregation_method: any\n  model: auto\n  dimension: 512\n  quality_priority: 0.5\n  latency_priority: 0.5\ncategories:\n- name: technical_support\n  description: Technical support and troubleshooting queries\n  mmlu_categories:\n  - technical_support\n- name: product_inquiry\n  description: Product information and specifications\n  mmlu_categories:\n  - product_inquiry\n- name: account_management\n  description: Account and subscription management\n  mmlu_categories:\n  - account_management\n- name: general_inquiry\n  description: General questions and information requests\n  mmlu_categories:\n  - general_inquiry\nstrategy: priority\ndecisions:\n- name: technical_support_decision\n  description: Technical support and troubleshooting queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: technical_support\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a technical support specialist. Provide detailed, step-by-step\n        guidance for technical issues. Use clear explanations and include relevant\n        troubleshooting steps.\n  - type: jailbreak\n    configuration:\n      enabled: true\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: product_inquiry_decision\n  description: Product information and specifications\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: product_inquiry\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a product specialist. Provide accurate information about\n        products, features, pricing, and availability. Be helpful and informative.\n  - type: jailbreak\n    configuration:\n      enabled: true\n  - type: pii\n    configuration:\n      enabled: false\n      pii_types_allowed: []\n- name: account_management_decision\n  description: Account and subscription management\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: account_management\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an account management assistant. Help users with account-related\n        tasks such as password resets, profile updates, and subscription management.\n        Prioritize security and privacy.\n  - type: jailbreak\n    configuration:\n      enabled: true\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: general_inquiry_decision\n  description: General questions and information requests\n  priority: 50\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: general_inquiry\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a helpful general assistant. Answer questions clearly\n        and concisely. If you need more information, ask clarifying questions.\n  - type: jailbreak\n    configuration:\n      enabled: true\n  - type: pii\n    configuration:\n      enabled: false\n      pii_types_allowed: []\nembedding_models:\n  qwen3_model_path: models/mom-embedding-pro\n  gemma_model_path: models/mom-embedding-flash\n  use_cpu: true\ndefault_model: qwen3\nentropy_threshold: 0.5\nhigh_entropy_threshold: 0.8\n", "intent": "Configuration with semantic caching, with routing decisions, with PII detection with semantic caching removed", "deployment_context": "unknown", "source": "augmented", "base_id": "real_embedding_8723", "augmentation_type": "remove_semantic_cache"}
{"id": "ai_generated_00190", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.770283"}
{"id": "section_tools_real_config.tracing_3469_1", "config": "tools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\n", "intent": "Generate tools auto-selection configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "tools", "deployment_context": "unknown", "source": "section", "base_id": "real_config.tracing_3469", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00201", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.424573"}
{"id": "ai_generated_00463", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.432619"}
{"id": "augmented_real_config_4819_8712", "config": "model_config:\n  vllm-llama3-8b-instruct:\n    reasoning_family: qwen3\n    loras:\n    - name: science-expert\n      description: 'Specialized for science domains: biology, chemistry, physics,\n        health, engineering'\n    - name: social-expert\n      description: 'Optimized for social sciences: business, economics'\n    - name: math-expert\n      description: Fine-tuned for mathematics and quantitative reasoning\n    - name: law-expert\n      description: Specialized for legal questions and law-related topics\n    - name: humanities-expert\n      description: 'Optimized for humanities: psychology, history, philosophy'\n    - name: general-expert\n      description: General-purpose adapter for diverse topics\ncategories:\n- name: business\n- name: law\n- name: psychology\n- name: biology\n- name: chemistry\n- name: history\n- name: other\n- name: health\n- name: economics\n- name: math\n- name: physics\n- name: computer science\n- name: philosophy\n- name: engineering\n- name: thinking\ndecisions:\n- name: business\n  description: Route business and management queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: business\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a senior business consultant and strategic advisor with\n        expertise in corporate strategy, operations management, financial analysis,\n        marketing, and organizational development. Provide practical, actionable business\n        advice backed by proven methodologies and industry best practices. Consider\n        market dynamics, competitive landscape, and stakeholder interests in your\n        recommendations.\n      mode: replace\n- name: law\n  description: Route legal queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: law\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a knowledgeable legal expert with comprehensive understanding\n        of legal principles, case law, statutory interpretation, and legal procedures\n        across multiple jurisdictions. Provide accurate legal information and analysis\n        while clearly stating that your responses are for informational purposes only\n        and do not constitute legal advice. Always recommend consulting with qualified\n        legal professionals for specific legal matters.\n      mode: replace\n- name: psychology\n  description: Route psychology queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: psychology\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a psychology expert with deep knowledge of cognitive\n        processes, behavioral patterns, mental health, developmental psychology, social\n        psychology, and therapeutic approaches. Provide evidence-based insights grounded\n        in psychological research and theory. When discussing mental health topics,\n        emphasize the importance of professional consultation and avoid providing\n        diagnostic or therapeutic advice.\n      mode: replace\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.92\n- name: biology\n  description: Route biology queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: biology\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a biology expert with comprehensive knowledge spanning\n        molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology,\n        and biotechnology. Explain biological concepts with scientific accuracy, use\n        appropriate terminology, and provide examples from current research. Connect\n        biological principles to real-world applications and emphasize the interconnectedness\n        of biological systems.\n      mode: replace\n- name: chemistry\n  description: Route chemistry queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: chemistry\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a chemistry expert specializing in chemical reactions,\n        molecular structures, and laboratory techniques. Provide detailed, step-by-step\n        explanations.\n      mode: replace\n- name: history\n  description: Route history queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: history\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a historian with expertise across different time periods\n        and cultures. Provide accurate historical context and analysis.\n      mode: replace\n- name: other\n  description: Route general queries\n  priority: 5\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: other\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a helpful and knowledgeable assistant. Provide accurate,\n        helpful responses across a wide range of topics.\n      mode: replace\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.75\n- name: health\n  description: Route health and medical queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: health\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a health and medical information expert with knowledge\n        of anatomy, physiology, diseases, treatments, preventive care, nutrition,\n        and wellness. Provide accurate, evidence-based health information while emphasizing\n        that your responses are for educational purposes only and should never replace\n        professional medical advice, diagnosis, or treatment. Always encourage users\n        to consult healthcare professionals for medical concerns and emergencies.\n      mode: replace\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.95\n- name: economics\n  description: Route economics queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: economics\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are an economics expert with deep understanding of microeconomics,\n        macroeconomics, econometrics, financial markets, monetary policy, fiscal policy,\n        international trade, and economic theory. Analyze economic phenomena using\n        established economic principles, provide data-driven insights, and explain\n        complex economic concepts in accessible terms. Consider both theoretical frameworks\n        and real-world applications in your responses.\n      mode: replace\n- name: math\n  description: Route mathematics queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: math\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a mathematics expert. Provide step-by-step solutions,\n        show your work clearly, and explain mathematical concepts in an understandable\n        way.\n      mode: replace\n- name: physics\n  description: Route physics queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: physics\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a physics expert with deep understanding of physical\n        laws and phenomena. Provide clear explanations with mathematical derivations\n        when appropriate.\n      mode: replace\n- name: computer_science\n  description: Route computer science queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: computer science\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a computer science expert with knowledge of algorithms,\n        data structures, programming languages, and software engineering. Provide\n        clear, practical solutions with code examples when helpful.\n      mode: replace\n- name: philosophy\n  description: Route philosophy queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: philosophy\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a philosophy expert with comprehensive knowledge of philosophical\n        traditions, ethical theories, logic, metaphysics, epistemology, political\n        philosophy, and the history of philosophical thought. Engage with complex\n        philosophical questions by presenting multiple perspectives, analyzing arguments\n        rigorously, and encouraging critical thinking. Draw connections between philosophical\n        concepts and contemporary issues while maintaining intellectual honesty about\n        the complexity and ongoing nature of philosophical debates.\n      mode: replace\n- name: engineering\n  description: Route engineering queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: engineering\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are an engineering expert with knowledge across multiple\n        engineering disciplines including mechanical, electrical, civil, chemical,\n        software, and systems engineering. Apply engineering principles, design methodologies,\n        and problem-solving approaches to provide practical solutions. Consider safety,\n        efficiency, sustainability, and cost-effectiveness in your recommendations.\n        Use technical precision while explaining concepts clearly, and emphasize the\n        importance of proper engineering practices and standards.\n      mode: replace\n- name: thinking\n  description: Route thinking and reasoning queries\n  priority: 15\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: thinking\n  modelRefs:\n  - model: vllm-llama3-8b-instruct\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: true\n      system_prompt: You are a thinking expert, should think multiple steps before\n        answering. Please answer the question step by step.\n      mode: replace\ndefault_model: vllm-llama3-8b-instruct\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\ntools:\n  enabled: false\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\nprompt_guard:\n  enabled: true\n  use_modernbert: true\n  model_id: models/mom-jailbreak-classifier\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: models/mom-jailbreak-classifier/jailbreak_type_mapping.json\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/pii_classifier_modernbert-base_presidio_token_model\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\nkeyword_rules:\n- name: thinking\n  operator: OR\n  keywords:\n  - urgent\n  - immediate\n  - asap\n  - think\n  - careful\n  case_sensitive: false\nrouter:\n  high_confidence_threshold: 0.99\n  low_latency_threshold_ms: 2000\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  success_confidence_threshold: 0.8\n  large_batch_threshold: 4\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  multi_task_lora_weight: 0.3\n  single_task_traditional_weight: 0.3\n  large_batch_lora_weight: 0.25\n  small_batch_traditional_weight: 0.25\n  medium_batch_weight: 0.1\n  high_confidence_lora_weight: 0.25\n  low_confidence_traditional_weight: 0.25\n  low_latency_lora_weight: 0.3\n  high_latency_traditional_weight: 0.1\n  performance_history_weight: 0.2\n  traditional_bert_confidence_threshold: 0.95\n  traditional_modernbert_confidence_threshold: 0.8\n  traditional_pii_detection_threshold: 0.5\n  traditional_token_classification_threshold: 0.9\n  traditional_dropout_prob: 0.1\n  traditional_attention_dropout_prob: 0.1\n  tie_break_confidence: 0.5\nreasoning_families:\n  deepseek:\n    type: chat_template_kwargs\n    parameter: thinking\n  qwen3:\n    type: chat_template_kwargs\n    parameter: enable_thinking\n  gpt-oss:\n    type: reasoning_effort\n    parameter: reasoning_effort\n  gpt:\n    type: reasoning_effort\n    parameter: reasoning_effort\ndefault_reasoning_effort: high\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n      - 0.001\n      - 0.005\n      - 0.01\n      - 0.025\n      - 0.05\n      - 0.1\n      - 0.25\n      - 0.5\n      - 1\n      - 2.5\n      - 5\n      - 10\n      - 30\n      size_buckets:\n      - 1\n      - 2\n      - 5\n      - 10\n      - 20\n      - 50\n      - 100\n      - 200\nembedding_models:\n  qwen3_model_path: models/mom-embedding-pro\n  gemma_model_path: models/mom-embedding-flash\n  use_cpu: true\nobservability:\n  tracing:\n    enabled: false\n    provider: opentelemetry\n    exporter:\n      type: otlp\n      endpoint: jaeger:4317\n      insecure: true\n    sampling:\n      type: always_on\n      rate: 1.0\n    resource:\n      service_name: vllm-semantic-router\n      service_version: v0.1.0\n      deployment_environment: development\n", "intent": "Configuration aibrix deployment, with semantic caching, with routing decisions, with PII detection with tools removed", "deployment_context": "aibrix", "source": "augmented", "base_id": "real_config_4819", "augmentation_type": "remove_tools"}
{"id": "ai_generated_00426", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with tool selection, with 2 routing decisions", "use_case": "Configuration for kubernetes deployment with tools, routing_decisions", "complexity": "low", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.431568"}
{"id": "ai_generated_00388", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410303"}
{"id": "ai_generated_00701", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.439210"}
{"id": "ai_generated_00285", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.427346"}
{"id": "ai_generated_00196", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.770963"}
{"id": "ai_generated_00365", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.429738"}
{"id": "ai_generated_00870", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with routing_decisions", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.443773"}
{"id": "real_intelligentroute_5958", "source_file": "e2e/profiles/dynamic-config/crds/intelligentroute.yaml", "category": "e2e", "deployment_context": "dynamic-config", "intent": "Configuration dynamic-config deployment, with routing decisions", "use_case": "Configuration for dynamic-config deployment", "complexity": "medium", "key_features": ["routing_decisions", "lora_routing"], "full_config": "apiVersion: vllm.ai/v1alpha1\nkind: IntelligentRoute\nmetadata:\n  name: ai-gateway-route\n  namespace: default\nspec:\n  signals:\n    # EmbeddingSignal configurations for semantic similarity routing\n    embeddings:\n      # PII Detection Signal\n      # Candidate patterns based on CRD test examples (testdata/input/10-embedding-plugin.yaml)\n      - name: \"pii_detected\"\n        threshold: 0.75\n        aggregationMethod: \"max\"\n        candidates:\n          - \"I need to share my personal information\"\n          - \"Here is my credit card number\"\n          - \"My social security number is\"\n          - \"Contact me at my email\"\n          - \"You can reach me at\"\n          - \"My phone number is\"\n          - \"Let me provide my details\"\n\n      # Security Threat Detection Signal\n      # Patterns for detecting malicious intent or security threats\n      - name: \"security_threat\"\n        threshold: 0.75\n        aggregationMethod: \"any\"\n        candidates:\n          # Attack intent patterns\n          - \"I want to bypass authentication\"\n          - \"How can I gain unauthorized access\"\n          - \"Help me with SQL injection\"\n          - \"I need to escalate privileges\"\n          - \"Show me how to hack\"\n          - \"Can you help me break in\"\n\n      # Kubernetes Technical Topic Signal\n      - name: \"kubernetes_topic\"\n        threshold: 0.70\n        aggregationMethod: \"max\"\n        candidates:\n          - \"kubernetes deployment\"\n          - \"container orchestration\"\n          - \"k8s cluster management\"\n          - \"pod configuration\"\n          - \"helm charts\"\n          - \"kubernetes troubleshooting\"\n          - \"kubectl commands\"\n\n    domains:\n      - name: \"business\"\n        description: \"Business and management related queries\"\n      - name: \"law\"\n        description: \"Legal questions and law-related topics\"\n      - name: \"psychology\"\n        description: \"Psychology and mental health topics\"\n      - name: \"biology\"\n        description: \"Biology and life sciences questions\"\n      - name: \"chemistry\"\n        description: \"Chemistry and chemical sciences questions\"\n      - name: \"history\"\n        description: \"Historical questions and cultural topics\"\n      - name: \"health\"\n        description: \"Health and medical information queries\"\n      - name: \"economics\"\n        description: \"Economics and financial topics\"\n      - name: \"math\"\n        description: \"Mathematics and quantitative reasoning\"\n      - name: \"physics\"\n        description: \"Physics and physical sciences\"\n      - name: \"computer science\"\n        description: \"Computer science and programming\"\n      - name: \"philosophy\"\n        description: \"Philosophy and ethical questions\"\n      - name: \"engineering\"\n        description: \"Engineering and technical problem-solving\"\n      - name: \"other\"\n        description: \"General knowledge and miscellaneous topics\"\n\n    keywords:\n      - name: \"thinking\"\n        operator: \"OR\"\n        keywords: [\"urgent\", \"immediate\", \"asap\", \"think\", \"careful\"]\n        caseSensitive: false\n\n  decisions:\n    # === HIGH PRIORITY EMBEDDING-BASED DECISIONS ===\n    # Block PII (highest priority)\n    - name: \"block_pii\"\n      priority: 100\n      description: \"Block requests containing PII\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"embedding\"\n            name: \"pii_detected\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"general-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"header_mutation\"\n          configuration:\n            add:\n              - name: \"x-vsr-pii-violation\"\n                value: \"true\"\n              - name: \"x-vsr-signal-pii_detected\"\n                value: \"true\"\n\n    # Block Security Threats\n    - name: \"block_security\"\n      priority: 95\n      description: \"Block security threats and malicious requests\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"embedding\"\n            name: \"security_threat\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"general-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"header_mutation\"\n          configuration:\n            add:\n              - name: \"x-vsr-security-violation\"\n                value: \"true\"\n              - name: \"x-vsr-signal-security_threat\"\n                value: \"true\"\n\n    # Route to Kubernetes Expert\n    - name: \"kubernetes_expert\"\n      priority: 90\n      description: \"Route Kubernetes questions to specialist\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"embedding\"\n            name: \"kubernetes_topic\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"general-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"header_mutation\"\n          configuration:\n            add:\n              - name: \"x-vsr-signal-kubernetes_topic\"\n                value: \"true\"\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a Kubernetes expert. Provide detailed technical guidance for K8s operations.\"\n            mode: \"replace\"\n\n\n    # === KEYWORD-BASED DECISIONS ===\n    - name: \"thinking_decision\"\n      priority: 15\n      description: \"Queries requiring careful thought or urgent attention\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"keyword\"\n            name: \"thinking\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"math-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a thoughtful assistant trained to approach problems systematically. When handling urgent matters or complex questions, break down the problem into clear steps, consider multiple angles, and provide thorough, well-reasoned responses. Take your time to think through implications and edge cases.\"\n            mode: \"replace\"\n\n    - name: \"business_decision\"\n      priority: 10\n      description: \"Business and management related queries\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"business\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"social-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations.\"\n            mode: \"replace\"\n\n    - name: \"law_decision\"\n      priority: 10\n      description: \"Legal questions and law-related topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"law\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"law-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters.\"\n            mode: \"replace\"\n\n    - name: \"psychology_decision\"\n      priority: 10\n      description: \"Psychology and mental health topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"psychology\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"humanities-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"semantic-cache\"\n          configuration:\n            enabled: true\n            similarity_threshold: 0.92\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice.\"\n            mode: \"replace\"\n\n    - name: \"biology_decision\"\n      priority: 10\n      description: \"Biology and life sciences questions\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"biology\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed:\n              - \"ORGANIZATION\"  # Allow - scientific terms like \"photosynthesis\" falsely detected as ORG\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems.\"\n            mode: \"replace\"\n\n    - name: \"chemistry_decision\"\n      priority: 10\n      description: \"Chemistry and chemical sciences questions\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"chemistry\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations.\"\n            mode: \"replace\"\n\n    - name: \"history_decision\"\n      priority: 10\n      description: \"Historical questions and cultural topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"history\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"humanities-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis.\"\n            mode: \"replace\"\n\n    - name: \"health_decision\"\n      priority: 10\n      description: \"Health and medical information queries\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"health\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"semantic-cache\"\n          configuration:\n            enabled: true\n            similarity_threshold: 0.95\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies.\"\n            mode: \"replace\"\n\n    - name: \"economics_decision\"\n      priority: 10\n      description: \"Economics and financial topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"economics\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"social-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses.\"\n            mode: \"replace\"\n\n    - name: \"math_decision\"\n      priority: 10\n      description: \"Mathematics and quantitative reasoning\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"math\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"math-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way.\"\n            mode: \"replace\"\n\n    - name: \"physics_decision\"\n      priority: 10\n      description: \"Physics and physical sciences\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"physics\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: true\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate.\"\n            mode: \"replace\"\n\n    - name: \"computer_science_decision\"\n      priority: 10\n      description: \"Computer science and programming\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"computer science\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful.\"\n            mode: \"replace\"\n\n    - name: \"philosophy_decision\"\n      priority: 10\n      description: \"Philosophy and ethical questions\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"philosophy\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"humanities-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates.\"\n            mode: \"replace\"\n\n    - name: \"engineering_decision\"\n      priority: 10\n      description: \"Engineering and technical problem-solving\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"engineering\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed: []\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards.\"\n            mode: \"replace\"\n\n    - name: \"other_decision\"\n      priority: 1\n      description: \"General knowledge and miscellaneous topics\"\n      signals:\n        operator: \"OR\"\n        conditions:\n          - type: \"domain\"\n            name: \"other\"\n      modelRefs:\n        - model: \"base-model\"\n          loraName: \"science-expert\"\n          useReasoning: false\n      plugins:\n        - type: \"pii\"\n          configuration:\n            enabled: true\n            pii_types_allowed:\n              - \"GPE\"  # Allow - country/city names like \"France\" in general knowledge questions\n        - type: \"semantic-cache\"\n          configuration:\n            enabled: true\n            similarity_threshold: 0.75\n        - type: \"system_prompt\"\n          configuration:\n            enabled: true\n            system_prompt: \"You are a knowledgeable AI assistant with broad expertise across many domains. Provide accurate, helpful, and well-structured responses to general questions. When uncertain, acknowledge limitations and suggest where to find authoritative information.\"\n            mode: \"replace\"\n", "source": "real", "collected_at": "2026-01-06T10:23:39.235584"}
{"id": "ai_generated_00819", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.442385"}
{"id": "ai_generated_00651", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using gpt-oss-20b model, in istio deployment, with semantic caching, with tool selection, with 10 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, tools, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.437855"}
{"id": "ai_generated_00022", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.419308"}
{"id": "template_96202", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"business_decision\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    signals:\n      - type: \"keyword\"\n        categories:\n          - \"technical\"\n          - \"sales\"\n\nmodel_config:\n  llama3:\n    reasoning_family: \"llama3\"\n    preferred_endpoints:\n      - \"endpoint_llama3\"\n\nvllm_endpoints:\n  - name: \"endpoint_llama3\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 2\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"redis\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to llama3, using keyword-based routing, with PII detection, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "business_decision", "model_name": "llama3", "signal_type": "keyword", "category1": "technical", "category2": "sales", "endpoint_address": "192.168.1.100", "endpoint_port": 8002, "endpoint_weight": 2, "cache_enabled": false, "cache_backend": "redis", "cache_threshold": 0.9, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "ai_generated_00965", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446462"}
{"id": "ai_generated_00247", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406016"}
{"id": "ai_generated_00109", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with 9 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.421975"}
{"id": "ai_generated_00070", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400861"}
{"id": "ai_generated_00077", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401086"}
{"id": "ai_generated_00991", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for dynamic-config deployment with tools, observability, routing_decisions", "complexity": "medium", "key_features": ["tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.447215"}
{"id": "ai_generated_00110", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with 12 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.422025"}
{"id": "ai_generated_00153", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403136"}
{"id": "ai_generated_00976", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with 8 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446804"}
{"id": "ai_generated_00511", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.434012"}
{"id": "ai_generated_00289", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using deepseek model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.779257"}
{"id": "ai_generated_00174", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with observability, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.423798"}
{"id": "ai_generated_00275", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using deepseek model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.778011"}
{"id": "ai_generated_00186", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with PII detection, with tool selection, with 8 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.769918"}
{"id": "ai_generated_00652", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with PII detection, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.437887"}
{"id": "ai_generated_00058", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using deepseek model, with semantic caching, with tool selection, with 9 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.759503"}
{"id": "ai_generated_00436", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with routing_decisions", "complexity": "high", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.431917"}
{"id": "ai_generated_00148", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.766690"}
{"id": "ai_generated_00299", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with tool selection, with observability, with 5 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, tools, observability", "complexity": "medium", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407673"}
{"id": "ai_generated_00332", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408582"}
{"id": "ai_generated_00245", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.774930"}
{"id": "ai_generated_00928", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with semantic caching, with tool selection, with observability, with 9 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.445462"}
{"id": "ai_generated_00030", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399822"}
{"id": "ai_generated_00106", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with routing_decisions", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401905"}
{"id": "ai_generated_00084", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with PII detection, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.421225"}
{"id": "ai_generated_00727", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.439901"}
{"id": "ai_generated_00166", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403757"}
{"id": "ai_generated_00086", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.421260"}
{"id": "ai_generated_00418", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with semantic caching, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.431341"}
{"id": "template_14332", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"general_decision\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"support\"\n          - \"customer_service\"\n\nmodel_config:\n  phi4:\n    reasoning_family: \"phi4\"\n    preferred_endpoints:\n      - \"endpoint_phi4\"\n\nvllm_endpoints:\n  - name: \"endpoint_phi4\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 3\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"memory\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: False\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to phi4, using embedding-based routing, for quickstart deployment", "deployment_context": "quickstart", "source": "template", "values": {"decision_name": "general_decision", "model_name": "phi4", "signal_type": "embedding", "category1": "support", "category2": "customer_service", "endpoint_address": "192.168.1.100", "endpoint_port": 11434, "endpoint_weight": 3, "cache_enabled": false, "cache_backend": "memory", "cache_threshold": 0.9, "guard_enabled": false, "guard_threshold": 0.6, "tools_enabled": false, "deployment_context": "quickstart"}}
{"id": "ai_generated_00392", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with routing_decisions", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410382"}
{"id": "ai_generated_00038", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.419824"}
{"id": "ai_generated_00414", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.431113"}
{"id": "template_14081", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"business_decision\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"support\"\n          - \"sales\"\n\nmodel_config:\n  phi4:\n    reasoning_family: \"phi4\"\n    preferred_endpoints:\n      - \"endpoint_phi4\"\n\nvllm_endpoints:\n  - name: \"endpoint_phi4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to phi4, using embedding-based routing, with redis semantic cache, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "business_decision", "model_name": "phi4", "signal_type": "embedding", "category1": "support", "category2": "sales", "endpoint_address": "192.168.1.100", "endpoint_port": 8002, "endpoint_weight": 1, "cache_enabled": true, "cache_backend": "redis", "cache_threshold": 0.7, "guard_enabled": false, "guard_threshold": 0.6, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "ai_generated_00247", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.775111"}
{"id": "augmented_real_bert_classification_7027_2691", "config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: models/mom-jailbreak-classifier\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: models/mom-jailbreak-classifier/jailbreak_type_mapping.json\nvllm_endpoints:\n- name: endpoint1\n  address: 172.28.0.20\n  port: 8002\n  weight: 1\nmodel_config:\n  qwen3:\n    reasoning_family: qwen3\n    preferred_endpoints:\n    - endpoint1\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/pii_classifier_modernbert-base_presidio_token_model\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\ncategories:\n- name: business\n  description: Business and management related queries\n  mmlu_categories:\n  - business\n- name: law\n  description: Legal questions and law-related topics\n  mmlu_categories:\n  - law\n- name: psychology\n  description: Psychology and mental health topics\n  mmlu_categories:\n  - psychology\n- name: biology\n  description: Biology and life sciences questions\n  mmlu_categories:\n  - biology\n- name: chemistry\n  description: Chemistry and chemical sciences questions\n  mmlu_categories:\n  - chemistry\n- name: history\n  description: Historical questions and cultural topics\n  mmlu_categories:\n  - history\n- name: other\n  description: General knowledge and miscellaneous topics\n  mmlu_categories:\n  - other\n- name: health\n  description: Health and medical information queries\n  mmlu_categories:\n  - health\n- name: economics\n  description: Economics and financial topics\n  mmlu_categories:\n  - economics\n- name: math\n  description: Mathematics and quantitative reasoning\n  mmlu_categories:\n  - math\n- name: physics\n  description: Physics and physical sciences\n  mmlu_categories:\n  - physics\n- name: computer_science\n  description: Computer science and programming\n  mmlu_categories:\n  - computer_science\n- name: philosophy\n  description: Philosophy and ethical questions\n  mmlu_categories:\n  - philosophy\n- name: engineering\n  description: Engineering and technical problem-solving\n  mmlu_categories:\n  - engineering\nstrategy: priority\ndecisions:\n- name: business_decision\n  description: Business and management related queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: business\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a senior business consultant and strategic advisor with\n        expertise in corporate strategy, operations management, financial analysis,\n        marketing, and organizational development. Provide practical, actionable business\n        advice backed by proven methodologies and industry best practices. Consider\n        market dynamics, competitive landscape, and stakeholder interests in your\n        recommendations.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: law_decision\n  description: Legal questions and law-related topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: law\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a knowledgeable legal expert with comprehensive understanding\n        of legal principles, case law, statutory interpretation, and legal procedures\n        across multiple jurisdictions. Provide accurate legal information and analysis\n        while clearly stating that your responses are for informational purposes only\n        and do not constitute legal advice. Always recommend consulting with qualified\n        legal professionals for specific legal matters.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: psychology_decision\n  description: Psychology and mental health topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: psychology\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a psychology expert with deep knowledge of cognitive\n        processes, behavioral patterns, mental health, developmental psychology, social\n        psychology, and therapeutic approaches. Provide evidence-based insights grounded\n        in psychological research and theory. When discussing mental health topics,\n        emphasize the importance of professional consultation and avoid providing\n        diagnostic or therapeutic advice.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.92\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: biology_decision\n  description: Biology and life sciences questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: biology\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a biology expert with comprehensive knowledge spanning\n        molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology,\n        and biotechnology. Explain biological concepts with scientific accuracy, use\n        appropriate terminology, and provide examples from current research. Connect\n        biological principles to real-world applications and emphasize the interconnectedness\n        of biological systems.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: chemistry_decision\n  description: Chemistry and chemical sciences questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: chemistry\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a chemistry expert specializing in chemical reactions,\n        molecular structures, and laboratory techniques. Provide detailed, step-by-step\n        explanations.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: history_decision\n  description: Historical questions and cultural topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: history\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a historian with expertise across different time periods\n        and cultures. Provide accurate historical context and analysis.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: health_decision\n  description: Health and medical information queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: health\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a health and medical information expert with knowledge\n        of anatomy, physiology, diseases, treatments, preventive care, nutrition,\n        and wellness. Provide accurate, evidence-based health information while emphasizing\n        that your responses are for educational purposes only and should never replace\n        professional medical advice, diagnosis, or treatment. Always encourage users\n        to consult healthcare professionals for medical concerns and emergencies.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.95\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: economics_decision\n  description: Economics and financial topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: economics\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an economics expert with deep understanding of microeconomics,\n        macroeconomics, econometrics, financial markets, monetary policy, fiscal policy,\n        international trade, and economic theory. Analyze economic phenomena using\n        established economic principles, provide data-driven insights, and explain\n        complex economic concepts in accessible terms. Consider both theoretical frameworks\n        and real-world applications in your responses.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: math_decision\n  description: Mathematics and quantitative reasoning\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: math\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a mathematics expert. Provide step-by-step solutions,\n        show your work clearly, and explain mathematical concepts in an understandable\n        way.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: physics_decision\n  description: Physics and physical sciences\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: physics\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a physics expert with deep understanding of physical\n        laws and phenomena. Provide clear explanations with mathematical derivations\n        when appropriate.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: computer_science_decision\n  description: Computer science and programming\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: computer_science\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a computer science expert with knowledge of algorithms,\n        data structures, programming languages, and software engineering. Provide\n        clear, practical solutions with code examples when helpful.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: philosophy_decision\n  description: Philosophy and ethical questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: philosophy\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a philosophy expert with comprehensive knowledge of philosophical\n        traditions, ethical theories, logic, metaphysics, epistemology, political\n        philosophy, and the history of philosophical thought. Engage with complex\n        philosophical questions by presenting multiple perspectives, analyzing arguments\n        rigorously, and encouraging critical thinking. Draw connections between philosophical\n        concepts and contemporary issues while maintaining intellectual honesty about\n        the complexity and ongoing nature of philosophical debates.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: engineering_decision\n  description: Engineering and technical problem-solving\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: engineering\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an engineering expert with knowledge across multiple\n        engineering disciplines including mechanical, electrical, civil, chemical,\n        software, and systems engineering. Apply engineering principles, design methodologies,\n        and problem-solving approaches to provide practical solutions. Consider safety,\n        efficiency, sustainability, and cost-effectiveness in your recommendations.\n        Use technical precision while explaining concepts clearly, and emphasize the\n        importance of proper engineering practices and standards.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: general_decision\n  description: General knowledge and miscellaneous topics\n  priority: 50\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: other\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a helpful and knowledgeable assistant. Provide accurate,\n        helpful responses across a wide range of topics.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.75\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\nrouter:\n  high_confidence_threshold: 0.99\n  low_latency_threshold_ms: 2000\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  success_confidence_threshold: 0.8\n  large_batch_threshold: 4\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  multi_task_lora_weight: 0.3\n  single_task_traditional_weight: 0.3\n  large_batch_lora_weight: 0.25\n  small_batch_traditional_weight: 0.25\n  medium_batch_weight: 0.1\n  high_confidence_lora_weight: 0.25\n  low_confidence_traditional_weight: 0.25\n  low_latency_lora_weight: 0.3\n  high_latency_traditional_weight: 0.1\n  performance_history_weight: 0.2\n  traditional_bert_confidence_threshold: 0.95\n  traditional_modernbert_confidence_threshold: 0.8\n  traditional_pii_detection_threshold: 0.5\n  traditional_token_classification_threshold: 0.9\n  traditional_dropout_prob: 0.1\n  traditional_attention_dropout_prob: 0.1\n  tie_break_confidence: 0.5\ndefault_model: qwen3\nreasoning_families:\n  deepseek:\n    type: chat_template_kwargs\n    parameter: thinking\n  qwen3:\n    type: chat_template_kwargs\n    parameter: enable_thinking\n  gpt-oss:\n    type: reasoning_effort\n    parameter: reasoning_effort\n  gpt:\n    type: reasoning_effort\n    parameter: reasoning_effort\ndefault_reasoning_effort: high\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n      - 0.001\n      - 0.005\n      - 0.01\n      - 0.025\n      - 0.05\n      - 0.1\n      - 0.25\n      - 0.5\n      - 1\n      - 2.5\n      - 5\n      - 10\n      - 30\n      size_buckets:\n      - 1\n      - 2\n      - 5\n      - 10\n      - 20\n      - 50\n      - 100\n      - 200\nembedding_models:\n  qwen3_model_path: models/mom-embedding-pro\n  gemma_model_path: models/mom-embedding-flash\n  use_cpu: true\nobservability:\n  tracing:\n    enabled: true\n    provider: opentelemetry\n    exporter:\n      type: otlp\n      endpoint: jaeger:4317\n      insecure: true\n    sampling:\n      type: always_on\n      rate: 1.0\n    resource:\n      service_name: vllm-semantic-router\n      service_version: v0.1.0\n      deployment_environment: development\n", "intent": "Configuration with semantic caching, with routing decisions, with PII detection with semantic caching added", "deployment_context": "unknown", "source": "augmented", "base_id": "real_bert_classification_7027", "augmentation_type": "add_semantic_cache"}
{"id": "ai_generated_00940", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.445776"}
{"id": "ai_generated_00228", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405564"}
{"id": "ai_generated_00205", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.424660"}
{"id": "ai_generated_00761", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.440756"}
{"id": "ai_generated_00700", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with PII detection, with tool selection, with observability, with 4 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.439195"}
{"id": "ai_generated_00099", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401739"}
{"id": "ai_generated_00311", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 8 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408034"}
{"id": "ai_generated_00231", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.425403"}
{"id": "template_91027", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"business_decision\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"general\"\n          - \"sales\"\n\nmodel_config:\n  llama3:\n    reasoning_family: \"llama3\"\n    preferred_endpoints:\n      - \"endpoint_llama3\"\n\nvllm_endpoints:\n  - name: \"endpoint_llama3\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 2\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"milvus\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to llama3, using embedding-based routing, with milvus semantic cache, with PII detection, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "business_decision", "model_name": "llama3", "signal_type": "embedding", "category1": "general", "category2": "sales", "endpoint_address": "10.0.0.50", "endpoint_port": 8002, "endpoint_weight": 2, "cache_enabled": true, "cache_backend": "milvus", "cache_threshold": 0.7, "guard_enabled": true, "guard_threshold": 0.6, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "section_semantic_cache_real_bert_classification_7027_10", "config": "semantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\n", "intent": "Generate semantic cache configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "semantic_cache", "deployment_context": "unknown", "source": "section", "base_id": "real_bert_classification_7027", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00967", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with PII detection, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446547"}
{"id": "ai_generated_00683", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with observability, with 11 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.438756"}
{"id": "ai_generated_00050", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with routing_decisions", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.420186"}
{"id": "ai_generated_00820", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.442410"}
{"id": "ai_generated_00759", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.440698"}
{"id": "template_1722", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"domain\"\n        categories:\n          - \"business\"\n          - \"finance\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"milvus\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.7\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using domain-based routing, with milvus semantic cache, with PII detection, with tools auto-selection, for istio deployment", "deployment_context": "istio", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "mistral", "signal_type": "domain", "category1": "business", "category2": "finance", "endpoint_address": "172.28.0.20", "endpoint_port": 8000, "endpoint_weight": 3, "cache_enabled": true, "cache_backend": "milvus", "cache_threshold": 0.9, "guard_enabled": true, "guard_threshold": 0.7, "tools_enabled": true, "deployment_context": "istio"}}
{"id": "ai_generated_00097", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.762648"}
{"id": "augmented_real_prompt_guard_2104_9161", "config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: models/mom-jailbreak-classifier\n  threshold: 0.7\n  use_cpu: true\nvllm_endpoints:\n- name: endpoint1\n  address: 127.0.0.1\n  port: 1234\n  weight: 1\nmodel_config:\n  qwen3:\n    reasoning_family: qwen3\n    preferred_endpoints:\n    - endpoint1\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/pii_classifier_modernbert-base_presidio_token_model\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\ncategories:\n- name: business\n  description: Business and management related queries\n  mmlu_categories:\n  - business\n- name: law\n  description: Legal questions and law-related topics\n  mmlu_categories:\n  - law\n- name: psychology\n  description: Psychology and mental health topics\n  mmlu_categories:\n  - psychology\n- name: biology\n  description: Biology and life sciences questions\n  mmlu_categories:\n  - biology\n- name: chemistry\n  description: Chemistry and chemical sciences questions\n  mmlu_categories:\n  - chemistry\n- name: history\n  description: Historical questions and cultural topics\n  mmlu_categories:\n  - history\n- name: other\n  description: General knowledge and miscellaneous topics\n  mmlu_categories:\n  - other\n- name: health\n  description: Health and medical information queries\n  mmlu_categories:\n  - health\n- name: economics\n  description: Economics and financial topics\n  mmlu_categories:\n  - economics\n- name: math\n  description: Mathematics and quantitative reasoning\n  mmlu_categories:\n  - math\n- name: physics\n  description: Physics and physical sciences\n  mmlu_categories:\n  - physics\n- name: computer_science\n  description: Computer science and programming\n  mmlu_categories:\n  - computer_science\n- name: philosophy\n  description: Philosophy and ethical questions\n  mmlu_categories:\n  - philosophy\n- name: engineering\n  description: Engineering and technical problem-solving\n  mmlu_categories:\n  - engineering\nstrategy: priority\ndecisions:\n- name: business_decision\n  description: Business and management queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: business\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a senior business consultant and strategic advisor with\n        expertise in corporate strategy, operations management, financial analysis,\n        marketing, and organizational development. Provide practical, actionable business\n        advice backed by proven methodologies and industry best practices. Consider\n        market dynamics, competitive landscape, and stakeholder interests in your\n        recommendations.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: law_decision\n  description: Legal questions and law-related topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: law\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a knowledgeable legal expert with comprehensive understanding\n        of legal principles, case law, statutory interpretation, and legal procedures\n        across multiple jurisdictions. Provide accurate legal information and analysis\n        while clearly stating that your responses are for informational purposes only\n        and do not constitute legal advice. Always recommend consulting with qualified\n        legal professionals for specific legal matters.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: psychology_decision\n  description: Psychology and mental health topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: psychology\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a psychology expert with deep knowledge of cognitive\n        processes, behavioral patterns, mental health, developmental psychology, social\n        psychology, and therapeutic approaches. Provide evidence-based insights grounded\n        in psychological research and theory. When discussing mental health topics,\n        emphasize the importance of professional consultation and avoid providing\n        diagnostic or therapeutic advice.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.92\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: biology_decision\n  description: Biology and life sciences questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: biology\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a biology expert with comprehensive knowledge spanning\n        molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology,\n        and biotechnology. Explain biological concepts with scientific accuracy, use\n        appropriate terminology, and provide examples from current research. Connect\n        biological principles to real-world applications and emphasize the interconnectedness\n        of biological systems.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: chemistry_decision\n  description: Chemistry and chemical sciences questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: chemistry\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a chemistry expert specializing in chemical reactions,\n        molecular structures, and laboratory techniques. Provide detailed, step-by-step\n        explanations.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: history_decision\n  description: Historical questions and cultural topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: history\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a historian with expertise across different time periods\n        and cultures. Provide accurate historical context and analysis.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: health_decision\n  description: Health and medical information queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: health\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a health and medical information expert with knowledge\n        of anatomy, physiology, diseases, treatments, preventive care, nutrition,\n        and wellness. Provide accurate, evidence-based health information while emphasizing\n        that your responses are for educational purposes only and should never replace\n        professional medical advice, diagnosis, or treatment. Always encourage users\n        to consult healthcare professionals for medical concerns and emergencies.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.95\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: economics_decision\n  description: Economics and financial topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: economics\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an economics expert with deep understanding of microeconomics,\n        macroeconomics, econometrics, financial markets, monetary policy, fiscal policy,\n        international trade, and economic theory. Analyze economic phenomena using\n        established economic principles, provide data-driven insights, and explain\n        complex economic concepts in accessible terms. Consider both theoretical frameworks\n        and real-world applications in your responses.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: math_decision\n  description: Mathematics and quantitative reasoning\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: math\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a mathematics expert. Provide step-by-step solutions,\n        show your work clearly, and explain mathematical concepts in an understandable\n        way.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: physics_decision\n  description: Physics and physical sciences\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: physics\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a physics expert with deep understanding of physical\n        laws and phenomena. Provide clear explanations with mathematical derivations\n        when appropriate.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: computer_science_decision\n  description: Computer science and programming\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: computer_science\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a computer science expert with knowledge of algorithms,\n        data structures, programming languages, and software engineering. Provide\n        clear, practical solutions with code examples when helpful.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: philosophy_decision\n  description: Philosophy and ethical questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: philosophy\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a philosophy expert with comprehensive knowledge of philosophical\n        traditions, ethical theories, logic, metaphysics, epistemology, political\n        philosophy, and the history of philosophical thought. Engage with complex\n        philosophical questions by presenting multiple perspectives, analyzing arguments\n        rigorously, and encouraging critical thinking. Draw connections between philosophical\n        concepts and contemporary issues while maintaining intellectual honesty about\n        the complexity and ongoing nature of philosophical debates.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: engineering_decision\n  description: Engineering and technical problem-solving\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: engineering\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an engineering expert with knowledge across multiple\n        engineering disciplines including mechanical, electrical, civil, chemical,\n        software, and systems engineering. Apply engineering principles, design methodologies,\n        and problem-solving approaches to provide practical solutions. Consider safety,\n        efficiency, sustainability, and cost-effectiveness in your recommendations.\n        Use technical precision while explaining concepts clearly, and emphasize the\n        importance of proper engineering practices and standards.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: general_decision\n  description: General knowledge and miscellaneous topics\n  priority: 50\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: other\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a helpful and knowledgeable assistant. Provide accurate,\n        helpful responses across a wide range of topics.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.75\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\nrouter:\n  high_confidence_threshold: 0.99\n  low_latency_threshold_ms: 2000\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  success_confidence_threshold: 0.8\n  large_batch_threshold: 4\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  multi_task_lora_weight: 0.3\n  single_task_traditional_weight: 0.3\n  large_batch_lora_weight: 0.25\n  small_batch_traditional_weight: 0.25\n  medium_batch_weight: 0.1\n  high_confidence_lora_weight: 0.25\n  low_confidence_traditional_weight: 0.25\n  low_latency_lora_weight: 0.3\n  high_latency_traditional_weight: 0.1\n  performance_history_weight: 0.2\n  traditional_bert_confidence_threshold: 0.95\n  traditional_modernbert_confidence_threshold: 0.8\n  traditional_pii_detection_threshold: 0.5\n  traditional_token_classification_threshold: 0.9\n  traditional_dropout_prob: 0.1\n  traditional_attention_dropout_prob: 0.1\n  tie_break_confidence: 0.5\ndefault_model: qwen3\nreasoning_families:\n  deepseek:\n    type: chat_template_kwargs\n    parameter: thinking\n  qwen3:\n    type: chat_template_kwargs\n    parameter: enable_thinking\n  gpt-oss:\n    type: reasoning_effort\n    parameter: reasoning_effort\n  gpt:\n    type: reasoning_effort\n    parameter: reasoning_effort\ndefault_reasoning_effort: high\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n      - 0.001\n      - 0.005\n      - 0.01\n      - 0.025\n      - 0.05\n      - 0.1\n      - 0.25\n      - 0.5\n      - 1\n      - 2.5\n      - 5\n      - 10\n      - 30\n      size_buckets:\n      - 1\n      - 2\n      - 5\n      - 10\n      - 20\n      - 50\n      - 100\n      - 200\nembedding_models:\n  qwen3_model_path: models/mom-embedding-pro\n  gemma_model_path: models/mom-embedding-flash\n  use_cpu: true\nobservability:\n  tracing:\n    enabled: true\n    provider: opentelemetry\n    exporter:\n      type: otlp\n      endpoint: jaeger:4317\n      insecure: true\n    sampling:\n      type: always_on\n      rate: 1.0\n    resource:\n      service_name: vllm-semantic-router\n      service_version: v0.1.0\n      deployment_environment: development\n", "intent": "Configuration with semantic caching, with routing decisions, with PII detection with semantic caching added", "deployment_context": "unknown", "source": "augmented", "base_id": "real_prompt_guard_2104", "augmentation_type": "add_semantic_cache"}
{"id": "ai_generated_00110", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401970"}
{"id": "section_semantic_cache_real_keyword_4890_12", "config": "semantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\n", "intent": "Generate semantic cache configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "semantic_cache", "deployment_context": "unknown", "source": "section", "base_id": "real_keyword_4890", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00537", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.434802"}
{"id": "ai_generated_00027", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using gpt-oss-20b model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.756820"}
{"id": "ai_generated_00572", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.435642"}
{"id": "template_22891", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"business_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"keyword\"\n        categories:\n          - \"general\"\n          - \"finance\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 2\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.7\n  use_modernbert: true\n\ntools:\n  enabled: False\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using keyword-based routing, with PII detection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "business_decision", "model_name": "mistral", "signal_type": "keyword", "category1": "general", "category2": "finance", "endpoint_address": "172.28.0.20", "endpoint_port": 8002, "endpoint_weight": 2, "cache_enabled": false, "cache_backend": "milvus", "cache_threshold": 0.8, "guard_enabled": true, "guard_threshold": 0.7, "tools_enabled": false, "deployment_context": "kubernetes"}}
{"id": "ai_generated_00076", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.761029"}
{"id": "ai_generated_00478", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with 1 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.433075"}
{"id": "ai_generated_00462", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using qwen3 model, in istio deployment, with semantic caching, with PII detection, with tool selection, with observability, with 9 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.432605"}
{"id": "ai_generated_00615", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with PII detection, with tool selection, with observability, with 5 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.436818"}
{"id": "section_vllm_endpoints_real_config.hallucination_3225_9", "config": "vllm_endpoints:\n- name: mock-vllm\n  address: 127.0.0.1\n  port: 8002\n  weight: 1\n  health_check_path: /health\n", "intent": "Generate vLLM endpoints configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "vllm_endpoints", "deployment_context": "unknown", "source": "section", "base_id": "real_config.hallucination_3225", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00291", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with 12 routing decisions", "use_case": "Configuration for kubernetes deployment with routing_decisions", "complexity": "high", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.427522"}
{"id": "template_18754", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"support_decision\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"general\"\n          - \"finance\"\n\nmodel_config:\n  llama3:\n    reasoning_family: \"llama3\"\n    preferred_endpoints:\n      - \"endpoint_llama3\"\n\nvllm_endpoints:\n  - name: \"endpoint_llama3\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"milvus\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to llama3, using embedding-based routing, with PII detection, with tools auto-selection, for quickstart deployment", "deployment_context": "quickstart", "source": "template", "values": {"decision_name": "support_decision", "model_name": "llama3", "signal_type": "embedding", "category1": "general", "category2": "finance", "endpoint_address": "10.0.0.50", "endpoint_port": 8000, "endpoint_weight": 1, "cache_enabled": false, "cache_backend": "milvus", "cache_threshold": 0.9, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": true, "deployment_context": "quickstart"}}
{"id": "ai_generated_00029", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.419573"}
{"id": "ai_generated_00298", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.427707"}
{"id": "ai_generated_00199", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with observability, with 12 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.424478"}
{"id": "ai_generated_00784", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using llama3 model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.441350"}
{"id": "ai_generated_00915", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.445043"}
{"id": "augmented_real_config_9056_2884", "config": "model_config:\n  llama3-8b:\n    allow_by_default: true\n  phi4-mini:\n    allow_by_default: true\ndefault_model: llama3-8b\ncategories:\n- name: business\n- name: law\n- name: psychology\n- name: biology\n- name: chemistry\n- name: history\n- name: other\n- name: health\n- name: economics\n- name: math\n- name: physics\n- name: computer science\n- name: philosophy\n- name: engineering\ndecisions:\n- name: business\n  description: Route business and management queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: business\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a senior business consultant and strategic advisor with\n        expertise in corporate strategy, operations management, financial analysis,\n        marketing, and organizational development. Provide practical, actionable business\n        advice backed by proven methodologies and industry best practices. Consider\n        market dynamics, competitive landscape, and stakeholder interests in your\n        recommendations.\n      mode: replace\n- name: law\n  description: Route legal queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: law\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a knowledgeable legal expert with comprehensive understanding\n        of legal principles, case law, statutory interpretation, and legal procedures\n        across multiple jurisdictions. Provide accurate legal information and analysis\n        while clearly stating that your responses are for informational purposes only\n        and do not constitute legal advice. Always recommend consulting with qualified\n        legal professionals for specific legal matters.\n      mode: replace\n- name: psychology\n  description: Route psychology queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: psychology\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a psychology expert with deep knowledge of cognitive\n        processes, behavioral patterns, mental health, developmental psychology, social\n        psychology, and therapeutic approaches. Provide evidence-based insights grounded\n        in psychological research and theory. When discussing mental health topics,\n        emphasize the importance of professional consultation and avoid providing\n        diagnostic or therapeutic advice.\n      mode: replace\n  - type: semantic-cache\n    configuration:\n      enabled: false\n      similarity_threshold: 0.92\n- name: biology\n  description: Route biology queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: biology\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a biology expert with comprehensive knowledge spanning\n        molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology,\n        and biotechnology. Explain biological concepts with scientific accuracy, use\n        appropriate terminology, and provide examples from current research. Connect\n        biological principles to real-world applications and emphasize the interconnectedness\n        of biological systems.\n      mode: replace\n- name: chemistry\n  description: Route chemistry queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: chemistry\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a chemistry expert specializing in chemical reactions,\n        molecular structures, and laboratory techniques. Provide detailed, step-by-step\n        explanations.\n      mode: replace\n- name: history\n  description: Route history queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: history\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a historian with expertise across different time periods\n        and cultures. Provide accurate historical context and analysis.\n      mode: replace\n- name: other\n  description: Route general queries\n  priority: 5\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: other\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a helpful and knowledgeable assistant. Provide accurate,\n        helpful responses across a wide range of topics.\n      mode: replace\n  - type: semantic-cache\n    configuration:\n      enabled: false\n      similarity_threshold: 0.75\n- name: health\n  description: Route health and medical queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: health\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a health and medical information expert with knowledge\n        of anatomy, physiology, diseases, treatments, preventive care, nutrition,\n        and wellness. Provide accurate, evidence-based health information while emphasizing\n        that your responses are for educational purposes only and should never replace\n        professional medical advice, diagnosis, or treatment. Always encourage users\n        to consult healthcare professionals for medical concerns and emergencies.\n      mode: replace\n  - type: semantic-cache\n    configuration:\n      enabled: false\n      similarity_threshold: 0.95\n- name: economics\n  description: Route economics queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: economics\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are an economics expert with deep understanding of microeconomics,\n        macroeconomics, econometrics, financial markets, monetary policy, fiscal policy,\n        international trade, and economic theory. Analyze economic phenomena using\n        established economic principles, provide data-driven insights, and explain\n        complex economic concepts in accessible terms. Consider both theoretical frameworks\n        and real-world applications in your responses.\n      mode: replace\n- name: math\n  description: Route mathematics queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: math\n  modelRefs:\n  - model: phi4-mini\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a mathematics expert. Provide step-by-step solutions,\n        show your work clearly, and explain mathematical concepts in an understandable\n        way.\n      mode: replace\n- name: physics\n  description: Route physics queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: physics\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a physics expert with deep understanding of physical\n        laws and phenomena. Provide clear explanations with mathematical derivations\n        when appropriate.\n      mode: replace\n- name: computer_science\n  description: Route computer science queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: computer science\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a computer science expert with knowledge of algorithms,\n        data structures, programming languages, and software engineering. Provide\n        clear, practical solutions with code examples when helpful.\n      mode: replace\n- name: philosophy\n  description: Route philosophy queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: philosophy\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are a philosophy expert with comprehensive knowledge of philosophical\n        traditions, ethical theories, logic, metaphysics, epistemology, political\n        philosophy, and the history of philosophical thought. Engage with complex\n        philosophical questions by presenting multiple perspectives, analyzing arguments\n        rigorously, and encouraging critical thinking. Draw connections between philosophical\n        concepts and contemporary issues while maintaining intellectual honesty about\n        the complexity and ongoing nature of philosophical debates.\n      mode: replace\n- name: engineering\n  description: Route engineering queries\n  priority: 10\n  rules:\n    operator: OR\n    conditions:\n    - type: domain\n      name: engineering\n  modelRefs:\n  - model: llama3-8b\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      enabled: false\n      system_prompt: You are an engineering expert with knowledge across multiple\n        engineering disciplines including mechanical, electrical, civil, chemical,\n        software, and systems engineering. Apply engineering principles, design methodologies,\n        and problem-solving approaches to provide practical solutions. Consider safety,\n        efficiency, sustainability, and cost-effectiveness in your recommendations.\n        Use technical precision while explaining concepts clearly, and emphasize the\n        importance of proper engineering practices and standards.\n      mode: replace\nbert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: true\n  backend_type: redis\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\ntools:\n  enabled: false\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\nprompt_guard:\n  enabled: false\n  use_modernbert: true\n  model_id: models/mom-jailbreak-classifier\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: models/mom-jailbreak-classifier/jailbreak_type_mapping.json\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: true\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/pii_classifier_modernbert-base_presidio_token_model\n    use_modernbert: true\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\nrouter:\n  high_confidence_threshold: 0.99\n  low_latency_threshold_ms: 2000\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  success_confidence_threshold: 0.8\n  large_batch_threshold: 4\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  multi_task_lora_weight: 0.3\n  single_task_traditional_weight: 0.3\n  large_batch_lora_weight: 0.25\n  small_batch_traditional_weight: 0.25\n  medium_batch_weight: 0.1\n  high_confidence_lora_weight: 0.25\n  low_confidence_traditional_weight: 0.25\n  low_latency_lora_weight: 0.3\n  high_latency_traditional_weight: 0.1\n  performance_history_weight: 0.2\n  traditional_bert_confidence_threshold: 0.95\n  traditional_modernbert_confidence_threshold: 0.8\n  traditional_pii_detection_threshold: 0.5\n  traditional_token_classification_threshold: 0.9\n  traditional_dropout_prob: 0.1\n  traditional_attention_dropout_prob: 0.1\n  tie_break_confidence: 0.5\nreasoning_families:\n  deepseek:\n    type: chat_template_kwargs\n    parameter: thinking\n  qwen3:\n    type: chat_template_kwargs\n    parameter: enable_thinking\n  gpt-oss:\n    type: reasoning_effort\n    parameter: reasoning_effort\n  gpt:\n    type: reasoning_effort\n    parameter: reasoning_effort\nclear_route_cache: true\ndefault_reasoning_effort: high\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n      - 0.001\n      - 0.005\n      - 0.01\n      - 0.025\n      - 0.05\n      - 0.1\n      - 0.25\n      - 0.5\n      - 1\n      - 2.5\n      - 5\n      - 10\n      - 30\n      size_buckets:\n      - 1\n      - 2\n      - 5\n      - 10\n      - 20\n      - 50\n      - 100\n      - 200\nembedding_models:\n  qwen3_model_path: models/mom-embedding-pro\n  use_cpu: true\nobservability:\n  tracing:\n    enabled: false\n    provider: opentelemetry\n    exporter:\n      type: otlp\n      endpoint: jaeger:4317\n      insecure: true\n    sampling:\n      type: always_on\n      rate: 1.0\n    resource:\n      service_name: vllm-semantic-router\n      service_version: v0.1.0\n      deployment_environment: development\n", "intent": "Configuration istio deployment, with semantic caching, with routing decisions, with PII detection with semantic caching added", "deployment_context": "istio", "source": "augmented", "base_id": "real_config_9056", "augmentation_type": "add_semantic_cache"}
{"id": "ai_generated_00066", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400761"}
{"id": "ai_generated_00782", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.441311"}
{"id": "section_vllm_endpoints_real_keyword_4890_14", "config": "vllm_endpoints:\n- name: endpoint1\n  address: 172.28.0.20\n  port: 8002\n  weight: 1\n", "intent": "Generate vLLM endpoints configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "vllm_endpoints", "deployment_context": "unknown", "source": "section", "base_id": "real_keyword_4890", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00291", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407458"}
{"id": "section_tools_real_config.e2e_6379_5", "config": "tools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\n", "intent": "Generate tools auto-selection configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "tools", "deployment_context": "unknown", "source": "section", "base_id": "real_config.e2e_6379", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00254", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with tool selection, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.775780"}
{"id": "ai_generated_00382", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using deepseek model, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410116"}
{"id": "ai_generated_00147", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402926"}
{"id": "ai_generated_00344", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.429137"}
{"id": "ai_generated_00405", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.430870"}
{"id": "section_vllm_endpoints_real_config.testing_20_11", "config": "vllm_endpoints:\n- name: mock\n  address: 172.28.0.10\n  port: 8000\n  weight: 1\n  health_check_path: /health\n", "intent": "Generate vLLM endpoints configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "vllm_endpoints", "deployment_context": "unknown", "source": "section", "base_id": "real_config.testing_20", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00383", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.430267"}
{"id": "ai_generated_00746", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.440357"}
{"id": "ai_generated_00975", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446770"}
{"id": "ai_generated_00969", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446597"}
{"id": "template_35727", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"support\"\n          - \"sales\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.7\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using embedding-based routing, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "mistral", "signal_type": "embedding", "category1": "support", "category2": "sales", "endpoint_address": "10.0.0.50", "endpoint_port": 8002, "endpoint_weight": 1, "cache_enabled": false, "cache_backend": "redis", "cache_threshold": 0.7, "guard_enabled": false, "guard_threshold": 0.7, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "ai_generated_00242", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405921"}
{"id": "ai_generated_00288", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.779193"}
{"id": "ai_generated_00074", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using qwen3 model, in istio deployment, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.420955"}
{"id": "ai_generated_00222", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405448"}
{"id": "ai_generated_00149", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.766789"}
{"id": "ai_generated_00246", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with semantic caching, with observability, with 9 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.775037"}
{"id": "ai_generated_00076", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with PII detection, with tool selection, with observability, with 4 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401068"}
{"id": "ai_generated_00370", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.429851"}
{"id": "ai_generated_00089", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.421312"}
{"id": "ai_generated_00284", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.778854"}
{"id": "ai_generated_00439", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.431980"}
{"id": "template_10120", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"business_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"technical\"\n          - \"finance\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"redis\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using embedding-based routing, with redis semantic cache, with PII detection, with tools auto-selection, for istio deployment", "deployment_context": "istio", "source": "template", "values": {"decision_name": "business_decision", "model_name": "mistral", "signal_type": "embedding", "category1": "technical", "category2": "finance", "endpoint_address": "192.168.1.100", "endpoint_port": 8080, "endpoint_weight": 3, "cache_enabled": true, "cache_backend": "redis", "cache_threshold": 0.9, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": true, "deployment_context": "istio"}}
{"id": "ai_generated_00770", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.441012"}
{"id": "ai_generated_00139", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with tool selection, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.765935"}
{"id": "ai_generated_00372", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409797"}
{"id": "ai_generated_00297", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.427666"}
{"id": "ai_generated_00359", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.429562"}
{"id": "template_83295", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    signals:\n      - type: \"keyword\"\n        categories:\n          - \"business\"\n          - \"customer_service\"\n\nmodel_config:\n  phi4:\n    reasoning_family: \"phi4\"\n    preferred_endpoints:\n      - \"endpoint_phi4\"\n\nvllm_endpoints:\n  - name: \"endpoint_phi4\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"milvus\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to phi4, using keyword-based routing, with tools auto-selection, for quickstart deployment", "deployment_context": "quickstart", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "phi4", "signal_type": "keyword", "category1": "business", "category2": "customer_service", "endpoint_address": "172.28.0.20", "endpoint_port": 8000, "endpoint_weight": 1, "cache_enabled": false, "cache_backend": "milvus", "cache_threshold": 0.7, "guard_enabled": false, "guard_threshold": 0.6, "tools_enabled": true, "deployment_context": "quickstart"}}
{"id": "ai_generated_00445", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.432117"}
{"id": "template_58742", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    signals:\n      - type: \"keyword\"\n        categories:\n          - \"general\"\n          - \"customer_service\"\n\nmodel_config:\n  qwen3:\n    reasoning_family: \"qwen3\"\n    preferred_endpoints:\n      - \"endpoint_qwen3\"\n\nvllm_endpoints:\n  - name: \"endpoint_qwen3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 2\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to qwen3, using keyword-based routing, with tools auto-selection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "qwen3", "signal_type": "keyword", "category1": "general", "category2": "customer_service", "endpoint_address": "172.28.0.20", "endpoint_port": 8002, "endpoint_weight": 2, "cache_enabled": false, "cache_backend": "redis", "cache_threshold": 0.7, "guard_enabled": false, "guard_threshold": 0.6, "tools_enabled": true, "deployment_context": "kubernetes"}}
{"id": "template_96696", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    signals:\n      - type: \"domain\"\n        categories:\n          - \"business\"\n          - \"customer_service\"\n\nmodel_config:\n  llama3:\n    reasoning_family: \"llama3\"\n    preferred_endpoints:\n      - \"endpoint_llama3\"\n\nvllm_endpoints:\n  - name: \"endpoint_llama3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"redis\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.7\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to llama3, using domain-based routing, with PII detection, with tools auto-selection, for quickstart deployment", "deployment_context": "quickstart", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "llama3", "signal_type": "domain", "category1": "business", "category2": "customer_service", "endpoint_address": "172.28.0.20", "endpoint_port": 8002, "endpoint_weight": 3, "cache_enabled": false, "cache_backend": "redis", "cache_threshold": 0.8, "guard_enabled": true, "guard_threshold": 0.7, "tools_enabled": true, "deployment_context": "quickstart"}}
{"id": "ai_generated_00267", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.426816"}
{"id": "ai_generated_00170", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403886"}
{"id": "section_semantic_cache_real_prompt_guard_2104_2", "config": "semantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\n", "intent": "Generate semantic cache configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "semantic_cache", "deployment_context": "unknown", "source": "section", "base_id": "real_prompt_guard_2104", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "ai_generated_00027", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.419487"}
{"id": "ai_generated_00282", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.427199"}
{"id": "ai_generated_00620", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with tool selection, with 9 routing decisions", "use_case": "Configuration for ai-gateway deployment with tools, routing_decisions", "complexity": "high", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.436969"}
{"id": "section_semantic_cache_real_config-7b_1306_19", "config": "semantic_cache:\n  enabled: false\n", "intent": "Generate semantic cache configuration for Configuration with semantic caching, with routing decisions, with PII detection", "section": "semantic_cache", "deployment_context": "unknown", "source": "section", "base_id": "real_config-7b_1306", "full_config_intent": "Configuration with semantic caching, with routing decisions, with PII detection"}
{"id": "real_envoyfilter_3156", "source_file": "deploy/kubernetes/istio/envoyfilter.yaml", "category": "deploy", "deployment_context": "istio", "intent": "Configuration istio deployment", "use_case": "Configuration for istio deployment", "complexity": "low", "key_features": [], "full_config": "apiVersion: networking.istio.io/v1alpha3\nkind: EnvoyFilter\nmetadata:\n  name: semantic-router\n  namespace: default\nspec:\n  configPatches:\n  - applyTo: HTTP_FILTER\n    match:\n      listener:\n        filterChain:\n          filter:\n            name: envoy.filters.network.http_connection_manager\n    patch:\n      operation: INSERT_FIRST\n      value:\n        name: envoy.filters.http.ext_proc\n        typed_config:\n          '@type': type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor\n          failure_mode_allow: true\n          allow_mode_override: true\n          message_timeout: 300s\n          processing_mode:\n            request_header_mode: SEND\n            response_header_mode: SEND\n            request_body_mode: BUFFERED\n            response_body_mode: NONE\n            request_trailer_mode: SKIP\n            response_trailer_mode: SKIP\n          grpc_service:\n            envoy_grpc:\n              cluster_name: outbound|50051||semantic-router.vllm-semantic-router-system.svc.cluster.local\n", "source": "real", "collected_at": "2026-01-06T10:23:39.291483"}
{"id": "ai_generated_00028", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.419556"}
{"id": "ai_generated_00728", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.439932"}
{"id": "ai_generated_00191", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with 12 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404631"}
{"id": "ai_generated_00607", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with tool selection, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, tools, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.436537"}
{"id": "ai_generated_00103", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401870"}
{"id": "ai_generated_00070", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.760570"}
{"id": "ai_generated_00958", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 12 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.446278"}
{"id": "ai_generated_00241", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405909"}
{"id": "ai_generated_00184", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using openai/gpt-oss-20b model, in aibrix deployment, with PII detection, with 2 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404453"}
{"id": "template_84935", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"technical_decision\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"business\"\n          - \"customer_service\"\n\nmodel_config:\n  phi4:\n    reasoning_family: \"phi4\"\n    preferred_endpoints:\n      - \"endpoint_phi4\"\n\nvllm_endpoints:\n  - name: \"endpoint_phi4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nsemantic_cache:\n  enabled: True\n  backend_type: \"memory\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: True\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to phi4, using embedding-based routing, with memory semantic cache, with PII detection, with tools auto-selection, for istio deployment", "deployment_context": "istio", "source": "template", "values": {"decision_name": "technical_decision", "model_name": "phi4", "signal_type": "embedding", "category1": "business", "category2": "customer_service", "endpoint_address": "192.168.1.100", "endpoint_port": 8002, "endpoint_weight": 3, "cache_enabled": true, "cache_backend": "memory", "cache_threshold": 0.7, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": true, "deployment_context": "istio"}}
{"id": "ai_generated_00084", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.761565"}
{"id": "ai_generated_00092", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.762251"}
{"id": "ai_generated_00617", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.436898"}
{"id": "template_82934", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"general_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"domain\"\n        categories:\n          - \"business\"\n          - \"engineering\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: False\n  threshold: 0.6\n  use_modernbert: true\n\ntools:\n  enabled: False\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using domain-based routing, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "general_decision", "model_name": "mistral", "signal_type": "domain", "category1": "business", "category2": "engineering", "endpoint_address": "172.16.0.10", "endpoint_port": 8002, "endpoint_weight": 1, "cache_enabled": false, "cache_backend": "memory", "cache_threshold": 0.8, "guard_enabled": false, "guard_threshold": 0.6, "tools_enabled": false, "deployment_context": "kubernetes"}}
{"id": "template_49739", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"general_decision\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    signals:\n      - type: \"keyword\"\n        categories:\n          - \"technical\"\n          - \"finance\"\n\nmodel_config:\n  mistral:\n    reasoning_family: \"mistral\"\n    preferred_endpoints:\n      - \"endpoint_mistral\"\n\nvllm_endpoints:\n  - name: \"endpoint_mistral\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"memory\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: False\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to mistral, using keyword-based routing, with PII detection, for kubernetes deployment", "deployment_context": "kubernetes", "source": "template", "values": {"decision_name": "general_decision", "model_name": "mistral", "signal_type": "keyword", "category1": "technical", "category2": "finance", "endpoint_address": "172.28.0.20", "endpoint_port": 8000, "endpoint_weight": 1, "cache_enabled": false, "cache_backend": "memory", "cache_threshold": 0.7, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": false, "deployment_context": "kubernetes"}}
{"id": "augmented_real_bert_classification_7027_2691", "config": "bert_model:\n  model_id: models/mom-embedding-light\n  threshold: 0.6\n  use_cpu: true\nsemantic_cache:\n  enabled: true\n  backend_type: memory\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  eviction_policy: fifo\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n  embedding_model: bert\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: config/tools_db.json\n  fallback_to_empty: true\nprompt_guard:\n  enabled: true\n  use_modernbert: false\n  model_id: models/mom-jailbreak-classifier\n  threshold: 0.7\n  use_cpu: true\n  jailbreak_mapping_path: models/mom-jailbreak-classifier/jailbreak_type_mapping.json\nvllm_endpoints:\n- name: endpoint1\n  address: 172.28.0.20\n  port: 8002\n  weight: 1\nmodel_config:\n  qwen3:\n    reasoning_family: qwen3\n    preferred_endpoints:\n    - endpoint1\nclassifier:\n  category_model:\n    model_id: models/mom-domain-classifier\n    use_modernbert: false\n    threshold: 0.6\n    use_cpu: true\n    category_mapping_path: models/mom-domain-classifier/category_mapping.json\n  pii_model:\n    model_id: models/pii_classifier_modernbert-base_presidio_token_model\n    use_modernbert: false\n    threshold: 0.7\n    use_cpu: true\n    pii_mapping_path: models/mom-pii-classifier/pii_type_mapping.json\ncategories:\n- name: business\n  description: Business and management related queries\n  mmlu_categories:\n  - business\n- name: law\n  description: Legal questions and law-related topics\n  mmlu_categories:\n  - law\n- name: psychology\n  description: Psychology and mental health topics\n  mmlu_categories:\n  - psychology\n- name: biology\n  description: Biology and life sciences questions\n  mmlu_categories:\n  - biology\n- name: chemistry\n  description: Chemistry and chemical sciences questions\n  mmlu_categories:\n  - chemistry\n- name: history\n  description: Historical questions and cultural topics\n  mmlu_categories:\n  - history\n- name: other\n  description: General knowledge and miscellaneous topics\n  mmlu_categories:\n  - other\n- name: health\n  description: Health and medical information queries\n  mmlu_categories:\n  - health\n- name: economics\n  description: Economics and financial topics\n  mmlu_categories:\n  - economics\n- name: math\n  description: Mathematics and quantitative reasoning\n  mmlu_categories:\n  - math\n- name: physics\n  description: Physics and physical sciences\n  mmlu_categories:\n  - physics\n- name: computer_science\n  description: Computer science and programming\n  mmlu_categories:\n  - computer_science\n- name: philosophy\n  description: Philosophy and ethical questions\n  mmlu_categories:\n  - philosophy\n- name: engineering\n  description: Engineering and technical problem-solving\n  mmlu_categories:\n  - engineering\nstrategy: priority\ndecisions:\n- name: business_decision\n  description: Business and management related queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: business\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a senior business consultant and strategic advisor with\n        expertise in corporate strategy, operations management, financial analysis,\n        marketing, and organizational development. Provide practical, actionable business\n        advice backed by proven methodologies and industry best practices. Consider\n        market dynamics, competitive landscape, and stakeholder interests in your\n        recommendations.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: law_decision\n  description: Legal questions and law-related topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: law\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a knowledgeable legal expert with comprehensive understanding\n        of legal principles, case law, statutory interpretation, and legal procedures\n        across multiple jurisdictions. Provide accurate legal information and analysis\n        while clearly stating that your responses are for informational purposes only\n        and do not constitute legal advice. Always recommend consulting with qualified\n        legal professionals for specific legal matters.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: psychology_decision\n  description: Psychology and mental health topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: psychology\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a psychology expert with deep knowledge of cognitive\n        processes, behavioral patterns, mental health, developmental psychology, social\n        psychology, and therapeutic approaches. Provide evidence-based insights grounded\n        in psychological research and theory. When discussing mental health topics,\n        emphasize the importance of professional consultation and avoid providing\n        diagnostic or therapeutic advice.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.92\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: biology_decision\n  description: Biology and life sciences questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: biology\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a biology expert with comprehensive knowledge spanning\n        molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology,\n        and biotechnology. Explain biological concepts with scientific accuracy, use\n        appropriate terminology, and provide examples from current research. Connect\n        biological principles to real-world applications and emphasize the interconnectedness\n        of biological systems.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: chemistry_decision\n  description: Chemistry and chemical sciences questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: chemistry\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a chemistry expert specializing in chemical reactions,\n        molecular structures, and laboratory techniques. Provide detailed, step-by-step\n        explanations.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: history_decision\n  description: Historical questions and cultural topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: history\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a historian with expertise across different time periods\n        and cultures. Provide accurate historical context and analysis.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: health_decision\n  description: Health and medical information queries\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: health\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a health and medical information expert with knowledge\n        of anatomy, physiology, diseases, treatments, preventive care, nutrition,\n        and wellness. Provide accurate, evidence-based health information while emphasizing\n        that your responses are for educational purposes only and should never replace\n        professional medical advice, diagnosis, or treatment. Always encourage users\n        to consult healthcare professionals for medical concerns and emergencies.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.95\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: economics_decision\n  description: Economics and financial topics\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: economics\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an economics expert with deep understanding of microeconomics,\n        macroeconomics, econometrics, financial markets, monetary policy, fiscal policy,\n        international trade, and economic theory. Analyze economic phenomena using\n        established economic principles, provide data-driven insights, and explain\n        complex economic concepts in accessible terms. Consider both theoretical frameworks\n        and real-world applications in your responses.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: math_decision\n  description: Mathematics and quantitative reasoning\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: math\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a mathematics expert. Provide step-by-step solutions,\n        show your work clearly, and explain mathematical concepts in an understandable\n        way.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: physics_decision\n  description: Physics and physical sciences\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: physics\n  modelRefs:\n  - model: qwen3\n    use_reasoning: true\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a physics expert with deep understanding of physical\n        laws and phenomena. Provide clear explanations with mathematical derivations\n        when appropriate.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: computer_science_decision\n  description: Computer science and programming\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: computer_science\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a computer science expert with knowledge of algorithms,\n        data structures, programming languages, and software engineering. Provide\n        clear, practical solutions with code examples when helpful.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: philosophy_decision\n  description: Philosophy and ethical questions\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: philosophy\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a philosophy expert with comprehensive knowledge of philosophical\n        traditions, ethical theories, logic, metaphysics, epistemology, political\n        philosophy, and the history of philosophical thought. Engage with complex\n        philosophical questions by presenting multiple perspectives, analyzing arguments\n        rigorously, and encouraging critical thinking. Draw connections between philosophical\n        concepts and contemporary issues while maintaining intellectual honesty about\n        the complexity and ongoing nature of philosophical debates.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: engineering_decision\n  description: Engineering and technical problem-solving\n  priority: 100\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: engineering\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are an engineering expert with knowledge across multiple\n        engineering disciplines including mechanical, electrical, civil, chemical,\n        software, and systems engineering. Apply engineering principles, design methodologies,\n        and problem-solving approaches to provide practical solutions. Consider safety,\n        efficiency, sustainability, and cost-effectiveness in your recommendations.\n        Use technical precision while explaining concepts clearly, and emphasize the\n        importance of proper engineering practices and standards.\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\n- name: general_decision\n  description: General knowledge and miscellaneous topics\n  priority: 50\n  rules:\n    operator: AND\n    conditions:\n    - type: domain\n      name: other\n  modelRefs:\n  - model: qwen3\n    use_reasoning: false\n  plugins:\n  - type: system_prompt\n    configuration:\n      system_prompt: You are a helpful and knowledgeable assistant. Provide accurate,\n        helpful responses across a wide range of topics.\n  - type: semantic-cache\n    configuration:\n      enabled: true\n      similarity_threshold: 0.75\n  - type: pii\n    configuration:\n      enabled: true\n      pii_types_allowed: []\nrouter:\n  high_confidence_threshold: 0.99\n  low_latency_threshold_ms: 2000\n  lora_baseline_score: 0.8\n  traditional_baseline_score: 0.7\n  embedding_baseline_score: 0.75\n  success_confidence_threshold: 0.8\n  large_batch_threshold: 4\n  lora_default_execution_time_ms: 1345\n  traditional_default_execution_time_ms: 4567\n  default_confidence_threshold: 0.95\n  default_max_latency_ms: 5000\n  default_batch_size: 4\n  default_avg_execution_time_ms: 3000\n  lora_default_confidence: 0.99\n  traditional_default_confidence: 0.95\n  lora_default_success_rate: 0.98\n  traditional_default_success_rate: 0.95\n  multi_task_lora_weight: 0.3\n  single_task_traditional_weight: 0.3\n  large_batch_lora_weight: 0.25\n  small_batch_traditional_weight: 0.25\n  medium_batch_weight: 0.1\n  high_confidence_lora_weight: 0.25\n  low_confidence_traditional_weight: 0.25\n  low_latency_lora_weight: 0.3\n  high_latency_traditional_weight: 0.1\n  performance_history_weight: 0.2\n  traditional_bert_confidence_threshold: 0.95\n  traditional_modernbert_confidence_threshold: 0.8\n  traditional_pii_detection_threshold: 0.5\n  traditional_token_classification_threshold: 0.9\n  traditional_dropout_prob: 0.1\n  traditional_attention_dropout_prob: 0.1\n  tie_break_confidence: 0.5\ndefault_model: qwen3\nreasoning_families:\n  deepseek:\n    type: chat_template_kwargs\n    parameter: thinking\n  qwen3:\n    type: chat_template_kwargs\n    parameter: enable_thinking\n  gpt-oss:\n    type: reasoning_effort\n    parameter: reasoning_effort\n  gpt:\n    type: reasoning_effort\n    parameter: reasoning_effort\ndefault_reasoning_effort: high\napi:\n  batch_classification:\n    max_batch_size: 100\n    concurrency_threshold: 5\n    max_concurrency: 8\n    metrics:\n      enabled: true\n      detailed_goroutine_tracking: true\n      high_resolution_timing: false\n      sample_rate: 1.0\n      duration_buckets:\n      - 0.001\n      - 0.005\n      - 0.01\n      - 0.025\n      - 0.05\n      - 0.1\n      - 0.25\n      - 0.5\n      - 1\n      - 2.5\n      - 5\n      - 10\n      - 30\n      size_buckets:\n      - 1\n      - 2\n      - 5\n      - 10\n      - 20\n      - 50\n      - 100\n      - 200\nembedding_models:\n  qwen3_model_path: models/mom-embedding-pro\n  gemma_model_path: models/mom-embedding-flash\n  use_cpu: true\nobservability:\n  tracing:\n    enabled: true\n    provider: opentelemetry\n    exporter:\n      type: otlp\n      endpoint: jaeger:4317\n      insecure: true\n    sampling:\n      type: always_on\n      rate: 1.0\n    resource:\n      service_name: vllm-semantic-router\n      service_version: v0.1.0\n      deployment_environment: development\n", "intent": "Configuration with semantic caching, with routing decisions, with PII detection with PII detection added", "deployment_context": "unknown", "source": "augmented", "base_id": "real_bert_classification_7027", "augmentation_type": "add_pii_detection"}
{"id": "ai_generated_00203", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404976"}
{"id": "ai_generated_00292", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407501"}
{"id": "ai_generated_00015", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T15:48:04.419071"}
{"id": "ai_generated_00064", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with 5 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n", "source": "ai", "collected_at": "2026-01-06T10:23:39.760080"}
{"id": "template_61942", "config": "# Semantic Router Configuration\n# Generated from template\n\ndecisions:\n  - name: \"general_decision\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    signals:\n      - type: \"embedding\"\n        categories:\n          - \"technical\"\n          - \"customer_service\"\n\nmodel_config:\n  phi4:\n    reasoning_family: \"phi4\"\n    preferred_endpoints:\n      - \"endpoint_phi4\"\n\nvllm_endpoints:\n  - name: \"endpoint_phi4\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 3\n\nsemantic_cache:\n  enabled: False\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nprompt_guard:\n  enabled: True\n  threshold: 0.8\n  use_modernbert: true\n\ntools:\n  enabled: False\n  top_k: 3\n  similarity_threshold: 0.2\n", "intent": "Route queries to phi4, using embedding-based routing, with PII detection, for ai-gateway deployment", "deployment_context": "ai-gateway", "source": "template", "values": {"decision_name": "general_decision", "model_name": "phi4", "signal_type": "embedding", "category1": "technical", "category2": "customer_service", "endpoint_address": "10.0.0.50", "endpoint_port": 8080, "endpoint_weight": 3, "cache_enabled": false, "cache_backend": "memory", "cache_threshold": 0.8, "guard_enabled": true, "guard_threshold": 0.8, "tools_enabled": false, "deployment_context": "ai-gateway"}}
