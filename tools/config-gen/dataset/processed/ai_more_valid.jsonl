{"id": "ai_generated_00001", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.398885"}
{"id": "ai_generated_00002", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.398927"}
{"id": "ai_generated_00003", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.398972"}
{"id": "ai_generated_00004", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399031"}
{"id": "ai_generated_00005", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399076"}
{"id": "ai_generated_00006", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399118"}
{"id": "ai_generated_00007", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with PII detection, with tool selection, with 5 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399145"}
{"id": "ai_generated_00008", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399175"}
{"id": "ai_generated_00009", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 5 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399202"}
{"id": "ai_generated_00010", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399224"}
{"id": "ai_generated_00011", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399266"}
{"id": "ai_generated_00012", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399287"}
{"id": "ai_generated_00013", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using deepseek model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399354"}
{"id": "ai_generated_00014", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399375"}
{"id": "ai_generated_00015", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399399"}
{"id": "ai_generated_00016", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using openai/gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399438"}
{"id": "ai_generated_00017", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399461"}
{"id": "ai_generated_00018", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with 12 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399508"}
{"id": "ai_generated_00019", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399541"}
{"id": "ai_generated_00020", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399559"}
{"id": "ai_generated_00021", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, tools, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399576"}
{"id": "ai_generated_00022", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with 8 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399615"}
{"id": "ai_generated_00023", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399657"}
{"id": "ai_generated_00024", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with semantic caching, with observability, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399678"}
{"id": "ai_generated_00025", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 12 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399735"}
{"id": "ai_generated_00026", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, tools, observability", "complexity": "low", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399757"}
{"id": "ai_generated_00027", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399777"}
{"id": "ai_generated_00028", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399797"}
{"id": "ai_generated_00029", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399809"}
{"id": "ai_generated_00030", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399822"}
{"id": "ai_generated_00031", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399837"}
{"id": "ai_generated_00032", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with observability, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399884"}
{"id": "ai_generated_00033", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399913"}
{"id": "ai_generated_00034", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using llama3 model, in istio deployment, with semantic caching, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.399972"}
{"id": "ai_generated_00035", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using gpt-oss-20b model, in kubernetes deployment, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400005"}
{"id": "ai_generated_00036", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400023"}
{"id": "ai_generated_00037", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400042"}
{"id": "ai_generated_00038", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400078"}
{"id": "ai_generated_00039", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with semantic caching, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, tools, observability", "complexity": "low", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400094"}
{"id": "ai_generated_00040", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 9 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400138"}
{"id": "ai_generated_00041", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400158"}
{"id": "ai_generated_00042", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with tool selection, with 6 routing decisions", "use_case": "Configuration for routing-strategies deployment with tools, routing_decisions", "complexity": "medium", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400179"}
{"id": "ai_generated_00043", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 10 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400226"}
{"id": "ai_generated_00044", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400239"}
{"id": "ai_generated_00045", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400255"}
{"id": "ai_generated_00046", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400273"}
{"id": "ai_generated_00047", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with tool selection, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, tools, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400286"}
{"id": "ai_generated_00048", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400304"}
{"id": "ai_generated_00049", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400337"}
{"id": "ai_generated_00050", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with PII detection, with 5 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400360"}
{"id": "ai_generated_00051", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400413"}
{"id": "ai_generated_00052", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400444"}
{"id": "ai_generated_00053", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400466"}
{"id": "ai_generated_00054", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 12 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400514"}
{"id": "ai_generated_00055", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using gpt-oss-20b model, in kubernetes deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400531"}
{"id": "ai_generated_00056", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with observability, routing_decisions", "complexity": "low", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400542"}
{"id": "ai_generated_00057", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with semantic caching, with tool selection, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400559"}
{"id": "ai_generated_00058", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with PII detection, with tool selection, with 8 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400592"}
{"id": "ai_generated_00059", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400626"}
{"id": "ai_generated_00060", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with routing_decisions", "complexity": "medium", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400642"}
{"id": "ai_generated_00061", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400662"}
{"id": "ai_generated_00062", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with observability, routing_decisions", "complexity": "low", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400672"}
{"id": "ai_generated_00063", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400685"}
{"id": "ai_generated_00064", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400704"}
{"id": "ai_generated_00065", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400744"}
{"id": "ai_generated_00066", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400761"}
{"id": "ai_generated_00067", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with observability, with 4 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400782"}
{"id": "ai_generated_00068", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400797"}
{"id": "ai_generated_00069", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400830"}
{"id": "ai_generated_00070", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400861"}
{"id": "ai_generated_00071", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400892"}
{"id": "ai_generated_00072", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400943"}
{"id": "ai_generated_00073", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.400963"}
{"id": "ai_generated_00074", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401005"}
{"id": "ai_generated_00075", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with observability, with 10 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401046"}
{"id": "ai_generated_00076", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with PII detection, with tool selection, with observability, with 4 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401068"}
{"id": "ai_generated_00077", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401086"}
{"id": "ai_generated_00078", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401118"}
{"id": "ai_generated_00079", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with tool selection, with 2 routing decisions", "use_case": "Configuration for kubernetes deployment with tools, routing_decisions", "complexity": "low", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401131"}
{"id": "ai_generated_00080", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401178"}
{"id": "ai_generated_00081", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401192"}
{"id": "ai_generated_00082", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401211"}
{"id": "ai_generated_00083", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for dynamic-config deployment with tools, observability, routing_decisions", "complexity": "high", "key_features": ["tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401243"}
{"id": "ai_generated_00084", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401285"}
{"id": "ai_generated_00085", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401343"}
{"id": "ai_generated_00086", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401365"}
{"id": "ai_generated_00087", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401410"}
{"id": "ai_generated_00088", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401426"}
{"id": "ai_generated_00089", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401445"}
{"id": "ai_generated_00090", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401469"}
{"id": "ai_generated_00091", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401503"}
{"id": "ai_generated_00092", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using deepseek model, in kubernetes deployment, with tool selection, with observability, with 5 routing decisions", "use_case": "Configuration for kubernetes deployment with tools, observability, routing_decisions", "complexity": "medium", "key_features": ["tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401522"}
{"id": "ai_generated_00093", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401539"}
{"id": "ai_generated_00094", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with 9 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401581"}
{"id": "ai_generated_00095", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with observability, with 4 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401600"}
{"id": "ai_generated_00096", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401647"}
{"id": "ai_generated_00097", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401673"}
{"id": "ai_generated_00098", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with observability, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401720"}
{"id": "ai_generated_00099", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401739"}
{"id": "ai_generated_00100", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401769"}
{"id": "ai_generated_00101", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401805"}
{"id": "ai_generated_00102", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401822"}
{"id": "ai_generated_00103", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401870"}
{"id": "ai_generated_00104", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401883"}
{"id": "ai_generated_00105", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using deepseek model, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for quickstart deployment with tools, observability, routing_decisions", "complexity": "low", "key_features": ["tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401895"}
{"id": "ai_generated_00106", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with routing_decisions", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401905"}
{"id": "ai_generated_00107", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with 2 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401922"}
{"id": "ai_generated_00108", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401941"}
{"id": "ai_generated_00109", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401956"}
{"id": "ai_generated_00110", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401970"}
{"id": "ai_generated_00111", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.401983"}
{"id": "ai_generated_00112", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using deepseek model, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402020"}
{"id": "ai_generated_00113", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using llama3 model, in istio deployment, with observability, with 3 routing decisions", "use_case": "Configuration for istio deployment with observability, routing_decisions", "complexity": "medium", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402034"}
{"id": "ai_generated_00114", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402048"}
{"id": "ai_generated_00115", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with PII detection, with 2 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402062"}
{"id": "ai_generated_00116", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402087"}
{"id": "ai_generated_00117", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402105"}
{"id": "ai_generated_00118", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402124"}
{"id": "ai_generated_00119", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with tool selection, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, tools, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402142"}
{"id": "ai_generated_00120", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402153"}
{"id": "ai_generated_00121", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 9 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402195"}
{"id": "ai_generated_00122", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402219"}
{"id": "ai_generated_00123", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402237"}
{"id": "ai_generated_00124", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with tool selection, with 1 routing decisions", "use_case": "Configuration for kubernetes deployment with tools, routing_decisions", "complexity": "low", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402247"}
{"id": "ai_generated_00125", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402266"}
{"id": "ai_generated_00126", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402279"}
{"id": "ai_generated_00127", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402321"}
{"id": "ai_generated_00128", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402349"}
{"id": "ai_generated_00129", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using qwen3 model, in kubernetes deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402367"}
{"id": "ai_generated_00130", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402379"}
{"id": "ai_generated_00131", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402423"}
{"id": "ai_generated_00132", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with PII detection, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402436"}
{"id": "ai_generated_00133", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with 8 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402475"}
{"id": "ai_generated_00134", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402494"}
{"id": "ai_generated_00135", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402559"}
{"id": "ai_generated_00136", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with semantic caching, with observability, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402595"}
{"id": "ai_generated_00137", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402624"}
{"id": "ai_generated_00138", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402653"}
{"id": "ai_generated_00139", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402673"}
{"id": "ai_generated_00140", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402705"}
{"id": "ai_generated_00141", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402732"}
{"id": "ai_generated_00142", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, tools, observability", "complexity": "low", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402751"}
{"id": "ai_generated_00143", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402781"}
{"id": "ai_generated_00144", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with tool selection, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with tools, routing_decisions", "complexity": "low", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402799"}
{"id": "ai_generated_00145", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402826"}
{"id": "ai_generated_00146", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402902"}
{"id": "ai_generated_00147", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402926"}
{"id": "ai_generated_00148", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.402947"}
{"id": "ai_generated_00149", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403034"}
{"id": "ai_generated_00150", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403051"}
{"id": "ai_generated_00151", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403084"}
{"id": "ai_generated_00152", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403115"}
{"id": "ai_generated_00153", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403136"}
{"id": "ai_generated_00154", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403153"}
{"id": "ai_generated_00155", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403191"}
{"id": "ai_generated_00156", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403217"}
{"id": "ai_generated_00157", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using llama3 model, in istio deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403252"}
{"id": "ai_generated_00158", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with 10 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403317"}
{"id": "ai_generated_00159", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403364"}
{"id": "ai_generated_00160", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with semantic caching, with tool selection, with 10 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, tools, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403429"}
{"id": "ai_generated_00161", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403493"}
{"id": "ai_generated_00162", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403523"}
{"id": "ai_generated_00163", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with tool selection, with observability, with 9 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403592"}
{"id": "ai_generated_00164", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403658"}
{"id": "ai_generated_00165", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403682"}
{"id": "ai_generated_00166", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403757"}
{"id": "ai_generated_00167", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403791"}
{"id": "ai_generated_00168", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with tool selection, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403840"}
{"id": "ai_generated_00169", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403864"}
{"id": "ai_generated_00170", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403886"}
{"id": "ai_generated_00171", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.403949"}
{"id": "ai_generated_00172", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404002"}
{"id": "ai_generated_00173", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404029"}
{"id": "ai_generated_00174", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using qwen3 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404068"}
{"id": "ai_generated_00175", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404097"}
{"id": "ai_generated_00176", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404119"}
{"id": "ai_generated_00177", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with PII detection, with 2 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404145"}
{"id": "ai_generated_00178", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using qwen3 model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404202"}
{"id": "ai_generated_00179", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404229"}
{"id": "ai_generated_00180", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404341"}
{"id": "ai_generated_00181", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404370"}
{"id": "ai_generated_00182", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using deepseek model, in kubernetes deployment, with PII detection, with tool selection, with 5 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404411"}
{"id": "ai_generated_00183", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404439"}
{"id": "ai_generated_00184", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using openai/gpt-oss-20b model, in aibrix deployment, with PII detection, with 2 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404453"}
{"id": "ai_generated_00185", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404465"}
{"id": "ai_generated_00186", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with semantic caching, with PII detection, with tool selection, with 8 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404505"}
{"id": "ai_generated_00187", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, observability", "complexity": "low", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404524"}
{"id": "ai_generated_00188", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404535"}
{"id": "ai_generated_00189", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404563"}
{"id": "ai_generated_00190", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with tool selection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, tools, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404579"}
{"id": "ai_generated_00191", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with 12 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404631"}
{"id": "ai_generated_00192", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404645"}
{"id": "ai_generated_00193", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404672"}
{"id": "ai_generated_00194", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with PII detection, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404682"}
{"id": "ai_generated_00195", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404708"}
{"id": "ai_generated_00196", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with PII detection, with tool selection, with observability, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404745"}
{"id": "ai_generated_00197", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404767"}
{"id": "ai_generated_00198", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404802"}
{"id": "ai_generated_00199", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404816"}
{"id": "ai_generated_00200", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404837"}
{"id": "ai_generated_00201", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404873"}
{"id": "ai_generated_00202", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404930"}
{"id": "ai_generated_00203", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404976"}
{"id": "ai_generated_00204", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with observability, with 4 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.404998"}
{"id": "ai_generated_00205", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405033"}
{"id": "ai_generated_00206", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405047"}
{"id": "ai_generated_00207", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405078"}
{"id": "ai_generated_00208", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405114"}
{"id": "ai_generated_00209", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405135"}
{"id": "ai_generated_00210", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using gpt-oss-20b model, in istio deployment, with semantic caching, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405150"}
{"id": "ai_generated_00211", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with tool selection, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with tools, routing_decisions", "complexity": "medium", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405163"}
{"id": "ai_generated_00212", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using phi4 model, with PII detection, with tool selection, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405207"}
{"id": "ai_generated_00213", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405233"}
{"id": "ai_generated_00214", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405249"}
{"id": "ai_generated_00215", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405267"}
{"id": "ai_generated_00216", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405278"}
{"id": "ai_generated_00217", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405334"}
{"id": "ai_generated_00218", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405352"}
{"id": "ai_generated_00219", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with PII detection, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405376"}
{"id": "ai_generated_00220", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405394"}
{"id": "ai_generated_00221", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with PII detection, with 12 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405437"}
{"id": "ai_generated_00222", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405448"}
{"id": "ai_generated_00223", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with tool selection, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with tools, routing_decisions", "complexity": "low", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405461"}
{"id": "ai_generated_00224", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405483"}
{"id": "ai_generated_00225", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with PII detection, with tool selection, with 6 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405507"}
{"id": "ai_generated_00226", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405522"}
{"id": "ai_generated_00227", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405538"}
{"id": "ai_generated_00228", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405564"}
{"id": "ai_generated_00229", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405580"}
{"id": "ai_generated_00230", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with semantic caching, with PII detection, with tool selection, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405627"}
{"id": "ai_generated_00231", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405641"}
{"id": "ai_generated_00232", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with observability, with 7 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405670"}
{"id": "ai_generated_00233", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405686"}
{"id": "ai_generated_00234", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with observability, with 6 routing decisions", "use_case": "Configuration for aibrix deployment with observability, routing_decisions", "complexity": "medium", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405708"}
{"id": "ai_generated_00235", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with semantic caching, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405749"}
{"id": "ai_generated_00236", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with 9 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405794"}
{"id": "ai_generated_00237", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405834"}
{"id": "ai_generated_00238", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405852"}
{"id": "ai_generated_00239", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with observability, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405867"}
{"id": "ai_generated_00240", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405884"}
{"id": "ai_generated_00241", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405909"}
{"id": "ai_generated_00242", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405921"}
{"id": "ai_generated_00243", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405947"}
{"id": "ai_generated_00244", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with semantic caching, with PII detection, with 5 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405972"}
{"id": "ai_generated_00245", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using qwen3 model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405985"}
{"id": "ai_generated_00246", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with tool selection, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with tools, routing_decisions", "complexity": "medium", "key_features": ["tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.405998"}
{"id": "ai_generated_00247", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406016"}
{"id": "ai_generated_00248", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406038"}
{"id": "ai_generated_00249", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406058"}
{"id": "ai_generated_00250", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406092"}
{"id": "ai_generated_00251", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406108"}
{"id": "ai_generated_00252", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406127"}
{"id": "ai_generated_00253", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406163"}
{"id": "ai_generated_00254", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with PII detection, with 1 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406173"}
{"id": "ai_generated_00255", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406190"}
{"id": "ai_generated_00256", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406201"}
{"id": "ai_generated_00257", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406443"}
{"id": "ai_generated_00258", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with 8 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406485"}
{"id": "ai_generated_00259", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406531"}
{"id": "ai_generated_00260", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406547"}
{"id": "ai_generated_00261", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406576"}
{"id": "ai_generated_00262", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406596"}
{"id": "ai_generated_00263", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using openai/gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406662"}
{"id": "ai_generated_00264", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with observability, with 5 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406693"}
{"id": "ai_generated_00265", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406741"}
{"id": "ai_generated_00266", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406775"}
{"id": "ai_generated_00267", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406807"}
{"id": "ai_generated_00268", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using qwen3 model, in routing-strategies deployment, with semantic caching, with 8 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406842"}
{"id": "ai_generated_00269", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.9\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406859"}
{"id": "ai_generated_00270", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with observability, with 6 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406886"}
{"id": "ai_generated_00271", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406907"}
{"id": "ai_generated_00272", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using openai/gpt-oss-20b model, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406931"}
{"id": "ai_generated_00273", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with PII detection, with tool selection, with observability, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.406974"}
{"id": "ai_generated_00274", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407010"}
{"id": "ai_generated_00275", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407026"}
{"id": "ai_generated_00276", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407040"}
{"id": "ai_generated_00277", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with PII detection, with tool selection, with 1 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407052"}
{"id": "ai_generated_00278", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407069"}
{"id": "ai_generated_00279", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using gpt-oss-20b model, in istio deployment, with PII detection, with 10 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407105"}
{"id": "ai_generated_00280", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using phi4 model, in kubernetes deployment, with PII detection, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407134"}
{"id": "ai_generated_00281", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407185"}
{"id": "ai_generated_00282", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with PII detection, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407195"}
{"id": "ai_generated_00283", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with 8 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407227"}
{"id": "ai_generated_00284", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407246"}
{"id": "ai_generated_00285", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with PII detection, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407257"}
{"id": "ai_generated_00286", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using phi4 model, in ai-gateway deployment, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with observability, routing_decisions", "complexity": "low", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407267"}
{"id": "ai_generated_00287", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with PII detection, with 11 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407323"}
{"id": "ai_generated_00288", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407342"}
{"id": "ai_generated_00289", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with PII detection, with tool selection, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407399"}
{"id": "ai_generated_00290", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407424"}
{"id": "ai_generated_00291", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using mistral model, in istio deployment, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407458"}
{"id": "ai_generated_00292", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using llama3 model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407501"}
{"id": "ai_generated_00293", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with tool selection, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407515"}
{"id": "ai_generated_00294", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407531"}
{"id": "ai_generated_00295", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407549"}
{"id": "ai_generated_00296", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407598"}
{"id": "ai_generated_00297", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with tool selection, with observability, with 2 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, tools, observability", "complexity": "low", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407613"}
{"id": "ai_generated_00298", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using qwen3 model, in kubernetes deployment, with semantic caching, with PII detection, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407651"}
{"id": "ai_generated_00299", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with tool selection, with observability, with 5 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, tools, observability", "complexity": "medium", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407673"}
{"id": "ai_generated_00300", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with semantic caching, with PII detection, with tool selection, with 9 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407720"}
{"id": "ai_generated_00301", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407742"}
{"id": "ai_generated_00302", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407785"}
{"id": "ai_generated_00303", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407803"}
{"id": "ai_generated_00304", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407835"}
{"id": "ai_generated_00305", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407847"}
{"id": "ai_generated_00306", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with PII detection, with tool selection, with 4 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407871"}
{"id": "ai_generated_00307", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with observability, with 8 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407909"}
{"id": "ai_generated_00308", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using deepseek model, in dynamic-config deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407922"}
{"id": "ai_generated_00309", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with semantic caching, with PII detection, with 9 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407963"}
{"id": "ai_generated_00310", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.407997"}
{"id": "ai_generated_00311", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 8 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408034"}
{"id": "ai_generated_00312", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with PII detection, with tool selection, with 6 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408058"}
{"id": "ai_generated_00313", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using phi4 model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 4 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408082"}
{"id": "ai_generated_00314", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408139"}
{"id": "ai_generated_00315", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with 2 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408154"}
{"id": "ai_generated_00316", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with semantic caching, with PII detection, with 11 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408204"}
{"id": "ai_generated_00317", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using deepseek model, in istio deployment, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with observability, routing_decisions", "complexity": "low", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408216"}
{"id": "ai_generated_00318", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408228"}
{"id": "ai_generated_00319", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using llama3 model, in ai-gateway deployment, with semantic caching, with PII detection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408260"}
{"id": "ai_generated_00320", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408284"}
{"id": "ai_generated_00321", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with tool selection, with 5 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, tools, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408321"}
{"id": "ai_generated_00322", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with PII detection, with 1 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408332"}
{"id": "ai_generated_00323", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.84\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408350"}
{"id": "ai_generated_00324", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with PII detection, with 11 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408389"}
{"id": "ai_generated_00325", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using qwen3 model, in dynamic-config deployment, with PII detection, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408404"}
{"id": "ai_generated_00326", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408425"}
{"id": "ai_generated_00327", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with PII detection, with tool selection, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408466"}
{"id": "ai_generated_00328", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with PII detection, with observability, with 9 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408500"}
{"id": "ai_generated_00329", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using qwen3 model, in istio deployment, with 4 routing decisions", "use_case": "Configuration for istio deployment with routing_decisions", "complexity": "medium", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408515"}
{"id": "ai_generated_00330", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with observability, with 2 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.85\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408529"}
{"id": "ai_generated_00331", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with PII detection, with tool selection, with 8 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408561"}
{"id": "ai_generated_00332", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408582"}
{"id": "ai_generated_00333", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 10 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408628"}
{"id": "ai_generated_00334", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408660"}
{"id": "ai_generated_00335", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408691"}
{"id": "ai_generated_00336", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408726"}
{"id": "ai_generated_00337", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408745"}
{"id": "ai_generated_00338", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408771"}
{"id": "ai_generated_00339", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using qwen3 model, in kubernetes deployment, with semantic caching, with 2 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.75\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408784"}
{"id": "ai_generated_00340", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using gpt-oss-20b model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408803"}
{"id": "ai_generated_00341", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using qwen3 model, with semantic caching, with PII detection, with tool selection, with observability, with 12 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408859"}
{"id": "ai_generated_00342", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with tool selection, with 6 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, tools, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408885"}
{"id": "ai_generated_00343", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with PII detection, with tool selection, with 9 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408920"}
{"id": "ai_generated_00344", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using deepseek model, in routing-strategies deployment, with semantic caching, with observability, with 10 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408960"}
{"id": "ai_generated_00345", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, observability, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.82\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.408978"}
{"id": "ai_generated_00346", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409013"}
{"id": "ai_generated_00347", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409036"}
{"id": "ai_generated_00348", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using deepseek model, in production-stack deployment, with semantic caching, with PII detection, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409049"}
{"id": "ai_generated_00349", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with pii_detection, tools, observability", "complexity": "low", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.0.0.50\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409065"}
{"id": "ai_generated_00350", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409104"}
{"id": "ai_generated_00351", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using gpt-oss-20b model, in production-stack deployment, with semantic caching, with PII detection, with 12 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409163"}
{"id": "ai_generated_00352", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using phi4 model, in istio deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409176"}
{"id": "ai_generated_00353", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using gpt-oss-20b model, in aibrix deployment, with PII detection, with tool selection, with 12 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"127.0.0.1\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409217"}
{"id": "ai_generated_00354", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with 7 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409254"}
{"id": "ai_generated_00355", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with 3 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409272"}
{"id": "ai_generated_00356", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using phi4 model, in dynamic-config deployment, with semantic caching, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409313"}
{"id": "ai_generated_00357", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using openai/gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 3 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"127.0.0.1\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409333"}
{"id": "ai_generated_00358", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using mistral model, in dynamic-config deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.10.10.20\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.8\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409365"}
{"id": "ai_generated_00359", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 12 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.83\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409422"}
{"id": "ai_generated_00360", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using llama3 model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 5 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409447"}
{"id": "ai_generated_00361", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using gpt-oss-20b model, in istio deployment, with semantic caching, with observability, with 7 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.93\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.87\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409478"}
{"id": "ai_generated_00362", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using qwen3 model, in aibrix deployment, with PII detection, with tool selection, with observability, with 9 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409513"}
{"id": "ai_generated_00363", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409526"}
{"id": "ai_generated_00364", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using deepseek model, in kubernetes deployment, with semantic caching, with 3 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409542"}
{"id": "ai_generated_00365", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with observability, with 9 routing decisions", "use_case": "Configuration for production-stack deployment with observability, routing_decisions", "complexity": "high", "key_features": ["observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"production-stack\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409570"}
{"id": "ai_generated_00366", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using mistral model, in ai-gateway deployment, with semantic caching, with observability, with 12 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409613"}
{"id": "ai_generated_00367", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using llama3 model, in dynamic-config deployment, with semantic caching, with tool selection, with 3 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, tools, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.71\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409629"}
{"id": "ai_generated_00368", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 4 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409649"}
{"id": "ai_generated_00369", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with semantic caching, with PII detection, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.79\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409695"}
{"id": "ai_generated_00370", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using openai/gpt-oss-20b model, in kubernetes deployment, with semantic caching, with PII detection, with tool selection, with observability, with 10 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.81\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.92\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.83\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409739"}
{"id": "ai_generated_00371", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using mistral model, in production-stack deployment, with PII detection, with 10 routing decisions", "use_case": "Configuration for production-stack deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.0.0.50\"\n    port: 11434\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409774"}
{"id": "ai_generated_00372", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 3 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.7\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409797"}
{"id": "ai_generated_00373", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"kubernetes\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409827"}
{"id": "ai_generated_00374", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using mistral model, with semantic caching, with observability, with 11 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, observability, routing_decisions", "complexity": "high", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.73\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409868"}
{"id": "ai_generated_00375", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using llama3 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 6 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "medium", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409893"}
{"id": "ai_generated_00376", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using mistral model, in routing-strategies deployment, with semantic caching, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"127.0.0.1\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.75\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.77\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409922"}
{"id": "ai_generated_00377", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using mistral model, in kubernetes deployment, with PII detection, with 8 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"192.168.1.100\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409956"}
{"id": "ai_generated_00378", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8080\n    weight: 2\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.409985"}
{"id": "ai_generated_00379", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with PII detection, with observability, with 11 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8000\n    weight: 2\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.82\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.94\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.86\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.88\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410032"}
{"id": "ai_generated_00380", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using llama3 model, with semantic caching, with PII detection, with tool selection, with observability, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, tools", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"10.10.10.20\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.89\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410067"}
{"id": "ai_generated_00381", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using mistral model, in aibrix deployment, with semantic caching, with observability, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with semantic_cache, observability, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"mistral\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"mistral\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.88\n\ndefault_model: mistral\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"aibrix\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410084"}
{"id": "ai_generated_00382", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using deepseek model, with semantic caching, with PII detection, with observability, with 7 routing decisions", "use_case": "Configuration for quickstart deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.87\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410116"}
{"id": "ai_generated_00383", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using gpt-oss-20b model, in ai-gateway deployment, with semantic caching, with PII detection, with tool selection, with observability, with 1 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, pii_detection, tools", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.89\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410130"}
{"id": "ai_generated_00384", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using phi4 model, in routing-strategies deployment, with PII detection, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, tools, observability", "complexity": "high", "key_features": ["pii_detection", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"10.0.0.50\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410170"}
{"id": "ai_generated_00385", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using openai/gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with 6 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.77\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.72\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.95\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.76\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410205"}
{"id": "ai_generated_00386", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with semantic caching, with PII detection, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410220"}
{"id": "ai_generated_00387", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using qwen3 model, in ai-gateway deployment, with PII detection, with tool selection, with 12 routing decisions", "use_case": "Configuration for ai-gateway deployment with pii_detection, tools, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"172.28.0.20\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: -10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410264"}
{"id": "ai_generated_00388", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with semantic caching, with PII detection, with observability, with 8 routing decisions", "use_case": "Configuration for routing-strategies deployment with semantic_cache, pii_detection, observability", "complexity": "high", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8001\n    weight: 2\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.8\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.78\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"hybrid\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"routing-strategies\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410303"}
{"id": "ai_generated_00389", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using qwen3 model, in production-stack deployment, with semantic caching, with PII detection, with 4 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.28.0.20\"\n    port: 11434\n    weight: 2\n\nmodel_config:\n  \"qwen3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"qwen3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: qwen3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.81\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410323"}
{"id": "ai_generated_00390", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "routing-strategies", "intent": "Route queries using openai/gpt-oss-20b model, in routing-strategies deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for routing-strategies deployment with pii_detection, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.28.0.20\"\n    port: 8000\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410349"}
{"id": "ai_generated_00391", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with semantic caching, with PII detection, with 4 routing decisions", "use_case": "Configuration for istio deployment with semantic_cache, pii_detection, routing_decisions", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8080\n    weight: 1\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"redis\"\n  similarity_threshold: 0.72\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410372"}
{"id": "ai_generated_00392", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using phi4 model, in production-stack deployment, with 1 routing decisions", "use_case": "Configuration for production-stack deployment with routing_decisions", "complexity": "low", "key_features": ["routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 3\n\nmodel_config:\n  \"phi4\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"phi4\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n\ndefault_model: phi4\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410382"}
{"id": "ai_generated_00393", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using openai/gpt-oss-20b model, in istio deployment, with PII detection, with observability, with 2 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, observability, routing_decisions", "complexity": "low", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_2\"\n    address: \"172.20.0.5\"\n    port: 8000\n    weight: 3\n\nmodel_config:\n  \"openai/gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_2\"]\n\ncategories:\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"openai/gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: openai/gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"istio\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410394"}
{"id": "ai_generated_00394", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "quickstart", "intent": "Route queries using gpt-oss-20b model, with PII detection, with observability, with 10 routing decisions", "use_case": "Configuration for quickstart deployment with pii_detection, observability, routing_decisions", "complexity": "high", "key_features": ["pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 11434\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"quickstart\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410431"}
{"id": "ai_generated_00395", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "dynamic-config", "intent": "Route queries using gpt-oss-20b model, in dynamic-config deployment, with semantic caching, with PII detection, with observability, with 6 routing decisions", "use_case": "Configuration for dynamic-config deployment with semantic_cache, pii_detection, observability", "complexity": "medium", "key_features": ["semantic_cache", "pii_detection", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_4\"\n    address: \"172.20.0.5\"\n    port: 8080\n    weight: 3\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_4\"]\n\ncategories:\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.76\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.84\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.9\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.74\n  max_entries: 1000\n  ttl_seconds: 3600\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"dynamic-config\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410462"}
{"id": "ai_generated_00396", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "ai-gateway", "intent": "Route queries using deepseek model, in ai-gateway deployment, with semantic caching, with tool selection, with observability, with 11 routing decisions", "use_case": "Configuration for ai-gateway deployment with semantic_cache, tools, observability", "complexity": "high", "key_features": ["semantic_cache", "tools", "observability", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_3\"\n    address: \"172.16.0.10\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_3\"]\n\ncategories:\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: philosophy\n    description: \"Philosophy related queries\"\n    mmlu_categories: [\"philosophy\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: biology\n    description: \"Biology related queries\"\n    mmlu_categories: [\"biology\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.85\n\n  - name: \"philosophy_decision\"\n    description: \"Philosophy related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"philosophy\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a philosophy expert. Provide accurate and helpful responses.\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.71\n\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"biology_decision\"\n    description: \"Biology related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"biology\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a biology expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.91\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.73\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 30\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 20\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.79\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 10\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 0\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: true\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"memory\"\n  similarity_threshold: 0.86\n  max_entries: 1000\n  ttl_seconds: 3600\n  use_hnsw: true\n  hnsw_m: 16\n  hnsw_ef_construction: 200\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n\nobservability:\n  metrics:\n    enabled: true\n  tracing:\n    enabled: true\n    provider: \"opentelemetry\"\n    exporter:\n      type: \"otlp\"\n      endpoint: \"jaeger-collector:4317\"\n      insecure: true\n    sampling:\n      type: \"always_on\"\n      rate: 1.0\n    resource:\n      service_name: \"vllm-semantic-router\"\n      service_version: \"v0.1.0\"\n      deployment_environment: \"ai-gateway\"\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410505"}
{"id": "ai_generated_00397", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "istio", "intent": "Route queries using llama3 model, in istio deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for istio deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"192.168.1.100\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: health\n    description: \"Health related queries\"\n    mmlu_categories: [\"health\"]\n  - name: psychology\n    description: \"Psychology related queries\"\n    mmlu_categories: [\"psychology\"]\n  - name: computer_science\n    description: \"Computer_science related queries\"\n    mmlu_categories: [\"computer_science\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: business\n    description: \"Business related queries\"\n    mmlu_categories: [\"business\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"health_decision\"\n    description: \"Health related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"health\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a health expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"psychology_decision\"\n    description: \"Psychology related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"psychology\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a psychology expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"computer_science_decision\"\n    description: \"Computer_science related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"computer_science\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a computer_science expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"business_decision\"\n    description: \"Business related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"business\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a business expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410532"}
{"id": "ai_generated_00398", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "production-stack", "intent": "Route queries using llama3 model, in production-stack deployment, with semantic caching, with tool selection, with 2 routing decisions", "use_case": "Configuration for production-stack deployment with semantic_cache, tools, routing_decisions", "complexity": "low", "key_features": ["semantic_cache", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"10.10.10.20\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"llama3\":\n    reasoning_family: \"qwen3\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.7\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"llama3\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"semantic-cache\"\n        configuration:\n          enabled: true\n          similarity_threshold: 0.74\n\ndefault_model: llama3\n\nreasoning_families:\n  qwen3:\n    type: \"chat_template_kwargs\"\n    parameter: \"enable_thinking\"\n\ndefault_reasoning_effort: high\n\nsemantic_cache:\n  enabled: true\n  backend_type: \"milvus\"\n  similarity_threshold: 0.78\n  max_entries: 1000\n  ttl_seconds: 3600\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410548"}
{"id": "ai_generated_00399", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "kubernetes", "intent": "Route queries using gpt-oss-20b model, in kubernetes deployment, with PII detection, with 7 routing decisions", "use_case": "Configuration for kubernetes deployment with pii_detection, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_1\"\n    address: \"10.0.0.50\"\n    port: 8002\n    weight: 1\n\nmodel_config:\n  \"gpt-oss-20b\":\n    reasoning_family: \"gpt-oss\"\n    preferred_endpoints: [\"endpoint_1\"]\n\ncategories:\n  - name: math\n    description: \"Math related queries\"\n    mmlu_categories: [\"math\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n  - name: chemistry\n    description: \"Chemistry related queries\"\n    mmlu_categories: [\"chemistry\"]\n  - name: history\n    description: \"History related queries\"\n    mmlu_categories: [\"history\"]\n  - name: physics\n    description: \"Physics related queries\"\n    mmlu_categories: [\"physics\"]\n  - name: engineering\n    description: \"Engineering related queries\"\n    mmlu_categories: [\"engineering\"]\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"math_decision\"\n    description: \"Math related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"math\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a math expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"chemistry_decision\"\n    description: \"Chemistry related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"chemistry\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a chemistry expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"history_decision\"\n    description: \"History related queries\"\n    priority: 70\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"history\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a history expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"physics_decision\"\n    description: \"Physics related queries\"\n    priority: 60\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"physics\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a physics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"engineering_decision\"\n    description: \"Engineering related queries\"\n    priority: 50\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"engineering\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a engineering expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 40\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"gpt-oss-20b\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: gpt-oss-20b\n\nreasoning_families:\n  gpt-oss:\n    type: \"reasoning_effort\"\n    parameter: \"reasoning_effort\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410574"}
{"id": "ai_generated_00400", "source_file": "synthetic/ai_generated.yaml", "category": "main", "deployment_context": "aibrix", "intent": "Route queries using deepseek model, in aibrix deployment, with PII detection, with tool selection, with 3 routing decisions", "use_case": "Configuration for aibrix deployment with pii_detection, tools, routing_decisions", "complexity": "medium", "key_features": ["pii_detection", "tools", "routing_decisions"], "full_config": "vllm_endpoints:\n  - name: \"endpoint_5\"\n    address: \"172.16.0.10\"\n    port: 8001\n    weight: 3\n\nmodel_config:\n  \"deepseek\":\n    reasoning_family: \"deepseek\"\n    preferred_endpoints: [\"endpoint_5\"]\n\ncategories:\n  - name: other\n    description: \"Other related queries\"\n    mmlu_categories: [\"other\"]\n  - name: law\n    description: \"Law related queries\"\n    mmlu_categories: [\"law\"]\n  - name: economics\n    description: \"Economics related queries\"\n    mmlu_categories: [\"economics\"]\n\nstrategy: \"priority\"\n\ndecisions:\n  - name: \"other_decision\"\n    description: \"Other related queries\"\n    priority: 100\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"other\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a other expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"law_decision\"\n    description: \"Law related queries\"\n    priority: 90\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"law\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a law expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\n  - name: \"economics_decision\"\n    description: \"Economics related queries\"\n    priority: 80\n    rules:\n      operator: \"AND\"\n      conditions:\n        - type: \"domain\"\n          name: \"economics\"\n    modelRefs:\n      - model: \"deepseek\"\n        use_reasoning: false\n    plugins:\n      - type: \"system_prompt\"\n        configuration:\n          system_prompt: \"You are a economics expert. Provide accurate and helpful responses.\"\n      - type: \"pii\"\n        configuration:\n          enabled: true\n          pii_types_allowed: \"[]\"\n\ndefault_model: deepseek\n\nreasoning_families:\n  deepseek:\n    type: \"chat_template_kwargs\"\n    parameter: \"thinking\"\n\ndefault_reasoning_effort: high\n\nclassifier:\n  category_model:\n    model_id: \"models/mom-domain-classifier\"\n    threshold: 0.6\n    use_cpu: true\n  pii_model:\n    model_id: \"models/mom-pii-classifier\"\n    threshold: 0.9\n    use_cpu: true\n\ntools:\n  enabled: true\n  top_k: 3\n  similarity_threshold: 0.2\n  tools_db_path: \"config/tools_db.json\"\n  fallback_to_empty: true\n", "source": "ai", "collected_at": "2026-01-06T10:24:24.410589"}
